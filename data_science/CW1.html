<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>CW1</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos pre { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
span.linenos { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
td.linenos pre.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE0LjkgMTcuNDVDMTYuMjUgMTcuNDUgMTcuMzUgMTYuMzUgMTcuMzUgMTVDMTcuMzUgMTMuNjUgMTYuMjUgMTIuNTUgMTQuOSAxMi41NUMxMy41NCAxMi41NSAxMi40NSAxMy42NSAxMi40NSAxNUMxMi40NSAxNi4zNSAxMy41NCAxNy40NSAxNC45IDE3LjQ1Wk0yMC4xIDE1LjY4TDIxLjU4IDE2Ljg0QzIxLjcxIDE2Ljk1IDIxLjc1IDE3LjEzIDIxLjY2IDE3LjI5TDIwLjI2IDE5LjcxQzIwLjE3IDE5Ljg2IDIwIDE5LjkyIDE5LjgzIDE5Ljg2TDE4LjA5IDE5LjE2QzE3LjczIDE5LjQ0IDE3LjMzIDE5LjY3IDE2LjkxIDE5Ljg1TDE2LjY0IDIxLjdDMTYuNjIgMjEuODcgMTYuNDcgMjIgMTYuMyAyMkgxMy41QzEzLjMyIDIyIDEzLjE4IDIxLjg3IDEzLjE1IDIxLjdMMTIuODkgMTkuODVDMTIuNDYgMTkuNjcgMTIuMDcgMTkuNDQgMTEuNzEgMTkuMTZMOS45NjAwMiAxOS44NkM5LjgxMDAyIDE5LjkyIDkuNjIwMDIgMTkuODYgOS41NDAwMiAxOS43MUw4LjE0MDAyIDE3LjI5QzguMDUwMDIgMTcuMTMgOC4wOTAwMiAxNi45NSA4LjIyMDAyIDE2Ljg0TDkuNzAwMDIgMTUuNjhMOS42NTAwMSAxNUw5LjcwMDAyIDE0LjMxTDguMjIwMDIgMTMuMTZDOC4wOTAwMiAxMy4wNSA4LjA1MDAyIDEyLjg2IDguMTQwMDIgMTIuNzFMOS41NDAwMiAxMC4yOUM5LjYyMDAyIDEwLjEzIDkuODEwMDIgMTAuMDcgOS45NjAwMiAxMC4xM0wxMS43MSAxMC44NEMxMi4wNyAxMC41NiAxMi40NiAxMC4zMiAxMi44OSAxMC4xNUwxMy4xNSA4LjI4OTk4QzEzLjE4IDguMTI5OTggMTMuMzIgNy45OTk5OCAxMy41IDcuOTk5OThIMTYuM0MxNi40NyA3Ljk5OTk4IDE2LjYyIDguMTI5OTggMTYuNjQgOC4yODk5OEwxNi45MSAxMC4xNUMxNy4zMyAxMC4zMiAxNy43MyAxMC41NiAxOC4wOSAxMC44NEwxOS44MyAxMC4xM0MyMCAxMC4wNyAyMC4xNyAxMC4xMyAyMC4yNiAxMC4yOUwyMS42NiAxMi43MUMyMS43NSAxMi44NiAyMS43MSAxMy4wNSAyMS41OCAxMy4xNkwyMC4xIDE0LjMxTDIwLjE1IDE1TDIwLjEgMTUuNjhaIi8+CiAgICA8cGF0aCBkPSJNNy4zMjk2NiA3LjQ0NDU0QzguMDgzMSA3LjAwOTU0IDguMzM5MzIgNi4wNTMzMiA3LjkwNDMyIDUuMjk5ODhDNy40NjkzMiA0LjU0NjQzIDYuNTA4MSA0LjI4MTU2IDUuNzU0NjYgNC43MTY1NkM1LjM5MTc2IDQuOTI2MDggNS4xMjY5NSA1LjI3MTE4IDUuMDE4NDkgNS42NzU5NEM0LjkxMDA0IDYuMDgwNzEgNC45NjY4MiA2LjUxMTk4IDUuMTc2MzQgNi44NzQ4OEM1LjYxMTM0IDcuNjI4MzIgNi41NzYyMiA3Ljg3OTU0IDcuMzI5NjYgNy40NDQ1NFpNOS42NTcxOCA0Ljc5NTkzTDEwLjg2NzIgNC45NTE3OUMxMC45NjI4IDQuOTc3NDEgMTEuMDQwMiA1LjA3MTMzIDExLjAzODIgNS4xODc5M0wxMS4wMzg4IDYuOTg4OTNDMTEuMDQ1NSA3LjEwMDU0IDEwLjk2MTYgNy4xOTUxOCAxMC44NTUgNy4yMTA1NEw5LjY2MDAxIDcuMzgwODNMOS4yMzkxNSA4LjEzMTg4TDkuNjY5NjEgOS4yNTc0NUM5LjcwNzI5IDkuMzYyNzEgOS42NjkzNCA5LjQ3Njk5IDkuNTc0MDggOS41MzE5OUw4LjAxNTIzIDEwLjQzMkM3LjkxMTMxIDEwLjQ5MiA3Ljc5MzM3IDEwLjQ2NzcgNy43MjEwNSAxMC4zODI0TDYuOTg3NDggOS40MzE4OEw2LjEwOTMxIDkuNDMwODNMNS4zNDcwNCAxMC4zOTA1QzUuMjg5MDkgMTAuNDcwMiA1LjE3MzgzIDEwLjQ5MDUgNS4wNzE4NyAxMC40MzM5TDMuNTEyNDUgOS41MzI5M0MzLjQxMDQ5IDkuNDc2MzMgMy4zNzY0NyA5LjM1NzQxIDMuNDEwNzUgOS4yNTY3OUwzLjg2MzQ3IDguMTQwOTNMMy42MTc0OSA3Ljc3NDg4TDMuNDIzNDcgNy4zNzg4M0wyLjIzMDc1IDcuMjEyOTdDMi4xMjY0NyA3LjE5MjM1IDIuMDQwNDkgNy4xMDM0MiAyLjA0MjQ1IDYuOTg2ODJMMi4wNDE4NyA1LjE4NTgyQzIuMDQzODMgNS4wNjkyMiAyLjExOTA5IDQuOTc5NTggMi4yMTcwNCA0Ljk2OTIyTDMuNDIwNjUgNC43OTM5M0wzLjg2NzQ5IDQuMDI3ODhMMy40MTEwNSAyLjkxNzMxQzMuMzczMzcgMi44MTIwNCAzLjQxMTMxIDIuNjk3NzYgMy41MTUyMyAyLjYzNzc2TDUuMDc0MDggMS43Mzc3NkM1LjE2OTM0IDEuNjgyNzYgNS4yODcyOSAxLjcwNzA0IDUuMzU5NjEgMS43OTIzMUw2LjExOTE1IDIuNzI3ODhMNi45ODAwMSAyLjczODkzTDcuNzI0OTYgMS43ODkyMkM3Ljc5MTU2IDEuNzA0NTggNy45MTU0OCAxLjY3OTIyIDguMDA4NzkgMS43NDA4Mkw5LjU2ODIxIDIuNjQxODJDOS42NzAxNyAyLjY5ODQyIDkuNzEyODUgMi44MTIzNCA5LjY4NzIzIDIuOTA3OTdMOS4yMTcxOCA0LjAzMzgzTDkuNDYzMTYgNC4zOTk4OEw5LjY1NzE4IDQuNzk1OTNaIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Coursework-1">Coursework 1<a class="anchor-link" href="#Coursework-1">&#182;</a></h2><h4 id="Urte-Adomaityte-CID-01356309">Urte Adomaityte CID 01356309<a class="anchor-link" href="#Urte-Adomaityte-CID-01356309">&#182;</a></h4><h4 id="This-is-my-own-work-unless-stated-otherwise.">This is my own work unless stated otherwise.<a class="anchor-link" href="#This-is-my-own-work-unless-stated-otherwise.">&#182;</a></h4>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Task-1:-Regression">Task 1: Regression<a class="anchor-link" href="#Task-1:-Regression">&#182;</a></h3>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Loading-and-cleaning-the-regression-data">Loading and cleaning the regression data<a class="anchor-link" href="#Loading-and-cleaning-the-regression-data">&#182;</a></h3>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Save-and-clean-the-train-data">Save and clean the train data<a class="anchor-link" href="#Save-and-clean-the-train-data">&#182;</a></h4>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">19</span><span class="p">)]</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;regression_train.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
      <th>col12</th>
      <th>col13</th>
      <th>col14</th>
      <th>col15</th>
      <th>col16</th>
      <th>col17</th>
      <th>col18</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>-0.413447</td>
      <td>-0.487722</td>
      <td>0.115738</td>
      <td>0.115735</td>
      <td>0.158124</td>
      <td>0.984960</td>
      <td>0.797449</td>
      <td>-0.773684</td>
      <td>0.985161</td>
      <td>-0.803212</td>
      <td>1.176466</td>
      <td>0.441052</td>
      <td>-0.983048</td>
      <td>0.158124</td>
      <td>1.176469</td>
      <td>-0.487723</td>
      <td>-0.773598</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>-0.412788</td>
      <td>-0.487722</td>
      <td>-1.034027</td>
      <td>-1.034035</td>
      <td>-0.386091</td>
      <td>0.819700</td>
      <td>0.207144</td>
      <td>-0.418203</td>
      <td>0.819617</td>
      <td>-0.666608</td>
      <td>-0.857929</td>
      <td>0.379323</td>
      <td>-0.803625</td>
      <td>-0.386091</td>
      <td>-0.857939</td>
      <td>-0.487723</td>
      <td>-0.418305</td>
      <td>29.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-0.387983</td>
      <td>-0.487722</td>
      <td>-0.211099</td>
      <td>-0.211084</td>
      <td>0.261784</td>
      <td>-0.510932</td>
      <td>-0.923682</td>
      <td>-0.671859</td>
      <td>-0.511320</td>
      <td>-0.102376</td>
      <td>0.344213</td>
      <td>0.441052</td>
      <td>0.131334</td>
      <td>0.261784</td>
      <td>0.344218</td>
      <td>-0.487727</td>
      <td>-0.671863</td>
      <td>24.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.347952</td>
      <td>-0.487722</td>
      <td>-0.720322</td>
      <td>-0.720323</td>
      <td>-0.412006</td>
      <td>0.846768</td>
      <td>0.324494</td>
      <td>-0.248591</td>
      <td>0.846699</td>
      <td>-0.601276</td>
      <td>-0.488039</td>
      <td>0.369674</td>
      <td>-0.381702</td>
      <td>-0.412006</td>
      <td>-0.488023</td>
      <td>-0.487722</td>
      <td>-0.248524</td>
      <td>27.5</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Check for duplicate rows based on all columns, none found.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dup</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dup</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">dup</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;found duplicate at&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>

<span class="n">dup_rows</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="n">data_train</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Duplicate rows :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dup_rows</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Duplicate rows :
Empty DataFrame
Columns: [col0, col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11, col12, col13, col14, col15, col16, col17, col18]
Index: []
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We investigate the data visually to see whether it needs to be standardised. Notice that the predictors seem to be normalised. We assume that the train and test set have the same distribution.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check for colinearity of the training set with a boxplot</span>
<span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">19</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Check for colinearity of the training set with a boxplot</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">18</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice and print the collinear columns side-by-side</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">header2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col3&#39;</span><span class="p">,</span><span class="s1">&#39;col4&#39;</span><span class="p">,</span><span class="s1">&#39;col2&#39;</span><span class="p">,</span><span class="s1">&#39;col16&#39;</span><span class="p">,</span><span class="s1">&#39;col6&#39;</span><span class="p">,</span><span class="s1">&#39;col9&#39;</span><span class="p">,</span><span class="s1">&#39;col5&#39;</span><span class="p">,</span><span class="s1">&#39;col14&#39;</span><span class="p">,</span><span class="s1">&#39;col11&#39;</span><span class="p">,</span><span class="s1">&#39;col15&#39;</span><span class="p">,</span><span class="s1">&#39;col17&#39;</span><span class="p">,</span><span class="s1">&#39;col8&#39;</span><span class="p">]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that they are very similar in distribution - we will eliminate collinear columns and see if it linear regression works better with this dataset. The collumn elimination will be done when the data is turned into matrix (numpy array) form.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Test-data">Test data<a class="anchor-link" href="#Test-data">&#182;</a></h4>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;regression_test.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[28]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
      <th>col12</th>
      <th>col13</th>
      <th>col14</th>
      <th>col15</th>
      <th>col16</th>
      <th>col17</th>
      <th>col18</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>-0.405603</td>
      <td>0.048772</td>
      <td>-0.739290</td>
      <td>-0.739279</td>
      <td>-1.258562</td>
      <td>-0.569343</td>
      <td>-1.265064</td>
      <td>1.284902</td>
      <td>-0.568923</td>
      <td>-0.375583</td>
      <td>0.205505</td>
      <td>0.441052</td>
      <td>-0.541500</td>
      <td>-1.258562</td>
      <td>0.205489</td>
      <td>0.048770</td>
      <td>1.284940</td>
      <td>20.9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>-0.409965</td>
      <td>1.443658</td>
      <td>-1.123032</td>
      <td>-1.123042</td>
      <td>-1.016689</td>
      <td>0.949344</td>
      <td>-1.674010</td>
      <td>1.276251</td>
      <td>0.949281</td>
      <td>-0.060801</td>
      <td>-1.505237</td>
      <td>0.230317</td>
      <td>-1.058741</td>
      <td>-1.016689</td>
      <td>-1.505250</td>
      <td>1.443655</td>
      <td>1.276197</td>
      <td>37.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Check the distribution visually, notice that it has a similar distribution to the train set - we are safe to assume they have the same distribution and it will make sense to use the function trained on the train set on the test set.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">19</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAf2UlEQVR4nO3df5xcdX3v8ddnd/ODZpUfEtKQX2u96N3sRvBuSm0abSZpSFQQ7ANadq3Gy9ZIL2y5gpLVvbfW9rE20aK3N+i1xQ0Ef2wqKApBCLlhIo+IikkFgSyIUgiJXIgQUjYkkE0+949zZpndbHbOnDkzO3vyfj4e85g5M2c+8/meOecz3/M9M2fM3RERkXSoGesEREQkOSrqIiIpoqIuIpIiKuoiIimioi4ikiJ1lXyx008/3RsaGkad58CBA0yZMqWk10kiRrXFUS7ljVNNuSQVR7mUN04lc9mxY8dv3X1qpIDuXrFLS0uLF5LNZgvOU4kY1RZHuZQ3TjXlklQc5VLeOJXMBdjuEeushl9ERFJERV1EJEVU1EVEUkRFXUQkRVTURURSJFJRN7OnzOxhM3vQzLaH951mZpvN7Inw+tTypioikh4dHR1MnjyZTCbD5MmT6ejoSCRuMd9Tz7j7b/OmO4Et7r7azDrD6VWJZCUikmIdHR189atfZc2aNcydO5edO3eyalVQPteuXVtS7FKGXy4E1oe31wMXlZSJiMgJ4oYbbmDNmjVcffXVTJ48mauvvpo1a9Zwww03lBzbPML51M3s34F9gAP/7O7/YmYvufspefPsc/djhmDMbCWwEmDatGktGzZsGPW1+vv7qa+vL6oR5YhRbXGUS3njVFMuScVRLuWNU0qMTCbDXXfdxeTJkwfjHDp0iPe85z1ks9mR5t/h7vMjBY/yCyXgzPD6DOAh4N3AS8Pm2Vcojn5ROrYxkopTTbkkFaeackkqjnIpb5xSYkyaNMmvu+66IXGuu+46nzRp0ojzU8QvSiONqbv7b8Lr583sNuBc4Dkzm+7uz5rZdOD5SJ8iIiInuI9+9KODY+hz587li1/8IqtWreLyyy8vOXbBom5mU4Aad385vH0e8HfA7cAKYHV4/f2SsxEROQHkDoZ++tOf5tVXX2XSpElcfvnlJR8khWgHSqcB28zsIeAB4E53v5ugmC81syeApeG0iIhEsHbtWg4dOkQ2m+XQoUOJFHSI0FN39yeBs0e4/wVgSSJZiIhIIvSLUhGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSREVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSREVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSREVdRGRMdDb20tzczNLliyhubmZ3t7eROIW/I9SERFJVm9vL11dXfT09HDkyBFqa2tpb28HoLW1taTY6qmLiFRYd3c3PT09ZDIZ6urqyGQy9PT00N3dXXJsFXURkQrr6+tj4cKFQ+5buHAhfX19JcdWURcRqbDGxka2bds25L5t27bR2NhYcmwVdRGRCuvq6qK9vZ1sNsvAwADZbJb29na6urpKjq0DpSIiFZY7GNrR0UFfXx+NjY10d3eXfJAUVNRFRMZEa2srra2tbN26lUWLFiUWV8MvIiIpoqIuIpIikYu6mdWa2c/NbGM4fZqZbTazJ8LrU8uXpoiIRFFMT/0qIP9LlJ3AFnc/C9gSTouIyBiKVNTNbCbwPuBreXdfCKwPb68HLko0MxERKZq5e+GZzG4F/gF4A/AJdz/fzF5y91Py5tnn7scMwZjZSmAlwLRp01o2bNgw6mv19/dTX19fVCPKEaPa4iiX8sapplySiqNcyhunkrlkMpkd7j4/UkB3H/UCnA98Jby9CNgY3n5p2Hz7CsVqaWnxQrLZbMF5KhGj2uIol/LGqaZckoqjXMobp5K5ANu9QH3NXaJ8T/2PgPeb2XuBycAbzewbwHNmNt3dnzWz6cDzkT5FRESkbAqOqbv7p9x9prs3AJcC97r7XwC3AyvC2VYA3y9bliIiEkkp31NfDSw1syeApeG0iIiMoaJOE+DuW4Gt4e0XgCXJpyQiInHpF6UiIimioi4ikiIq6iIiY0B/PC0ikhL642kRkRTRH0+LiKSI/nhaRCRF9MfTIiIpoj+eFhFJkdbWVtra2li8ePEx95dKPXURkTGQO6vinFUb8892WzIVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSREVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSREVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRQpWNTNbLKZPWBmD5nZo2b22fD+08xss5k9EV6fWv50RURkNFF66q8Ci939bOAcYLmZvRPoBLa4+1nAlnBaRETGUMGi7oH+cHJCeHHgQmB9eP964KJyJCgiItFFGlM3s1ozexB4Htjs7j8Fprn7swDh9Rlly1JERCKxYv7B2sxOAW4DOoBt7n5K3mP73P2YcXUzWwmsBJg2bVrLhg0bRn2N/v5+6uvrI+dUrhjVFke5lDdONeWSVBzlUt44SeXykbsPcNPyKaPOk8lkdrj7/EgB3b2oC/AZ4BPA48D08L7pwOOFntvS0uKFZLPZgvNUIka1xVEu5Y1TTbkkFUe5lDdOUrnMWbWx4DzAdo9Yo6N8+2Vq2EPHzE4C/gR4DLgdWBHOtgL4fqRPERERKZu6CPNMB9abWS3BGPy33X2jmf0Y+LaZtQO7gEvKmKeIiERQsKi7+y+Ad4xw/wvAknIkJSIi8egXpSIiKaKiLiKSIirqIiIpoqIuIpIiKuoiIimioi4ikiIq6iIiKaKiLiKSIirqIiIpoqIuIpIiKuoiIimioi4ikiIq6iIiKaKiLiKSIirqIiIpoqIuIpIiKuoiIimioi4ikiJR/qNUREQScvZn72H/wcND7mvovHPw9sknTeChz5wXO76KuohIBe0/eJinVr9vcHrr1q0sWrRocDq/wMeh4RcRkRRRURcRSREVdRGRFFFRFxFJERV1EZEUUVEXEUkRFXURkRRRURcRSZGCRd3MZplZ1sz6zOxRM7sqvP80M9tsZk+E16eWP10RERlNlJ76AHCNuzcC7wSuMLO5QCewxd3PAraE0yIiMoYKFnV3f9bd/y28/TLQB8wALgTWh7OtBy4qU44iIhKRuXv0mc0agPuAZmCXu5+S99g+dz9mCMbMVgIrAaZNm9ayYcOGUV+jv7+f+vr6yDmVK0a1xVEu5Y1TTbkkFUe5lDdO3BgfufsANy2fctw4wx8HyGQyO9x9fqQXcPdIF6Ae2AH8aTj90rDH9xWK0dLS4oVks9mC81QiRrXFUS7ljVNNuSQVR7mUN07cGM03NRe8DAds94i1OtJZGs1sAvAd4Jvu/t3w7ufMbLq7P2tm04HnI32KiIicwF7uWz22Z2k0MwN6gD53/2LeQ7cDK8LbK4Dvl5SJiIiULEpP/Y+ADwEPm9mD4X2fBlYD3zazdmAXcElZMhQRkcgKFnV33wbYcR5ekmw6IiJSCv2iVEQkRVTURURSREVdRCRFVNRFRFJERV1EJEVU1EVEUkRFXUQkRVTURURSREVdRCRFVNRFRFJERV1EJEVU1EVEUiTS+dRFRCQ5x5wz/e7Xp08+aUJJsVXURUQqKP8PMiAo8MPvK4WGX0REUkRFXUQkRVTURURSREVdRCRFVNRFRFJERV1EJEVU1EVEUkRFXUQkRVTURURSREVdRCRFVNRFRFJERV1EJEVU1EVEUkRFXUQkRQoWdTNbZ2bPm9kjefedZmabzeyJ8PrU8qYpIiJRROmp3wQsH3ZfJ7DF3c8CtoTTIiIyxgoWdXe/D3hx2N0XAuvD2+uBi5JNS0RE4jB3LzyTWQOw0d2bw+mX3P2UvMf3ufuIQzBmthJYCTBt2rSWDRs2jPpa/f391NfXR82/bDGqLY5yKW+casolqTjKpbxxksrlI3cf4KblU0adJ5PJ7HD3+ZECunvBC9AAPJI3/dKwx/dFidPS0uKFZLPZgvNUIka1xVEu5Y1TTbkkFUe5lDdOUrnMWbWx4DzAdo9QY9099rdfnjOz6QDh9fMx44iISILiFvXbgRXh7RXA95NJR0REShHlK429wI+Bt5nZbjNrB1YDS83sCWBpOC0iImOsrtAM7t56nIeWJJyLiIiUSL8oFRFJERV1EZEUUVEXEUkRFXURkRQpeKBURESSZ2av314TXHuEX/gXop66iMgYyP0CNJvN5v86v2Qq6iIiKZKqot7b20tzczNLliyhubmZ3t7esU5JRKSiUjOm3tvbS1dXFz09PRw5coTa2lra29sBaG093u+nRETSJTU99e7ubnp6eshkMtTV1ZHJZOjp6aG7u3usUxMRqZjUFPW+vj4WLlw45L6FCxfS19c3RhmJiFReaop6Y2Mj27ZtG3Lftm3baGxsHKOMREQqLzVFvauri/b2drLZLAMDA2SzWdrb2+nq6hrr1EREKiY1B0pzB0M7Ojro6+ujsbGR7u5uHSQVkRNKaoo6BIW9tbWVrVu3smjRorFOR0Sk4lIz/CLll8bfAaSxTXJiS1VPXconjb8DSGObktTb20t3d/fgcGZXV5eWyziQqp56Ur0u9d6O1d3dTVtbGx0dHSxbtoyOjg7a2trG9e8A0timpOQ+8NauXcumTZtYu3YtXV1d435bOBG27dT01JPqdfX29nLVVVcxZcoUAA4cOMBVV11VdJxqM3v2bJ555pnB6VmzZrFr167Iz9+5cyevvPLKMcv3qaeeKkO2lZHGNiUl/8d8uWNUPT09dHR0FLUdlLreJSmt2/ZwqempJ9Xruvbaa6mrq2PdunVs2rSJdevWUVdXx7XXXlumzMsvt2EtWLCAW265hQULFvDMM88we/bsyDEmTpzIlVdeOeQXu1deeSUTJ04sY+bllcY2JSWJH/Mlsd4lKY3b9ohyp3ysxKWlpcULyWazBecZiZn51KlTvaGhwc3MGxoafOrUqW5mRcUBvLOz05uamrympsabmpq8s7PTg0UVT9w2JRUD8AULFgyJs2DBgqLaZGZ++umne0NDg9fU1HhDQ4OffvrpRS/ffEksl1LipLFNScVoamrye++9d0ice++915uamiLHSGK9G67U7SDJbbuS7zWw3SPW2dQMv9TW1nLkyBHWrVs3uCt98cUXU1tbW3SsG2+8kd7e3sE4adg1u/XWW4+ZPvPMMyM/f8aMGfT39wOvn8h/YGCAGTNmJJdkhaWxTUnp6upi8eLFx9z/rW99q6g4pa53SUvjtj1caor6wMAAAwMDXHbZZezatYvZs2cP3leMuro6+vv7ueyyy3j66aeZM2cO/f391NUVt6jy/9UkX654lBKn2BgAF198MT/60Y+GTBdr8uTJQz4029raio6RpCSWTbW1qVrkil13dzeP7uyjaW68b78ksd4lpdq27bKJ2qVP4lLO4RfAa2trHRi85KaLjWNmg8+tra11Mytpl3HOqo2xn5tEjFmzZg3uCt9yyy2Du8CzZs2KHKOmpsZvvvnmIbuuN998s9fU1MTOK6nd17jLpprbNNbDL/niLt8k1rvhSh1+SXLbTmK7dtfwy6iOHDlCTU0NR48epaamhiNHjhQdo66ujkmTJjF16lR27drFrFmz2Lt3L6+++moZMq6MXbt2YWbcf//93H///UPuj6qxsZGZM2fyyCOPDH4bIpvNjusTpiXZpqT2qNLkeOtd/rdhKimN2/ZIUlXUAU4++WT27ds3eF2sgYEBJkyYwJ49ezh69Ch79uyhrq6u6GGcapMrMA2dd/LU6vcV/fzcCdNyX//LnTBtPH+nO4k2nf3Ze9h/8DBzVm085rGGzjs5+aQJPPSZ85JMe1wpdb1LUlq37eFSVdTf/e5388ILL7B//37OPPNM5s2bx3333Vd0nIMHDw7ePnz4MIcPH04yzXEpjSdMS6JN+w8eHlKshp93qKHzzsixqn6sdgwltSd0ImzbY1rU562fN/ID64dOPrzi4UjxduzYwR133DF40OuCCy4oMcPi5Xpuw+Vv3FF6byPFGV4gKt0LzD+I+Oijj9LW1kZbW1vkjSvXpqfXnH/MY7me7nhrU5LyX7MaerbVpJp6/NWupKJuZsuBfwJqga+5++pinj9SsY57hkUz48CBAyN+DSuO+vp6+vv7B6+jGt5zg3i9t0I9wChxkvqAySl1wzracA1vAJpvah7h0c5gHgCifYgnoRqKRdLvUynnbKm2TkmhOHE6AXG37fEidlE3s1rgy8BSYDfwMzO73d13JpVcMa644gq+/OUvD+ntmBlXXHFF0bFmzpzJySefTF9fH3PmzGH//v3s3r07yXQrIqkPmKS83Le66j6oqkHuw27UeYBCH3b5e772SWMucwH43Guf43PrPzf42Gh7vtXUKYHCy6bYTkAp23Y17j2PpJSe+rnAr9z9SQAz2wBcCFS8qJ/92XvYP2U59e94ipcf2gRHDkPtBOrPXsYdU5ZzR5EHrHbv3s3HP/5x5s6dy86dO7nmmmvK3ILqVk0rc1JFp5raNPzDDuK16eW+1ez+ykc40r8PPO+bX1ZLbf2pzPxvN3HySRNGjfGGxk7mre889oH1+fMAVGavplBHoNhOSSnbdlIfVOVmcccOzexiYLm7/2U4/SHgD9z9ymHzrQRWAkybNq1lw4YNo8bN7RYV4yN3H+Cm5VNGjTF8nuPJZDLHfSybzRZ8fsfTHQXnAVg7Z23Z41RTLpDM+zTS48PjRHmvK7lsil0uEK9NUPr6W23Lt9A6E3W5QPLLppQ6ky9KzctkMjvcfX6UeKUU9UuAZcOK+rnuftx3c/78+b59+/ZR48YZUz/uAddhCh1wjRKnUIyRxmZH6l0UGr8dPs/xegWjxammXHLzFFKod5zUe51kmwr1JCuxXHLMjPPPP5877rhjMJcLLriAjRs3Rjr4O97WmSjLpZL1IUqc4aLUPDOLXNRLGX7ZDczKm54J/KaEeLENX4hxD7bm4ixbtozNmzfj7pgZS5cuZdOmTZHjjLgi3j10zDdWnLuPHR4YT7kM34DjHJxMaqhixPlitKlQnDjLJRcz7oHbBx54gGw2O/jd+wceeKCo56dtncmvD6Vs20kcE6qEUor6z4CzzOzNwB7gUiAVJ87IvclxPhyS2kCTWJmrKZckJVF0kmpTtS0bgBdffJFly5Zx+PBhJkyYUNTXM9O6zuSUsm1Dch2Bcopd1N19wMyuBDYRfKVxnbs/mlhm49zwH0vYmuC62OGu/DhxY6RJfmGopp/mV8v7NG/ePB5++PWeae7HNfPmRRs6kOPLrXvV/iOxkv4kw91/4O5vdfe3uPv4/b14GeSfYCebzQ7ejhunlBgQrIhmxtNrzh+8Pd4ltWzSlMuePXuKun80SawzI8UY7+veSO91tRR0SNE/H8noqqXoyPHlF724hfTFF1+kra2NpqYmampqaGpqoq2tjRdffLHofMrVKYkTJ42dknJJ1blfpLxGGmKA6tntjKOa2pT/mnHHfAFuu+02BgYGOHr0KL/85S958sknE8pw7OSWTSnL5UShnrpElsZeV7XvSsdx8OBB6uvrMTPq6+uHnMRK0k9FXSLr7e2lubmZJUuW0NzcTG9vb6w41TQUlFSbqs3+/ftxd/bv3z/WqUiFafhFIunt7aWrq2vw3OO1tbW0t7cDjNvT76axTRDsCR09GpwV5ejRo5jZuN/7kOhU1CWS7u5u2trahpx7vK2tbVyfUz2NbYJjjweooJ9YVNQlkp07d3LgwIEhf9Kc+wPf8SqNbcqZPHkyhw4dGryWE4fG1CWSiRMn0tHRQSaToa6ujkwmQ0dHBxMnThzr1GJLY5uAIf/Pm/vfXjlx6N2WSF577TWuv/56stksAwMDZLNZrr/+el577bWxTi22NLYJYNKkScyYMYOamhpmzJjBpEmTxjolqSANv0gkc+fO5aKLLjpm/Pl73/veWKcWWxrbBMFXGg8ePIi7D96WE4eKukTS1dU14jdFurvH79kh0tim8847j3vuuYe9e/fi7uzdu3fwfjkxqKhLJLlvg+T3asf7t0TS2KZNmzYNnl4Wgm++nHfeeUWdOlrGNxV1iay1tZXW1tZU/VQ7jW0q9fSyMr7pQKmISIqoqIuIpIiKuohIiqioi4ikiIq6iEiKWCVP9mNme4FCJ9Y4HfhtiS+VRIxqi6NcyhunmnJJKo5yKW+cSuYyx92nRoqW/8cA1XABtldDjGqLo1zUJuVSXXGqKZf8i4ZfRERSREVdRCRFqrGo/0uVxKi2OMqlvHGqKZek4iiX8sapplwGVfRAqYiIlFc19tRFRCQmFXURkRSpyqJuZn9rZp8Ib59mZpvN7Inw+tSYcS4xs0fN7KiZzY8Z4wtm9piZ/cLMbjOzU2LG+fswxoNmdo+ZnVlsjLz7PmFmbmanx8zlb81sT5jLg2b23jhxwukOM3s8XM6fj5HLv+bl8ZSZPRizTeeY2U/CONvN7NwYMc42sx+b2cNmdoeZvbGI5x53XTOzT5nZr8LltCxOHDN7k5llzazfzK6PGWOpme0I27fDzBbHjHNu3nv2kJl9IM5yCR+fHbbpEyM8FiWXBjM7mJfPV+PECR97e/j+Pxouo8lF5vLBvDweDB8/J0abJpjZ+jCHPjP71PA2DVeVRX2YTmCLu58FbAmn43gE+FPgvhJy2Qw0u/vbgV8CBRfwcXzB3d/u7ucAG4G/iRPEzGYBS4FdMfPI+ZK7nxNefhAzlwxwIfB2d28C/rHYGO7+57k8gO8A342TC/B54LNhnL8Jp4v1NaDT3ecBtwGfLOK5I65rZjYXuBRoApYDXzGz2mLjAIeA/wkcU/yKiPFb4IKwfSuAr8eM8wgwP1zWy4F/NrPjndK70Db4JeCuAnkUivPrvHX58jhxwvy/AVwersuLgMPFxHD3b+atyx8CnnL3B2O06RJgUvg+tQAfM7OG0RpV0aJuZh+2oIf6kJl93czmmNmW8L4tZjZ7hKddCKwPb68HLooTx9373P3xUnJx93vcfSCc/AkwM2ac/8ibnAKcFWO5QLARXAt4Ccv3GDHj/BWw2t1fDaeXx83FzAz4M6A3Zi4O5HrWJwOTYsR4G3CfmX2YoKB/Mu66llumBJ2SMwg+MI4CpwCPF7vOAvcDHyNYdy6Mmct64C4z+zrwMnBG2BssNpcfAzea2RzgVuBU4J5icgnz/3fgPwO7CQpXnDbdBbyl1JpA0GGrB14ysy1ANmabHgqX78eCu4trU+4hYIoFHzQnAa8B/zHCfIMqVtTNrAnoAha7+9nAVcD1wM1hz/ebwP8e4anT3P1ZgPD6d2PGyfd7CcS4DPhF3Dhm1m1mz4Rx5hQbw8zeD+xx94fCu95WQpuuDFe4dWb2hzHjvBV4l5n91Mx+Bvx9zFwA3gU8B0yMmct/B74QLt//RVBIi43xCHBF+PrfIuipxVlP8tf9Owk+IHJxHiHY84y7zv4F8HjMXPLjfAf4ZdgbjJPLzWFbWgg+jL9RZC7nA/+PoKf/XoJfWMZpUxvBh+XZwL8BP4lTE8J5fxZe3hK2p5Tl+1+BG4ppU55bgQPAswR75P/o7i+O9oRK9tQXA7e6+28BwsT+kGCDgWD3b2GEOBMSiDO/lBhm1gUMAK/EjePuXe4+C+gDflNMDDP7HYIVJ3/Y5l0xc/k/BCvuOQQrzhdjxqkj6KW9E/ghQQ/5hWKXS6gV6CX+OvNXwMfD5XsnUBMjxmUERf2NBNvJayWss4sJNs5Xh+Xwa4KeWNx19j8R9CqLziUXB5gOvINg1z9qnOG5bA7b9vsEQ5LfLiYX4K8JhgCfAWYBP4/TJmAnMDssnjXAhy04FlJsm+qAc4Fa4O3ABwj2IOIs37OAScAXimxTzrnAEeBM4M3ANWb2e6M9oZJF3QiHCUYx0uPPmdl0gPD65ZhxksgFM1tB0LP4YClx8uwg2O0sJsZbCN7gh8zsKWAmwTDM7xSbi7s/5+5H3P0ocAPBXkOcNu0GvuvBDx92hfOMdvD2eMu3jqDA/Cvxl+8KXh+Pf5Bggygqhrs/RvCB10PwAfPrIl5/uFw7dhMUrZyZwG8ixkliXRsSx8xmEhwveBl4sog4x8vlMYJeZVORufwB8PlwXZ4MdJrZlRFzGYzj7q+6+wvhfUcI2vTWiHHy27SboGPiwEHgBwQffEUt39ClhB/meYr5cVAbcLe7H3b354EfEXwAHVcli/oW4M/M7E0QfKuFYGzw0vDxDwLbRnje7QQbKeH1xphx8v0sTgwzWw6sAt7v7q/EbZOZnZU3ORE4qZgY7v6wu5/h7g3u3kCwEl4AvC9GLtPzJj9AUATjLN/vEfRSAH5FMCZ5tMgYAH8CPObuu4m/zvwG+OPwdj/gMZbLGbnXB/4O+GrMdY28OD8ELjWz3yVYzucAD0SMM9I6+yuCnmDRuZjZmwn2YroJDs7F2n7M7M1mNpVguVxBMAz4+8XkAlwUrsf/BXiCoIhdH6NNbzWz2nDZPAjMIyjsxS7fTQRF/KcERfWPgWlF5vImM6sJ2/djil9ncnYBiy0whWBP+LHRnlCxP55290fNrBv4oZkdIdjF+mtgnZl9EthLMPY03Grg22bWTtDASwgKWFFxLPiq1VpgKtAIPB8jl+sJdqU2mxkEB0tjtcnM3kZQ9J4G/keMGMM9HjOXz1vwVSsHngLagfNixFkXzvMIwcGc62K26VKCnnEp68xHgX8Ke/2HgH+IEaOV14dflhCsM++O8txh69qdBAWmm+Dn4G8iGDLZS/Dh8/OIcYavs28hGAKcZ2avEezx/XkRufyEYE/qSwTj2V8xs87wduRcwuXzBoKhuwzBkNsHilwu+e/NXQSdk19EXC75cf4vwfGTVwiW7TPA1ohx8tt0BNhP8IH55TCeFdsmgr2OicBfUuQ6Y2YPuvuy8PVvJDhmYcCN7v6L4c8fEst1mgARkdQYD99TFxGRiFTURURSREVdRCRFVNRFRFJERV1EJEVU1EVEUkRFXUQkRf4/+WfR1BWRkYcAAAAASUVORK5CYII=
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check for colinearity of the test set with a boxplot</span>
<span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">18</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># print out the collinear columns side-by-side</span>
<span class="n">header2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col3&#39;</span><span class="p">,</span><span class="s1">&#39;col4&#39;</span><span class="p">,</span><span class="s1">&#39;col2&#39;</span><span class="p">,</span><span class="s1">&#39;col16&#39;</span><span class="p">,</span><span class="s1">&#39;col6&#39;</span><span class="p">,</span><span class="s1">&#39;col9&#39;</span><span class="p">,</span><span class="s1">&#39;col5&#39;</span><span class="p">,</span><span class="s1">&#39;col14&#39;</span><span class="p">,</span><span class="s1">&#39;col11&#39;</span><span class="p">,</span><span class="s1">&#39;col15&#39;</span><span class="p">,</span><span class="s1">&#39;col17&#39;</span><span class="p">,</span><span class="s1">&#39;col8&#39;</span><span class="p">]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that here, too, the same colums are collinear. Eliminate them and see how linear regression performs with each train and test datasets.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="1.1-Linear-Regression">1.1 Linear Regression<a class="anchor-link" href="#1.1-Linear-Regression">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="1.1.1.">1.1.1.<a class="anchor-link" href="#1.1.1.">&#182;</a></h5><p>We will obtain a linear regression model to predict the target variable: median value of owner-occupied homes in USD 1000's, stored in the last column of the dataset.</p>
<p>Then we will report parameters of the model and the in-sample mean squared error (MSE) from the training set.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get X (predictors) and y (target variable) for train and test from dataframes</span>

<span class="c1"># training set into matrix</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1"># split it</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;shape of matrix X containing training predictors&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;length of y_train&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="c1"># test set into matrix</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1"># split it</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># eliminate the fourth column in train set and test set</span>
<span class="n">X_train_elim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_elim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of the predictor matrices X_train and X_test after elimination of collinear columns&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train_elim</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test_elim</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>shape of matrix X containing training predictors (404, 18)
length of y_train 404
Shape of the predictor matrices X_train and X_test after elimination of collinear columns
(404, 12)
(102, 12)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define maximum likelihood estimate for this training set</span>
<span class="k">def</span> <span class="nf">max_lik_estimate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># X: N=404 x D=18 matrix of training inputs</span>
    <span class="c1"># y: N=404 x 1 vector of training targets/observations</span>
    <span class="c1"># returns: maximum likelihood parameters (D=18 x 1)</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">beta_ml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">beta_ml</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We use the maximum liekelihood estimate to get the parameters beta of the model</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">beta_ml</span> <span class="o">=</span> <span class="n">max_lik_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;parameters beta of the model with collinear rows:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">beta_ml</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>parameters beta of the model with collinear rows:
 [ 2.25195147e+01 -6.18293247e-01 -4.49290005e+04 -4.00382415e+04
  4.00380821e+04  3.01999433e+02  9.82671082e+02 -1.58321469e-01
  1.37926982e+03 -9.79553073e+02 -5.46852187e-02 -5.67502440e+03
  7.41991548e-01 -3.71807163e+00 -3.03791933e+02  5.67328253e+03
  4.49301324e+04 -1.38276124e+03]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define the prediction function for linear regression</span>
<span class="k">def</span> <span class="nf">predict_with_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="c1"># X_test: K x D matrix of test inputs</span>
    <span class="c1"># beta: D x 1 vector of parameters</span>
    <span class="c1"># returns: prediction of f(X_test); K x 1 vector </span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">X_test</span> <span class="o">@</span> <span class="n">beta</span>
    <span class="k">return</span> <span class="n">prediction</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Finally, we get the prediction and calculate the in-sample mean squared error (MSE)</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">in_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta_ml</span><span class="p">)</span>
<span class="n">mse_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">in_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;in-sample MSE, train set with collinear rows&#39;</span><span class="p">,</span><span class="n">mse_in</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>in-sample MSE, train set with collinear rows 24.36924679184832
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get maximum likelihood estimate - parameters of the model for the X_train with eliminated 4th row</span>
<span class="n">beta_ml_elim</span> <span class="o">=</span> <span class="n">max_lik_estimate</span><span class="p">(</span><span class="n">X_train_elim</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Parameters beta of the model without collinear rows:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">beta_ml_elim</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Parameters beta of the model without collinear rows:
 [22.52796322 -0.63690087  1.15237006 -0.19674719 -1.69697157  3.13055287
 -0.13692781 -0.08360849 -1.74357946  0.81728303 -3.66390957 -3.48789421]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># in-sample MSE with eliminated (colinear) 4th row</span>
<span class="n">in_pred_elim</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train_elim</span><span class="p">,</span> <span class="n">beta_ml_elim</span><span class="p">)</span>
<span class="n">mse_in_elim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">in_pred_elim</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;in-sample MSE, train set without collinear rows&#39;</span><span class="p">,</span><span class="n">mse_in_elim</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>in-sample MSE, train set without collinear rows 24.553868836373788
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Getting a MSE of around 24 makes sense when we look at the values of the dependent variable y_train, the last column in the full training dataset, as their mean is around 20 and the data points range from 7 to the largest outlier being 50. Moreover, a larger in-sample MSE having removed the collinear rows suggests a reduction in overfitting, so we will proceed to work with the removed columns.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As a plus, compute the condition numbers of the matrices with collinear columns and without collinear columns:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_cond</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;not eliminated&#39;</span><span class="p">,</span><span class="n">X_cond</span><span class="p">)</span>
<span class="n">X_cond_e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">X_train_elim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eliminated&#39;</span><span class="p">,</span><span class="n">X_cond_e</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>not eliminated 1.5685751557079054e+16
eliminated 6.094416963408895
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now clearly see that the condition number of the training data with collinear columns is much larger. This shows that the taking the inverse $(X^T X)^{-1}$  which is needed in the solution for the beta terms in linear regression will result in larger variance.</p>
<p>We will explicitly check that when we evaluate whether the elimination reduces the out-of-sample error in the next subsection.</p>
<p>Now, check whether we can get a smaller error by standardising the data.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># function to standardize X_train_elim and X_test_elim</span>
<span class="k">def</span> <span class="nf">standardise</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="k">return</span> <span class="n">X_std</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># standardise the data separately</span>
<span class="n">X_train_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_train_elim</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># delete the first column not to get nan</span>
<span class="n">X_test_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_test_elim</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># delete the first column not to get nan</span>
<span class="n">X_train_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">)</span>
<span class="n">X_test_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_test_st</span><span class="p">)</span>
<span class="c1"># concatenate the first column back to capture the beta0</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_train_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">X_train_st</span><span class="p">))</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_st</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_test_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">X_test_st</span><span class="p">))</span>

<span class="n">y_train_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get maximum likelihood estimate - parameters of the model</span>
<span class="n">beta_st</span> <span class="o">=</span> <span class="n">max_lik_estimate</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">,</span><span class="n">y_train_st</span><span class="p">)</span>
<span class="c1"># print(&#39;parameters beta, standardised data:\n&#39;,beta_st)</span>
<span class="c1"># in-sample mean squared error (MSE)</span>
<span class="n">in_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">,</span> <span class="n">beta_st</span><span class="p">)</span>
<span class="n">mse_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train_st</span><span class="p">,</span><span class="n">in_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;in-sample MSE for training set&#39;</span><span class="p">,</span><span class="n">mse_in</span><span class="p">)</span>

<span class="c1"># make a prediction using the MLE</span>
<span class="n">out_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test_st</span><span class="p">,</span> <span class="n">beta_st</span><span class="p">)</span>
<span class="c1"># out-sample mean squared error (MSE)</span>
<span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test_st</span><span class="p">,</span><span class="n">out_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE for test set&#39;</span><span class="p">,</span><span class="n">mse_out</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>in-sample MSE for training set 0.273472927326193
out-of-sample MSE for test set 0.3380837473894245
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># standardise the train data X and y TOGETHER</span>
<span class="n">arr_train_st</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">arr_train_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_train_st</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># delete the first column not to get nan</span>
<span class="n">arr_train_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">arr_train_st</span><span class="p">)</span>
<span class="c1"># concatenate the first column back to capture the beta0</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">arr_train_st</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
<span class="n">arr_train_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">arr_train_st</span><span class="p">))</span>

<span class="n">X_train_st</span> <span class="o">=</span> <span class="n">arr_train_st</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_train_st</span> <span class="o">=</span> <span class="n">arr_train_st</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># get maximum likelihood estimate - parameters of the model</span>
<span class="n">beta_st</span> <span class="o">=</span> <span class="n">max_lik_estimate</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">,</span><span class="n">y_train_st</span><span class="p">)</span>
<span class="c1"># print(&#39;parameters beta, standardised data:\n&#39;,beta_st)</span>
<span class="c1"># in-sample mean squared error (MSE)</span>
<span class="n">in_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train_st</span><span class="p">,</span> <span class="n">beta_st</span><span class="p">)</span>
<span class="n">mse_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train_st</span><span class="p">,</span><span class="n">in_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mse_in</span><span class="p">)</span>


<span class="c1"># standardise the test data X and y TOGETHER</span>
<span class="n">arr_test_st</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">arr_test_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_test_st</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># delete the first column not to get nan</span>
<span class="n">arr_test_st</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">arr_test_st</span><span class="p">)</span>
<span class="c1"># concatenate the first column back to capture the beta0</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">arr_test_st</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
<span class="n">arr_test_st</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">arr_test_st</span><span class="p">))</span>

<span class="n">X_test_st</span> <span class="o">=</span> <span class="n">arr_test_st</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_st</span> <span class="o">=</span> <span class="n">arr_test_st</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># make a prediction using the MLE</span>
<span class="n">out_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test_st</span><span class="p">,</span> <span class="n">beta_st</span><span class="p">)</span>
<span class="c1"># out-sample mean squared error (MSE)</span>
<span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test_st</span><span class="p">,</span><span class="n">out_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE for test set with collinear columns&#39;</span><span class="p">,</span><span class="n">mse_out</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>0.2714166676017768
out-of-sample MSE for test set with collinear columns 0.340311020497055
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="1.1.2.">1.1.2.<a class="anchor-link" href="#1.1.2.">&#182;</a></h5><p>In this subsection, we will use the test data to test the model to predict the target variable, compute the out-of-sample MSE on the test set. We will then compare to the in-sample MSE and explain the differences.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># make a prediction using the MLE</span>
<span class="n">out_pred</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_ml</span><span class="p">)</span>
<span class="c1"># out-sample mean squared error (MSE)</span>
<span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">out_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE for test set with collinear columns&#39;</span><span class="p">,</span><span class="n">mse_out</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>out-of-sample MSE for test set with collinear columns 19.557330193706065
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># out-sample MSE, eliminated colinear columns</span>
<span class="n">out_pred_elim</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test_elim</span><span class="p">,</span> <span class="n">beta_ml_elim</span><span class="p">)</span>
<span class="n">mse_out_elim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">out_pred_elim</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE for test set, eliminated collinear columns:&#39;</span><span class="p">,</span><span class="n">mse_out_elim</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>out-of-sample MSE for test set, eliminated collinear columns: 19.360481532901694
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The first observation is that the out-of-sample MSE for both matrices is smaller than the in-sample MSE. This is arguably because we have less rows in the test set than the train set and the model works better.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Moreover, we know that collinearity produces overfitting and we see that indeed for the train and test sets with all columns (some of which are collinear), we have a smaller in-sample MSE and a larger out-of-sample MSE than for the train and test sets where we eliminate the collinear columns. This shows that the model trained with collinear columns tends to overfit and has errors due to the large condition number of the training matrix. It is also nicer because in addition to getting more accurate predictions, we have less data to train on - the computations are faster.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="1.2-Ridge-Regression">1.2 Ridge Regression<a class="anchor-link" href="#1.2-Ridge-Regression">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Report the values of the penalty parameter obtained for the five folds.</p>
<p>We start by eliminating the collinear columns as we have seen they produce better results in the previous part (less overfitting).</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># eliminate collinear columns for good</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of X_train before elimination&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of X_test before elimination&#39;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of X_train after elimination&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of X_test after elimination&#39;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Shape of X_train before elimination (404, 18)
Shape of X_test before elimination (102, 18)
Shape of X_train after elimination (404, 12)
Shape of X_test after elimination (102, 12)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define the function that computes maximum likelihood parameters.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ridge_estimate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">penalty</span><span class="p">):</span>
    <span class="c1"># X: N x D matrix of training inputs</span>
    <span class="c1"># y: N x 1 vector of training targets/observations</span>
    <span class="c1"># returns: maximum likelihood parameters (D x 1)</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">beta_ridge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">penalty</span> <span class="o">*</span> <span class="n">I</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">beta_ridge</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define the functions that will allow us to do the splitting into folds and evaluate the model.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">):</span>
    <span class="n">fold_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_folds</span><span class="p">)</span>
    <span class="n">data_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1007</span><span class="p">)</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># set the seed to always have the same random permutations</span>
    <span class="n">folds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_folds</span><span class="p">):</span>
        <span class="n">folds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_perm</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">fold_size</span><span class="p">:(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">fold_size</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">return</span> <span class="n">folds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">penalty_term</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>  <span class="c1"># the y_test needs to be shuffled the same as the folds</span>
  
    <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>
    
    <span class="c1"># define this list for each penalty term, it collects the 5 MSEs</span>
    <span class="n">val_mses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_mses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
        <span class="c1"># define the training set</span>
        <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
        <span class="c1"># define the validation set</span>
        <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># train on all folds except k with penalty p - get beta_ridge</span>
        <span class="n">beta_ridge</span> <span class="o">=</span> <span class="n">ridge_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty_term</span><span class="p">)</span>
        
        <span class="c1"># calculate prediction on fold k with penalty p - get ridge_prediction</span>
        <span class="n">ridge_prediction_val</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">beta_ridge</span><span class="p">)</span>
        <span class="c1"># evaluate the MSE on the validation set</span>
        <span class="n">val_mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">ridge_prediction_val</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># append the validation MSE to the list containing the MSEs for each fold</span>
        <span class="n">val_mses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_mse</span><span class="p">)</span>
        
        <span class="c1"># calculate prediction for test set, evaluate the MSE on the test set</span>
        <span class="n">ridge_prediction_test</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_ridge</span><span class="p">)</span>
        <span class="n">test_mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ridge_prediction_test</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">test_mses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)</span> <span class="c1"># append</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_mses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_mses</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">404</span><span class="p">))</span><span class="o">+</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># stack the X and y train together so that permutation does not violate the correspondence of the predictors and outcome</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">data1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># y_test = (np.zeros((1,102))+y_test).T</span>
<span class="c1"># data_test = np.hstack((X_test,y_test))  </span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>(404, 12)
(404,)
(404, 1)
(404, 13)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Scan over penalty parameters, save the validation MSEs in a matrix with rows corresponding to each candidate parameter, and 5 columns corresponding to each of the 5 validation folds. The number of columns is therefore 5 in our case.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># candidate penalty terms</span>
<span class="n">p_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">ERR_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">p_term</span><span class="p">),</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ERR_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">p_term</span><span class="p">),</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># shuffle the data (X and y stacked together)</span>
<span class="n">data_ridge</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_ridge</span><span class="p">)</span>


<span class="c1"># fill the MSE matrix</span>
<span class="n">p_i</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_term</span><span class="p">:</span>
    <span class="n">val_mses</span><span class="p">,</span> <span class="n">test_mses</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_ridge</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="n">ERR_val</span><span class="p">[</span><span class="n">p_i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">val_mses</span>
    <span class="n">ERR_test</span><span class="p">[</span><span class="n">p_i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">test_mses</span>
    <span class="n">p_i</span><span class="o">+=</span><span class="mi">1</span>
        
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of the matrix containing the MSEs for each fold for each candidate penalty term&#39;</span><span class="p">,</span><span class="n">ERR_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Shape of the matrix containing the MSEs for each fold for each candidate penalty term (2800, 5)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Get optimal penalty terms, plot for the first fold</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[469]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_optimal_penalty</span><span class="p">(</span><span class="n">ERR</span><span class="p">,</span><span class="n">p_term</span><span class="p">,</span><span class="n">val_fold_index</span><span class="p">):</span>    
    <span class="n">mse_fold</span> <span class="o">=</span> <span class="n">ERR</span><span class="p">[:,</span><span class="n">val_fold_index</span><span class="p">]</span>
    
    <span class="n">minp1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">mse_fold</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Minimal value of validation MSE, fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">val_fold_index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">minp1</span><span class="p">)</span>
    
    <span class="n">opt_p</span> <span class="o">=</span> <span class="n">p_term</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_fold</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal penalty term validation fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">val_fold_index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">opt_p</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">val_fold_index</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_term</span><span class="p">,</span><span class="n">mse_fold</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;search for penalty term that minimises the MSE, validation fold 1&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate penalty terms&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">opt_p</span>

<span class="n">p_optimal</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">get_optimal_penalty</span><span class="p">(</span><span class="n">ERR_val</span><span class="p">,</span><span class="n">p_term</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
    <span class="n">p_optimal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal penalty parameter for each 5-fold&#39;</span><span class="p">,</span><span class="n">p_optimal</span><span class="p">)</span>
    
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Minimal value of validation MSE, fold 1: 32.17310161113137
Optimal penalty term validation fold 1: 0.0 

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Minimal value of validation MSE, fold 2: 11.773948995352871
Optimal penalty term validation fold 2: 13.030000000000001 

Minimal value of validation MSE, fold 3: 18.78405850427335
Optimal penalty term validation fold 3: 11.01 

Minimal value of validation MSE, fold 4: 33.87176873784628
Optimal penalty term validation fold 4: 0.0 

Minimal value of validation MSE, fold 5: 25.420508858164368
Optimal penalty term validation fold 5: 1.67 

Optimal penalty parameter for each 5-fold [0.0, 13.030000000000001, 11.01, 0.0, 1.67]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="1.2.2.">1.2.2.<a class="anchor-link" href="#1.2.2.">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Compute average in-sample MSE (using validation MSE):</p>
<p>1) Compute the MSE of each validation fold for each candidate penalty term</p>
<p>2) Take the average of these MSEs to get the average MSE for the specific candidate penalty term</p>
<p>3) Choose the optimal penalty where the average MSE is minimum across all candidate penalty terms</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[470]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate the average validation MSE over the 5 folds for each candidate penalty term</span>
<span class="n">mse_avg_val</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">ERR_val</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># find the optimal penalty term to get the smallest average MSE over the 5 folds</span>
<span class="n">minp_in</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">mse_avg_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average in-sample validation MSE over 5 folds</span><span class="se">\n\n</span><span class="s1">Minimum value of validation MSE&#39;</span><span class="p">,</span><span class="n">minp_in</span><span class="p">)</span>
<span class="c1"># print(&#39;\nminimum at index&#39;,np.argmin(mse_avg))</span>
<span class="n">p_opt</span> <span class="o">=</span> <span class="n">p_term</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_avg_val</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Optimal penalty term&#39;</span><span class="p">,</span><span class="n">p_opt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_term</span><span class="p">,</span><span class="n">mse_avg_val</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;search for optimal penalty term with validation MSE, 5 fold avg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate penalty terms&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Average in-sample validation MSE over 5 folds

Minimum value of validation MSE 24.754479641205048

Optimal penalty term 0.39
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Compute the out-of-sample MSE with this optimal penalty term that we got from the evaluation of the average in-sample MSE:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[471]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train the model with this &#39;optimal&#39; training parameter</span>
<span class="n">beta_ridge1</span> <span class="o">=</span> <span class="n">ridge_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">p_opt</span><span class="p">)</span>
<span class="c1"># calculate prediction on training set</span>
<span class="n">ridge_prediction1</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta_ridge1</span><span class="p">)</span>
<span class="c1"># evaluate the MSE on the train set</span>
<span class="n">in_mse1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">ridge_prediction1</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_mse1</span><span class="p">)</span>


<span class="c1"># train the model with this &#39;optimal&#39; training parameter</span>
<span class="n">beta_ridge2</span> <span class="o">=</span> <span class="n">ridge_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">p_opt</span><span class="p">)</span>
<span class="c1"># calculate prediction on test set</span>
<span class="n">ridge_prediction2</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_ridge1</span><span class="p">)</span>
<span class="c1"># evaluate the MSE on the test set</span>
<span class="n">in_mse2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ridge_prediction2</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_mse2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>24.55442531773087
107.60476132137794
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Compute average out-of-sample MSE using the test set, averaged over the 5 folds:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[472]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate the average test MSE over the 5 folds for each candidate penalty term</span>
<span class="n">mse_avg_test</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">ERR_test</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># find the optimal penalty term to get the smallest average MSE over the 5 folds</span>
<span class="n">minp_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">mse_avg_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average out-of-sample MSE over 5 folds:</span><span class="se">\n\n</span><span class="s1">Minimum value of test MSE&#39;</span><span class="p">,</span><span class="n">minp_out</span><span class="p">)</span>
<span class="c1"># print(&#39;\nminimum at index&#39;,np.argmin(mse_avg))</span>
<span class="n">p_opt1</span> <span class="o">=</span> <span class="n">p_term</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_avg_test</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Optimal penalty term&#39;</span><span class="p">,</span><span class="n">p_opt1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_term</span><span class="p">,</span><span class="n">mse_avg_test</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;search for optimal penalty term with test MSE, 5 fold avg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate penalty terms&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Average out-of-sample MSE over 5 folds:

Minimum value of test MSE 19.17294737005144

Optimal penalty term 0.3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[473]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train the model with this &#39;optimal&#39; training parameter</span>
<span class="n">beta_ridge1</span> <span class="o">=</span> <span class="n">ridge_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">p_opt1</span><span class="p">)</span>
<span class="c1"># calculate prediction on training set</span>
<span class="n">ridge_prediction1</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta_ridge1</span><span class="p">)</span>
<span class="c1"># evaluate the MSE on the train set</span>
<span class="n">in_mse1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">ridge_prediction1</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_mse1</span><span class="p">)</span>


<span class="c1"># calculate prediction on test set</span>
<span class="n">ridge_prediction2</span> <span class="o">=</span> <span class="n">predict_with_estimate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_ridge1</span><span class="p">)</span>
<span class="c1"># evaluate the MSE on the test set</span>
<span class="n">in_mse2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ridge_prediction2</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_mse2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>24.554198350978666
107.61118556684289
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Comparison with the linear regression MSE values:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[482]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># in-sample MSE (averaged over the 5-fold validation sets from X_train)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average in-sample MSE over the 5 folds (y_validation-y_pred):&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal penalty term:&#39;</span><span class="p">,</span><span class="n">p_opt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">in-sample MSE Ridge regression&#39;</span><span class="p">,</span><span class="n">minp_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;in-sample MSE linear regression&#39;</span><span class="p">,</span><span class="n">mse_in_elim</span><span class="p">)</span>


<span class="c1"># out-of-sample MSE (with test set X_test, y_test)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Average out-of-sample MSE over the 5 folds (y_test-y_pred):&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal penalty term:&#39;</span><span class="p">,</span><span class="n">p_opt1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">out-of-sample MSE Ridge regression&#39;</span><span class="p">,</span><span class="n">minp_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE linear regression&#39;</span><span class="p">,</span><span class="n">mse_out_elim</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Average in-sample MSE over the 5 folds (y_validation-y_pred):
optimal penalty term: 0.39

in-sample MSE Ridge regression 24.754479641205048
in-sample MSE linear regression 24.553868836373788

Average out-of-sample MSE over the 5 folds (y_test-y_pred):
optimal penalty term: 0.3

out-of-sample MSE Ridge regression 19.17294737005144
out-of-sample MSE linear regression 19.360481532901694
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>In-sample: using Ridge regression, we get a larger in-sample MSE than linear regression in part 1.1.2.</p>
<p>Out-of-sample: using Ridge regression, we get a slightly smaller out-of-sample MSE than linear regression in part 1.1.2.</p>
<p>This clearly shows that Ridge regression indeed reduces overfitting that we get with linear regression. This is because compared to linear regression, Ridge is a bit worse (larger MSE) for the train set and, crucially, performs better on an unseen test set (smaller MSE). However, even though it is an improvement, it is not as significant as we would expect.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="1.3-Regression-with-kNN">1.3 Regression with kNN<a class="anchor-link" href="#1.3-Regression-with-kNN">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="1.3.1.">1.3.1.<a class="anchor-link" href="#1.3.1.">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Recall that the dataset we are using has the collinear columns eliminated so as to reduce overfitting - this is also valid for kNN because when we have collinear predictors (columns), the values in the predictor are close to each other and this will lead to smaller k values, which implies overfitting.</p>
<p>First, we define the functions we will use to implement the kNN algorithm.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">euclidian_distance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span><span class="o">-</span><span class="n">q</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">k_neighbours</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_train_stack</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">return_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="n">n_neighbours</span> <span class="o">=</span> <span class="n">k</span>
  <span class="n">dist</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">neigh_ind</span> <span class="o">=</span> <span class="p">[]</span>
  
  <span class="c1"># compute distance from each point x_text in X_test to all points in X_train (hint: use python&#39;s list comprehension)</span>
  <span class="n">point_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">euclidian_distance</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">X_train_stack</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_test</span> <span class="ow">in</span> <span class="n">X_test</span><span class="p">]</span>

  <span class="c1"># determine which k training points are closest to each test point</span>
  <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">point_dist</span><span class="p">:</span>
      <span class="n">enum_neigh</span> <span class="o">=</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
      <span class="n">sorted_neigh</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">enum_neigh</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[:</span><span class="n">k</span><span class="p">]</span>

      <span class="n">ind_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="n">sorted_neigh</span><span class="p">]</span>
      <span class="n">dist_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="n">sorted_neigh</span><span class="p">]</span>

      <span class="n">dist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist_list</span><span class="p">)</span>
      <span class="n">neigh_ind</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind_list</span><span class="p">)</span>
  
  <span class="c1"># return distances together with indices of k nearest neighbouts</span>
  <span class="k">if</span> <span class="n">return_distance</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dist</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">neigh_ind</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">neigh_ind</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">reg_predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_train_stack</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="c1"># each of the k neighbours contributes equally to the classification of any data point in X_test  </span>
  <span class="n">neighbours</span> <span class="o">=</span> <span class="n">k_neighbours</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_train_stack</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="c1"># compute mean over neighbours labels (hint: use python&#39;s list comprehension)</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">neighbour</span><span class="p">])</span> <span class="k">for</span> <span class="n">neighbour</span> <span class="ow">in</span> <span class="n">neighbours</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">y_pred</span>


<span class="k">def</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">y_avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
  <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_avg</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>In the cross-validation, we save the R2 error, the average in-sample and out-of-sample MSEs in matrices of the same form as in the CV for Ridge regression. The rows represent the candidate parameters, and the columns represent the folds over which we train the training data for that candidate parameter.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>  <span class="c1"># candidate k&#39;s</span>

<span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">):</span>
  
    <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>
    <span class="n">k_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>  <span class="c1"># candidate k&#39;s</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate ks:&#39;</span><span class="p">,</span><span class="n">k_arr</span><span class="p">)</span>

    <span class="n">R2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">k_arr</span><span class="p">),</span><span class="mi">5</span><span class="p">))</span>  <span class="c1"># matrix to contain the r2 scores</span>
    <span class="n">ERR_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">k_arr</span><span class="p">),</span><span class="mi">5</span><span class="p">))</span>  <span class="c1"># to contain the validation MSEs</span>
    <span class="n">ERR_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">k_arr</span><span class="p">),</span><span class="mi">5</span><span class="p">))</span> <span class="c1"># for out-of-sample MSEs</span>
    
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
<span class="c1">#         print(&#39;Fold&#39;, i+1)</span>
        <span class="c1"># define the training set</span>
        <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
        <span class="c1"># define the validation set</span>
        <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># iterate through the k&#39;s</span>
        <span class="n">j</span><span class="o">=</span><span class="mi">0</span>  <span class="c1"># row index for each candidate k</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_arr</span><span class="p">:</span>
            <span class="c1"># predict on validation set</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg_predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>  <span class="c1"># get prediction for knn-neighbors for train set without fold i</span>
            <span class="c1"># R2 score</span>
            <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  <span class="c1"># calculate the r2 score for knn-neighbors for fold i as validation set </span>
            <span class="n">R2</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2</span>
            <span class="c1"># validation MSE in-sample</span>
            <span class="n">mse_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">ERR_in</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mse_in</span>
            
            <span class="c1"># predict on the test set, out-of-sample</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg_predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">ERR_out</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mse_out</span>            
            <span class="n">j</span><span class="o">+=</span><span class="mi">1</span>
            
    <span class="k">return</span> <span class="n">R2</span><span class="p">,</span> <span class="n">ERR_in</span><span class="p">,</span> <span class="n">ERR_out</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># shuffle the data (X and y stacked together)</span>
<span class="n">data_perm</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_perm</span><span class="p">)</span>

<span class="n">R2</span><span class="p">,</span> <span class="n">ERR_in</span><span class="p">,</span> <span class="n">ERR_out</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_perm</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>candidate ks: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check the sizes of the matrices</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of the matrix containing the errors (R2 scores)&#39;</span><span class="p">,</span><span class="n">R2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of the matrix containing the in-sample MSEs for each fold for each candidate k&#39;</span><span class="p">,</span><span class="n">ERR_in</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of out-of sample MSEs&#39;</span><span class="p">,</span><span class="n">ERR_out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Shape of the matrix containing the errors (R2 scores) (19, 5)
Shape of the matrix containing the in-sample MSEs for each fold for each candidate k (19, 5)
Shape of out-of sample MSEs (19, 5)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We plot the three kinds of errors: R2 score, in-sample average MSE and out-of-sample average MSE over all 5 folds to see their behaviour</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plot the R2 scores for each fold</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">R2</span><span class="p">[:,</span><span class="n">j</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R2 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;R2 scores calculated over all 5 folds for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># plot the validation MSE for each fold</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">ERR_in</span><span class="p">[:,</span><span class="n">j</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;validation MSE calculated over all 5 folds for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">ERR_out</span><span class="p">[:,</span><span class="n">j</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;out-of-sample MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;MSE calculated with y_test over all 5 folds for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABpnUlEQVR4nO2dd3gVVfrHP2967wnpoffeiwULigr2sipYULCsbVd/q6trX11XXV1dXTuKFbEr9hVRASmh9xpI773fcn5/zAQuIeUm5OYmcD7PM8/MnTlzzjsz5853TnuPKKXQaDQajaaj8XC3ARqNRqM5NtECo9FoNBqXoAVGo9FoNC5BC4xGo9FoXIIWGI1Go9G4BC0wGo1Go3EJbhMYEZkqIpkOv7eKyFRnwrYjrZdF5P72nn8sICLXiMiyDohnv4ic3hE2OZHWWyLy985Iq6NoIl932P0SkQtEJENEKkVkVCthW7x3IqJEpG87bPi7iBSKSG5bz3UXItLTvF4v8/e3InK1M2FdbNdRvdfakM5SEbne1ek0RZcpwSilhiillh5tPE29SJVSNyqlHj3auJtI6yEzM97WaP8d5v6HHPbdKyJp5sshU0Q+dDi2VERqzWMNy1cdbW9n096X2PGCmX8sjZ577xZOeRq4RSkVpJRa31l2NiAiScCdwGClVGxnp99RKKXOUkotONp4OksgujNdRmC6MbuAxl9DV5n7ATC/lmYDpyulgoCxwE+Nzml4cTQsM11ptMY5RMTTxUl82Oi572shbAqw1cX2tEQKUKSUym/riZ1RItB0PY5KYETkHhH5uNG+50TkeXP7WhHZLiIVIrJPRG5oIa6DVQki4m8W8UtEZBswrol095rxbhORC8z9g4CXgUnm12Cpuf+w6gIRmSsie0SkWES+FJF4h2NKRG4Ukd1m+i+KiLRwG9YAASIyxDx/COBv7m9gHPC9UmovgFIqVyn1agtxtohp/3aH6x/d0n1pJo4hIvKjeQ/yRORec3/je9XsV5qIjBeR30WkVERyROQFEfExj/1qBttoPovLzP0zRGSDec4KERnuEN8oEVln2v8h4NeC/R4i8jcROSAi+SLytoiEmse+E5FbGoXfKCIXmtsDHa59p4hc6hDuLRF5SUS+EZEq4JQm0nY6X3cEIuIrIpWAJ8b93GvuHyRG6bdUjCrmc1uI4//MZ5QtInMaHTvbzC8VIpIlInc1cf7pwI9AvPk83zL3n2umXWraMsjhnP0icreIbAKqpAmRaSEfNpu3zOPN/k9FxFNEnhajKm8fcE6jNA9WGTkRtslnLSKBwLcO96NSROLNfNnwPywSkUUiEtHcc2mU1m3mc0hstN/XvA9DHfZFi0iNiMSISLiILBaRAvNeLG4ch8N5D4nIuw6/G1cfhorIG+Y9zxKjStTTPNZXRH4RkTLzfn3YVBqHoZRq94LxRVMNhJi/PYEcYKL5+xygDyDAyWbY0eaxqUCmQ1z7Mb7wAZ4AfgMigCRgS6OwlwDxGAJ5GVAFxJnHrgGWNbLzLeDv5vapQCEwGvAF/gP86hBWAYuBMCAZKACmN3P9DwHvAvcC/zT3PQn81dz/kLlvFlAM/B9G6cWzUTxLgeudvOeXAFkYoiVAXyClLfcFCDaf050YL/FgYELje+XEcxoDTAS8gJ7AduCORveyr8Pv0UA+MMHMK1eb8fkCPsAB4E+AN3AxYHG0pdF9mAPsAXoDQcCnwDvmsauA5Q5hBwOlZjqBQAZwrWn3aDM/DHG4/jJginkf/ZpIu135upn8U2bmja3ATa08+4P307xHezDyng9Gvq4ABjSR56cDecBQ8/rfbxRXDnCiuR3ecC1NpN/42vpj5LFppj1/MW3ycbj2DRj/Yf8m4mspHzqTt5r8nwI3AjvMdCOAn83wXo3/b06EdfpZm/vuAFYCiRj57RXgg9buJ3A/sA6IbibsfOAxh99/BL4ztyOBi4AA8x5+BHze1PsF853lcKxno+v93LQ5EIgBVgM3mMc+AO7D/F8AJ7T6vnLmpdZKpl8GXGVuTwP2thD2c+B2J15c+3B4qQPzGj/IRvFuAM4zt6+hZYF5A3jS4VgQxousp0PGPcHh+CLgnhZeEO9iZPB0jD9ZOkZmPSgwZtgrgf9h/CGLHOM0M0A1xkuwYXm0mTS/b7iHTjybJu8LcDmwvplzDt6r1p5TE+feAXzm8LuxwLzU+LqAnRh/3JOAbEAcjq2geYH5CbjZ4fcA8zl6YfzJqjgkvI8B883ty4DfGsX1CvCgw/W/3cb/wOc4ka+bOG8wxgeBJzAZ42V7eQvpOIrCiUAu4OFw/AMOfdQcfI4YL6cnHML1bxRXOnAD5odiC+k3vrb7gUUOvz0wPn6mOlz7nBbiazYfOpm3mvyfAkuAGx2OnUHzAtNi2LY8a3PfduA0h99xDfmymfuZBTyD8R4NbeH6Twf2OfxejvnebSLsSKDE4bfj9T5EMwID9ADqcPgYMJ/Rz+b228CrQKKz/42OaIN53zQC4ArzNwAicpaIrDSLv6XA2UCUE3HGY3xlNnDA8aCIXCWHqllKMb7MnIm3Ie6D8SmlKjFe+AkOYRx7yFRjiFCzKKXSMb7cHgd2K6UymgjznlLqdIwvrhuBR0TkTIcgtymlwhyW5nq9JQF7mzrQhvvSbBxtQUT6m8XxXBEpx7j+lp5DCnBng32mjUkYzyQeyFJmTjY50EQcDcQ3On4A80+ilKoAvgb+YB77A/Cegw0TGtlwJeDYaH3E83PkKPL1YSiltimlspVSNqXUCuA5jJKbM8QDGUopu8O+Axyejw8L2yicIxdhXMMBswpkUhtscPwv2c10HG1o6V62lJedyVvN/U9bu97G19DSu6atzzoF+Mwhb20HbBgv76YIw/iA/odSqqyFeJcA/iIyQURSMETkM9PGABF5RYzq4nLgVyBM2t5+mILxkZzjYP8rGCUZMEqoAqwWo1p0TtPRHKIjBOYjYKpZ53cBpsCIiC/wCUbPlx5KqTDgG9PA1sjByHwNJDdsmDf3NeAWINKMd4tDvI4vqKbIxriRDfEFYhQxs5ywqyXexijqv91SIKWURSn1EbAJQwDaSgZGkf0wnLgvrcZhUoVR1G6gpd5CL2FUL/RTSoVgVNe09HwzMIr5jkIaoJT6AOOZJzTUo5skNx0N0Og5mmGtGFVBYHzNX26+LP0xqj4abPilkQ1BSqmbHOJqNg8dZb5uDdWGeLKBJBFx/A8n03Q+bvb/BKCUWqOUOg/jRfI5RmnAWRsc/0tipuNoQ0v/x5byYVvzliMtXq+zYZ141k1dWwZwVqP85aeUau79UgLMAN4UkSnNGWmK9yKMj/krgMXmhxQY750BGNWLIRi1AdD0/Wrp/52BUYKJcrA9RCk1xLQhVyk1VykVj1Hi/a+00kv0qAVGKVWAUQR7E0hTSm03D/lg1EEWAFYROQuj+OkMi4C/mo1XicCtDscCMR5sARiNcBz+os4DEsWhQbAR7wPXishIMwM9DqxSSu130rbm+BDj+o74c4rRdfocEQk2GwHPAoYAq9qRzuvAXSIyRgz6muLS2n1xZDEQK0Z3al/TrgnmsQ3A2SISISKxGFUTzREMlAOVIjIQuKnR8TyMNpIGXgNuNL/CREQCG+4L8DuGQNwmIl5iNMiPbyHtD4A/iUgvEQnCeI4fKqWs5vFvMF5+j5j7G770FwP9RWS2iHibyzhxaJxuhaPJ14chIueZeVxEZDxwG/CFk6evwnhZ/MW8hqnATGBhE2EXAdeIyGARCQAedLDBR0SuFJFQpZQF43nanLRhEXCOiJwmIt4YL7o6jKpNZ2gpH7aWt1qz6zYRSRSRcOCedoZt7VnnAZFidi4xeRl4zPxPNjTGn9eSscoYnnElRslnQgtB38eo4r0Sh5oijHtVA5SK0aHgwSbObWADcJKIJJt2/9XBjhzgB+BfIhJivqv6iMjJ5rVcIoc6D5RgvG9azCsd1U35fYw6woMXbarrbRgPsARDdb90Mr6HMYqqaRgX/I5DvNuAf2G8kPKAYRj1kQ0swWgwzRWRwsYRK6V+wqg7/gTj66UPh6pS2o1SqkYp9T+lVE0Th8sxvsDSMdpXnsRo0HUcr/OCHD4eYm0z6XyE0abwPkaj7udAhBP3xTGOCoz2spkY1Qy7OdRb6h1gI0b9+Q8Ywtkcd2E81woM8Wgc9iFggVncvlQplQrMBV7AyBN7MNqGUErVAxeav0sw/kiftpD2fNPWXzHySS0OHyJKqTrz/Kby5RkYzzzbvP5/YrxIWuUo83Vj/oBxDyowSr7/VE6OzzDv17nAWRidFP6LUSe/o4mw3wL/xvhv7DHXjswG9pvVKzdidEpxxoadZtj/mDbMBGaatjlzfkv5sLW81RKvYbRVbsRoOG8pHzUbtrVnbd7rD4B9Zh6Px6jm/BL4QUQqMBr8WxKNhrh+xOh48qWIjGkmTMNHRTxGD7YG/o1RSi800/uulXQ+xKhBWYsh8o5chSGs28xr/hijHQmMjkWrxOjR+CVGW1RaS9clh1d5azQajUbTMeiBlhqNRqNxCVpgNBqNRuMStMBoNBqNxiVogdFoNBqNS+gWDuiioqJUz5493W2GRqPRdCvWrl1bqJSKdlf63UJgevbsSWpqqrvN0Gg0mm6FiLTkxcDl6CoyjUaj0bgELTAajUajcQkuFxgx5ltYLyKLzd8RYsz/sNtch7vaBo1Go9F0Pp3RBnM7hkfREPP3PcBPSqknROQe8/fdbY3UYrGQmZlJbW1tx1naTfDz8yMxMRFvb293m6LRaDTN4lKBMR2jnYPhO+vP5u7zMOZBAFiA4SizzQKTmZlJcHAwPXv2RFqccPLYQilFUVERmZmZ9OrVy93maDQaTbO4uors3xhzCDjOWdHD9NrZ4L0zponzWqW2tpbIyMjjSlwARITIyMjjsuSm0Wi6Fy4TGBGZAeQrpZr0CuzE+fNEJFVEUgsKCpoLczQmdluO1+vWaDTdC1dWkU0BzhWRszHmbw4RkXeBPBGJU0rliEgcxhztR6CUehVjek7Gjh2rXT5rNJpjFqUUlXVWCivrKayso6CijsLKOgor6rhoTCIpkYHuNrFduExglFJ/xZzMxpwM6S6l1CwReQq4GnjCXDs7wVKX4/nnn+ell15i9OjRvPfee02Geeutt0hNTeWFF1444lhQUBCVlZVH7J8zZw6LFy8mJiaGLVu2dLjdGo3G9bQkGgWVdRRUGPsbjtVZ7UfE4SEwKjlcC0wbeAJYJCLXYUzAdYkbbOgQ/vvf//Ltt992eGP7Nddcwy233MJVV13VofFqNBrXUWuxsTGjlDX7i1m9v4T1B0qoqLMeEU4EIgN9iAryJTrYl15RgUQF+RAd7EtUkO/B/VFBvkQE+uDp0X2rxDtFYMwpQZea20XAaZ2Rriu58cYb2bdvH+eeey5z5szh6quvZs6cOezbt4+AgABeffVVhg8fftg5aWlpXHHFFVitVqZPn95s3CeddBL79+938RVoNJqjobLOytoDJaxOK2JNWgkbMkqptxmlkAE9gpk5Mp6UiABDNIJ9iQ7yJSrYh4gAH7w8j48x7t3CF1lrPPzVVrZll3donIPjQ3hw5pBmj7/88st89913/Pzzz0RFRXHrrbcyatQoPv/8c5YsWcJVV13Fhg0bDjvn9ttv56abbuKqq67ixRdf7FB7NRqNaymqrGPN/hJWpxWzZn8xW7PLsCvw9BCGJoRy9eQUxveKZGxKOOGBPu42t0twTAhMV2DZsmV88sknAJx66qkUFRVRVlZ2WJjly5cfDDN79mzuvrvNw380Gk0nkVVaw+q0IlanlbBmfzF78o32Ul8vD0Ylh3HLqf0Y3zOCUclhBPrqV2lTHBN3paWSRmeh1JEd3ZrqTqy7GGs0XQ+7XbGnoJLVacWk7i9mzf4SskprAAj282JsSjgXjU5kfK9whiWE4eN1fFRxHS3HhMB0BU466STee+897r//fpYuXUpUVBQhISGHhZkyZQoLFy5k1qxZzfY602g0rqfOamNLVhlr9pewJq2Y1AMllNVYAIgO9mVcz3DmntiLcb0iGBgb0q0b2t2JFpgO4qGHHuLaa69l+PDhBAQEsGDBgiPCPPfcc1xxxRU899xzXHTRRc3Gdfnll7N06VIKCwtJTEzk4Ycf5rrrrnOl+RrNMU15rYV1B4yqrjX7S9iYUXqwW3Dv6EDOGhrL2J4RjOsZTnJEgK5p6CCkqaqdrsbYsWNV4wnHtm/fzqBBg9xkkfs53q9fo2mJvPLaw6q7duSWH9YgPy4l/KCgRAb5uttclyEia5VSY92Vvi7BaDSabk+d1caqfcUs2ZHP0p357C+qBiDAx5PRyeHcdprRID8yOYwAH/3a6yz0ndZoNN2SvPJaft6Rz5Id+SzbU0h1vQ1fLw+m9I1i9qSejOsZzuC4kONmzElXRAuMRqPpFtjsio2ZpQdFZas59i0hzJ8LRydw6sAYJvWOwt/H082WahrQAqPRaLosZTUWfttdwJId+fyys4Ciqno8BMakhPOX6QM4bWAP+vcI0o3yXRQtMBqNpsuglGJvQSVLzFJK6v4SrHZFWIA3U/tHc8rAGE7uH01YgB4p3x3QAqPRaI4Km12xbE8hH6/NJK2wErsd7EqZi7ltb2bbIYzNbizV9TYABsYGM++k3pw6MIZRyeF6LEo3RAvMUeAKd/0ZGRlcddVV5Obm4uHhwbx587j99ttdYr9GczRkFFfz0dpMPk7NILuslrAAb0YlheHp4YGHgIcInh6CmNseAh4ecnDbOGZuS8O20Ds6kFMGxpAQ5u/uS9QcJVpgjgJXuOv38vLiX//6F6NHj6aiooIxY8Ywbdo0Bg8e3GFpaDTtpdZi4/utuXyUmsnyvYUAnNA3invPGcS0wT3w9dIN7JpDaIFpJ65y1x8XF0dcXBwAwcHBDBo0iKysLC0wGreyNbuMRWsy+HxDNmU1FhLC/Ln9tH5cPCaRxPAAd5un6aIcGwLz7T2Qu7lj44wdBmc90ezhznDXv3//ftavX8+ECROO9mo0mjZTVmPhyw1ZfJiawZascnw8PThzaCyXjU1icp9IPHSbiKYVjg2B6QJ0tLv+yspKLrroIv79738f4TRTo3EVdrtiZVoRi9Zk8O2WXOqsdgbFhfDQzMGcPypB997StIljQ2BaKGl0Fh3prt9isXDRRRdx5ZVXcuGFF3aIfRpNSxRW1rFwdTqLUjNJL64m2M+LS8cmcenYJIYmhOhxJpp24TIfCiLiJyKrRWSjiGwVkYfN/Q+JSJaIbDCXs11lQ2fS4K4faNVdP9BsrzOlFNdddx2DBg3iz3/+s2uN1mgw2lfOef43nv5hFwlh/vz7spGsue90Hj1/KMMSQ7W4aNqNK0swdcCpSqlKEfEGlonIt+axZ5VST7sw7U6no9z1L1++nHfeeYdhw4YxcuRIAB5//HHOPvuY0GFNF+OXXQXc/O5aQvy9WXzrCQxNCHW3SZpjiE5x1y8iAcAy4CbgLKCyLQKj3fUfyfF+/Zqj58M16dz72Rb6xQTx1rXjiQ31c7dJmg7G3e76XepmVEQ8RWQDkA/8qJRaZR66RUQ2ich8EQlv5tx5IpIqIqkFBQWuNFOjOa5QSvHMDzu5+5PNTO4TyUc3TtLionEJLhUYpZRNKTUSSATGi8hQ4CWgDzASyAH+1cy5ryqlxiqlxkZHR7vSTI3muKHeaufOjzby/JI9XDImkfnXjCPYz9vdZmmOUTplogSlVCmwFJiulMozhccOvAaM7wwbNJrjnfJaC3PeWsOn67K44/R+PHnxcLz1XCkaF+LKXmTRIhJmbvsDpwM7RCTOIdgFwBZX2aDRaAxyymq49OXfWbmviKcuHs4dp/fXvcM0LseVvcjigAUi4okhZIuUUotF5B0RGQkoYD9wgwtt0GiOe7bnlHPtm2uorLPy5rXjOLGfrnLWdA4uExil1CZgVBP7Z7sqTY1Gczi/7S7gpnfXEeTrxUc3TmJQnPYKoek8dAXsUfD8888zaNAgrrzyymbDvPXWW9xyyy1NHgsKCjpiX21tLePHj2fEiBEMGTKEBx98sMPs1RxffJSawbVvriEx3J/P/jhZi4um0zk2XMW4CVe46/f19WXJkiUEBQVhsVg44YQTOOuss5g4cWKHpaE5tlFK8fxPe3j2f7uY0jeSl2aNIUT3FNO4AV2CaSeO7vqfffZZiouLOf/88xk+fDgTJ05k06ZNR5yTlpbGpEmTGDduHPfff3+T8YrIwZKNxWLBYrHoxliN01hsdv7y8Sae/d8uLhqdyJvXjNfionEbx0QJ5p+r/8mO4h0dGufAiIHcPb55b8eudNdvs9kYM2YMe/bs4Y9//KN2169xiopaCze/t47fdhdy22n9+NPp/fTHicat6BJMB7Fs2TJmzzb6L7Tkrv/yyy8HOBi2KTw9PdmwYQOZmZmsXr2aLVt0T25Ny+SW1XLpKytZsbeIJy8azp+n6W7IGvdzTJRgWippdBYd6a6/gbCwMKZOncp3333H0KFDj8o+zbHL7rwKrpq/mvIaC/OvGcfJ/XU3ZE3XQJdgOoiOctdfUFBAaWkpADU1Nfzvf/9j4MCBrjNc063JKK7mitdXYbMrFt04SYuLpktxTJRgugId5a4/JyeHq6++GpvNht1u59JLL2XGjBmuNl/TDSmqrOOq+aupt9r56MZJ9O8R7G6TNB2Ava6Out17qNu5k9qdO4iYPRufpCR3m9UuOsVd/9Gi3fUfyfF+/cc7VXVWLn9tJbvyKnjv+gmMSYlwt0maNqKUwppfQN2undTu2EHdDkNQ6tP2g80GgPj5kfif5wk68cR2peFud/26BKPRdDPqrXZufHctW7PLeWXWGC0u3QBVX0/dvn2HCUndjp3YSkoOhvGKj8Ov/wCCTz8dv4ED8R0wAJ/kZMTT042WHx1aYDSaboTdrvi/jzfy2+5Cnrx4OKcP7uFukzSNsFdVUbttGzWbt1C7Yzt1O3ZSt28fWK0AiI8Pvv36EXTqKfgNGIjvwAH4DRiAZ+ixN5uoFhiNppuglOLvX2/niw3Z/GX6AC4d2z3r5Y8llNVK3Z491GzaRO3mzdRs3ETdnj1gtwPgFROD78ABBJ18siEkAwfik5KCeB0fr97j4yo1mmOAV37dx/zlaVw7pSc3ndzH3eYcdyilsGRlU7tpIzWbNlOzeTO1W7eiamsB8AwNxW/4cKOKa/gw/IcNwysy0s1WuxctMBpNN+Cj1Aye+HYH546I5/5zButBlJ2AtaSE2i1bjNKJKSi24mLAqObyGzyYsEsvwX/YcPxHDMc7KUk/l0ZogdFoujhLduRxz6ebOaFvFE9fMgIPD/0SO1qUUthKSrDk5GDNyzPWublYcnKNdXY2luxsI7AIvn37EDR1Kv7Dh+E3bBh+/fsj3trHW2togTkKnn/+eV566SVGjx7d7MDJt956i9TUVF544YUjjgUFBVFZWdnkeTabjbFjx5KQkMDixYs71G5N92HtgRJufm8dg+NCeHn2GHy89Njo1lBKYS8rw5Kb6yAguVhzc7Dk5GLJy8Wam4eqqzv8RG9vvHv0wDs2Fv8xYwi/4nL8hg3Hb8gQPIMC3XMx3RwtMEeBK9z1N/Dcc88xaNAgysvLOzxuTfdgd14Fc95aQ2yIH29eO44gX/13bYyy26nff4DarVup3bbNWG/fjr2i4vCAXl54x8TgFRuL/5CheJ1+Ot49YvGKi8U7Ng7vuFg8IyIQDy3gHYnLcqyI+AG/Ar5mOh8rpR4UkQjgQ6AnxpTJlyqlSpqLp6vi6K5/zpw5XH311cyZM4d9+/YREBDAq6++yvDhww87Jy0tjSuuuAKr1cr06dObjTszM5Ovv/6a++67j2eeecbVl6LpgmSX1nDV/NX4eHnwznUTiArydbdJbkfZbNSnpR0Uk5qtW6nbth17dTUA4uuL78ABhMw4B9+ePfGKjcM7tgdesXF4RUV26/Ek3RVXfhLVAacqpSpFxBtYJiLfAhcCPymlnhCRe4B7gKPyVpn7+OPUbe9Yd/2+gwYSe++9zR53pbv+O+64gyeffJKKxl9hmuOC0up6rp6/mspaKwtvmEhSRIC7Tep0lNVK3d691G7ddqh0smMHqqYGAPH3x2/gQEIvuAC/IUPwGzIY3969dbtIF8NlAqMMHzQNDQze5qKA84Cp5v4FwFKOUmC6AsuWLeOTTz4BWnbX3xBm9uzZ3H33kZe9ePFiYmJiGDNmDEuXLnW53ZquRU29jesWpHKgqJoFc8YzJL57DL5TSmFJT8eSnY2yWA5f6i1H7jsiTP3BdX16OnU7dx5sI/EICMB38CDCLrkY/yFD8Bs8GJ/evXWJpBvg0kpdEfEE1gJ9gReVUqtEpIdSKgdAKZUjIjHNnDsPmAeQnJzcYjotlTQ6i45y1798+XK+/PJLvvnmG2praykvL2fWrFm8++67HWarpmtitdm55f11rEsv4b9XjGZSn649hsJWWkrVylVULV9O1YoVWLKy2haBlxfi7X344uWFd1wc4ZdffrBk4tOzp24b6aa4VGCUUjZgpIiEAZ+JiNOTmiilXgVeBcPZpWss7Dga3PXff//9rbrrnzVrVrO9zv7xj3/wj3/8AzDc/j/99NNaXI4DlFL89dPN/LQjn7+fP5SzhsW526QjUPX11GzcSOWKFVQtX0Htli1gt+MRFETAxAlEXDcH37598fDxgcOEw8dY+5i/fXwQLy8tGscBndItRSlVKiJLgelAnojEmaWXOCC/M2xwNR3lrl9zfPLU9zv5aG0mt5/Wj1kTU9xtDmCIXn1aGlXLV1C1fDnVq1cbDeqenvgPH07UTTcROGUK/sOHHTeuTzRtw2Xu+kUkGrCY4uIP/AD8EzgZKHJo5I9QSv2lpbi0u/4jOd6v/1hi/rI0Hlm8jSsmJPPY+UPdOhrcWlJC9e+/U7l8OVUrfseakwOAd3IygVMmEzRlCgETJuAZrOee6Q4cy+7644AFZjuMB7BIKbVYRH4HFonIdUA6cIkLbdBouiz1Vjuv/baPp77fyfQhsTx6nnvExVZRQemHH1L+7XfUbtsGSuEREkLgxIkE3nADgVMmd9sJrzTuxZW9yDYBo5rYXwSc5qp0NZruwIq9hTzwxVb25Fdy1tBYnr1sJJ6d7ALGkpdH8dtvU7rwQ+xVVfiPGkXUrbcQNGUKfkOH6l5amqNGV5xqNJ1Ifnktf/96O19uzCYpwp83rh7LaYM6d06Xur17KZo/n7IvvwKbjZDp04m4bg7+Q4Z0qh2aYx8tMBpNJ2C12Vnw+wGe/XEX9TY7t53Wj5un9sHPu/NKCdXr1lP0xhtU/vQT4utL+CWXEHHtNbr6S+MytMBoNC5mzf5i7v98CztyKzi5fzQPnzuEnlGd4zxR2e1ULv2FojfeoGbtWjxDQ4m6+WbCZ12JV4SealnjWrTAaDQuorCyjn98s4NP1mUSH+rHy7PGcOaQHp3SkK/q6ylb/DVF89+gfs9evOLj6HHvvYRddCEegdozsKZz0AJzFLjKXX/Pnj0JDg7G09MTLy8vGnfR1nRtbHbF+6sO8NT3O6mx2Lh5ah9uObUvAT6u/7vZKqsoXbSI4gULsObl4du/P/FPPUnI9OnaT5em09ECcxS40l1/gxNNTfdifXoJ93+xhS1Z5UzpG8nD5w6lb0yQy9O1FhZS/PY7lHzwAfaKCgLGjyfu748SeMIJepZFjdvQAtNOXOmuX9P9KKmq58nvd7BwTQYxwb785/JRzBge5/KXu7WoiMKXXqZ00SKUxULwtGlEXn8d/o3ynkbjDo4Jgflt0S4KM5qeGbK9RCUFceKl/Zs97kp3/SLCGWecgYhwww03MG/evI66LE0HY7crFqVm8M/vdlBea+X6E3px++n9XT45mL2qiqK33qL4jfnY6+oIveB8Iq+7Dl8XlKY1mvbSrn+BiHgppawdbUx3pqPc9TeEi4+PJz8/n2nTpjFw4EBOOukk116Apk3Y7Yrf9hTy7I+72JBRyvieETx6/lAGxLrWhYqyWCj56CMKX/wvtqIigqdNI/pPd+Dbu7dL09Vo2kOzAiMiy5RSJ5jb7yilZjscXg2MdrVxztJSSaOz6Ch3/QDx8fEAxMTEcMEFF7B69WotMF2E0up6Pl6bybsrD7C/qJroYF+euXQEF4xKcGl1mLLbqfj+e/L//W8sB9IJGDuWmBdfwH/kSJelqdEcLS35y3bsy9h4iK9uNWxEg7t+oFV3/UCzvc6qqqoOzmRZVVXFDz/8wNChTs9yoHERmzPL+MvHG5nw+E/8/evtRAf78twfRrL87lO5cHSiS8WlauVK9l96GVl/+jMevn4kvfIyye+8rcVF0+VpqYqsJTfLXX5+ls6mo9z15+XlccEFFwBgtVq54oordIcAN1FrsfH1phzeWXmADRmlBPh4ctGYRGZNSGFwfEjrERxt+tu3k/+vZ6hatgyv+DjinvgHoTNnah9hmm5Ds+76RWQfcCdGKecp4K6GQ8CTSqk+nWIh2l1/Uxzv1+9KMoqreXfVARatyaCk2kKf6EBmT0zhwjGJhPi5fixJfWYmBc89T/lXX+EZGkrkjTcSfsXlePj6ujxtzbFFV3bX/wtwrsP2TIdjv7rMIo3GDdjtil92F/DO7wf4eWc+HiJMG9SDqyalMKlPZKeMJbEWF1P40suULFyIeHoSOW8ekddfh2eI60tLGo0raFZglFLXdqYhGo07KKmq56O1Gby7Mp304mqigny59ZS+XD4hmbhQ/ybPsVVUUL1qFVUrVlC7axceAQF4BofgERKMZ0goniHBeAQH4xkScnDtGRyMh7luPKLeXlVF0YIFRpfj2lrCLrqIqD/+Ee8eMZ1xCzQal9FSL7KZwCal1AHz9wPARcAB4HalVFrnmNg8SqnjcpSyq2YhPZ4orqrnH98YbvPrrHbG94rg/84cwJlDYvHxOrzvi7JYqNm0yZg6eMUKajZvBpsNCQjAb9AgbMUl1B84gL28Alt5OdhsLaYtAQF4BgebQhRCfXo6tsJC3eVYc8zRUhXZY8BEABGZAcwCLseYROxl4EyXW9cCfn5+FBUVERnZOdUXXQWlFEVFRfj5+bnblG5LWbWFWa+vYk9BJZeMSWT2pBQGxh6qhjpsLvoVK4y56KuqwMMDv6FDiZx7PYGTJxMwciTi43NY3EopVHU1tgpDbOyHrSuwlZcZQlRRbq4rjPnt583VvcI0xxwt9iJTSlWb2xcCbyil1gJrReTm1iIWkSTgbSAWsAOvKqWeE5GHgLlAgRn0XqXUN201PDExkczMTAoKCloPfIzh5+dHYmKiu83ollTUWrhq/ir25Ffy+tVjOal/NGC0f1St+J2qFSuo+t1hLvqkJEJmzCBw8mQCJ07AMzS0xfhFBAkMxCMwEO/YWJdfj0bTlWlJYEREgoBqjCmO/+twzJnPZytwp1JqnYgEYwjTj+axZ5VST7fLYhNvb2+XOJnUHLtU1Vm59s01bM0u5+UrRjGmaA95T71F1Yrfqdu+HcCYi37CBAJvmEfg5Mn4JCe72WqNpvvSksD8G9gAlAPblVKpACIyCshpLWKlVE5DOKVUhYhsBxKO0l6Npl3UWmxcvyCVdeklvDbOn96P3EH6pk3g7U3AiBFE334bgZMn67noNZoOpNlxMAAikgDEABuVUnZzXxzgrZRKdzoRkZ4YXZuHAn8GrsEQrlSMUk5JE+fMA+YBJCcnjzlw4ICzyWk0h1FntTH37bVs2byX/1atJPTXH/CMjiLmjj8RMv1MPQGX5pjF3eNgWhpo2aKvMaXUOqcSMKrZfgEeU0p9KiI9gEIMbwCPAnFKqTktxdHUQEuNxhksNjt/XLCa4K8/4dq9S/C0WYi85moib7gRzyAtLJpjG3cLTEtVZKnAVg41xjt21VLAqa1FLiLewCfAe0qpTwGUUnkOx18DFrfRZo3GKaw2O8/8/S0u+eotEisLCDr5ZHr89R58evZ0t2kazXFBSwJzJ8a4lxpgIfCZUsrpSVfE6Dv8Bkb7zTMO++PM9hmAC4AtbbZao2mF2rT9LL39Ps7dtY6amHiS/vUyQSef7G6zNJrjipZG8j8LPCsivTDGv/wkIgeAx5VSG5yIewowG9gsIg3h7wUuF5GRGKWg/cAN7TVeo2mMrbKKwpdfpuDNt4gWT/ZccC0zHr7jiPEqGo3G9bQ64ZhSKk1EvgD8MQSjP0bvstbOW0bTbv3bPOZFo2kNpRTlX31F/lNPYy0oYEnSWDzm3cwtl0xyt2kazXFLS65iegN/AM4DMjCqyR5TStV2km0ajVPUbN5C3mOPUbNhA8VJfXnkpD9w0nlTufds7W1ao3EnLZVg9gCbgC8wuhQnAzc3uGVxbFfRaNyBtaiI/GefpeyTT/GMiGDTFbdyT1USsyf34t6zBx1XLoQ0mq5ISwLzCIcmFgvqBFs0GqdQFgsl779PwQsvYq+pIeKaa/hs2Jk88WsmfxifxEMzh2hx0Wi6AC018j/UiXZoNE5RvX49uQ89TN3OnQSecAI97v0r72TBE19v54JRCTx2wTA8PLS4aDRdgVYb+TWaroCtrIz8fz1D6aJFeMXGkvD8cwRPm8a7q9L5+9dbOGdYHE9dPBxPLS4aTZdBC4ymS9PQOyzviX9iKysj4ppriLrlFjyDAlm0JoP7P9/C6YNi+PcfRuLl6dF6hBqNptPQAqPpstTtSyP34YepXrUKvxHDSX7jdfwGGT3DvtiQxd2fbuKk/tG8eOVovLW4aDRdjlYFRkR8MUb093QMr5R6xHVmaY5n7LW1FL36KkWvvY74+RH70IOEXXop4mGIyC+7Cvjzoo1M6BXBK7PG4OulvR9rNF0RZ0owXwBlwFqgzrXmaI53KpctJ/eRR7CkpxMycyY97v4LXlFRB4/vK6jklvfX0S8miDeuHoe/jxYXjaar4ozAJCqlprvcEs1xjSU/n/wn/kn5N9/gk5JC8pvzCZx0+Cj88loL17+direnB69fPZZAX13Dq9F0ZZz5h64QkWFKqc0ut0Zz3KFsNkoWLqTg2X+j6uuJuvUWIq+/Hg9f38PC2eyK2z5YT3pRNe9dP4HE8AA3WazRdA42q52KoloCw3zx9u2eJXVnBOYE4BoRScOoIhNAKaWGu9QyzTFPzdat5D70MLWbNxM4eRKxDzzQrCv9J7/fwdKdBTx2wVAm9I7sXEM1GheglKK6vJ7ywlrKC2scFuN3ZWkdKJh52wiSB3fPPO+MwJzlcis0xxW2ykoKnn+eknffwzMigvinnybknLObHX3/+fosXvllH7MmJnPlhJROtlajaT/1tdZGAlJLeVEN5QU1VBTVYrXYDwsfGOpDSJQ/Cf3DCYnyIyTKn8j47utIxRlvygdEZARwornrN6XURteapTlWqVq9muz/+wvW/HzCL/8D0XfcgWdISLPhN2aU8pdPNjGhVwQPzhzSiZZqNK1js9ipKDYFpMhYVxQd+l1baTksvLefJyFR/oTHBpI8NJLQKH+CI/0IjfYnOMIPr2Os04oz3ZRvB+YCn5q73hWRV5VS/3GpZZpjCmW3U/Ta6xQ89xw+ycn0XPgB/iNGtHhOfnkt895JJSbYl//qsS4aN2C32aksqTNEo+hQCaSisJbyolqqyuoOeWwEPDyF4Ag/QqL86J0cTUikUQoJjfYnJNIf30Cv48pPnjNVZNcBE5RSVQAi8k/gd0ALjMYprCUlZN99N1W//kbI2WcT+8gjeAYFtnhOrcXGvHfWUlFr5ZObJhMZ5NtieI3maKmvtZK3r5ycfWXk7SujNL+ayuI67PZDCiICgeG+hET6kzQwnOAof6MqK9JYB4T6al94DjgjMALYHH7baHoiMY3mCKrXrSfrz3/GVlRE7IMPEPaHP7T6BaeU4r7PtrAho5SXZ41mUFzzVWgaTXtQSlFRXEvu3jJy95aRs6+MosxKlAIEIuOD6NErlL5j/Q6WQkKi/AgK98PTS5ekncUZgXkTWCUin5m/zwfeaO0kEUkC3gZiATvwqlLqORGJAD7E8AywH7hUKVXSZss1XRqlFMVvvkX+M8/gHRdHysIP8B/iXBvKG8vS+GRdJnec3o/pQ+NcbKnmeMBus1OYWUlOg6DsLaOq1Bg37u3rSY9eIYw5uydxfUKJ7RWKj78eY9URONPI/4yILMXorizAtUqp9U7EbQXuVEqtE5FgYK2I/AhcA/yklHpCRO4B7gHubu8FaLoetrIysu+9j8qffiJ42unEPfZYiw35jvyyq4DHv9nOWUNjue3Ufi62VHOsUldtIXdfObn7ysjZW0peWjnWeqPHVlC4L/F9Q4ntE0Zcn1AiEwLx0O17LqGlKZNDlFLlZoljv7k0HItQShW3FLFSKgfIMbcrRGQ7kIAxBfNUM9gCYClaYI4ZajZvIeuOO7Dk5dHjr/cQftVVTjdq7iuo5Nb319G/RzBPXzJC12Vr2kR1eT27Vueya3UeBRkVoEA8hKjEIAZNiTdKJ71DCY7wc7epxw0tlWDeB2Zg+CBz6CdhDLQEejubiIj0BEYBq4AepviglMoRkZhmzpkHzANITk52NimNm1BKUfLe++T/8594RkfR89138B850unzG9zAeHl68NpV2g2MxjmsFhtpGwvZuSqX9K3FKLsiJiWY8TN6EdsnlB49Q/Dx03nJXbQ0o+UMc93raBIQkSDgE+AOs0Tk1HlKqVeBVwHGjh2rWgmucSO2ykpy/nY/Fd99R9DJJxP3xD/wCg93/ny74nbTDcy7108gKUK7gdE0j1KK3H3l7FyZw561+dRVWwkM9WHUtCQGTIgjIr7lHopdHbuyU2utpdpaTY2lhkj/SAK8u+d/wplxMD8ppU5rbV8z53pjiMt7SqmGcTR5IhJnll7igPz2GK7pGtRu307mHXdgycwi5q47iZgz56BbfWd56vud/LyzgEfPH8pE7QZG0wzlhTXsXJXLzpW5lBXU4OXtQe9R0QycGEfCwPAuU6WqlCK9Ip1NBZsorSulxlpDjbWGakv1we3Gi+OxWlvtYfG9fPrLTEmY4qarOTpaaoPxAwKAKBEJ51DX5BAgvrWIxSiqvAFsV0o943DoS+Bq4Alz/UX7TNe4E6UUpR99RN7fH8MzLIyUtxcQMGZMm+P5fH0WL/+ylysnJDN7onYDozmc+lore9fls3NlLlm7SgGI7xfGmLNS6DM6pktUfymlSCtPIzU3ldTcVNbmrSW/5vDvZi/xwt/L31i8/QnwCsDfy58QnxB6BPQ4dMzLnwDvgMN+9w3r66YrO3paejo3AHdgiMlaDglMOfCiE3FPAWYDm0Vkg7nvXgxhWSQi1wHpwCVttlrjVuxVVeQ8/DDlX35F4OTJxD/1JF6RbS95bMwo5e5PNjFeu4HROGC3K7J2lLBjZQ771hdgtdgJjfZn/MxeDJgQS0iUv3vtU3b2lu4lNe+QoBTVFgEQ7R/N2B5jGRs7ltExo4kOiCbAKwBvT2+32uwuWmqDeQ54TkRubY9bGKXUMpofkNlq9Zqma1K3ezeZt99BfVoaUbfdStQNNyCebfef1OAGJirIl5euHI2PHrx23KLsitL8avIPVJC3v5x96wuoKq3Dx9+LARNjGTAxjtjeIW5zsWJXdnaV7DJKKHmGoJTWlQIQGxjLpPhJB0UlOTj5uHIF0xrOjIP5j4gMBQYDfg7733alYZquR9Xq1WTceBMeAQHGhGATJ7YrnlqLjRveXUt5jXYDc7yhlKKsoIaCAxXkHygn/0AFBRkVWGoNZyFe3h4kDAhnysV96TUiCi/vznf+aLPb2FmykzW5a0jNS2Vd3jrK68sBSAhK4KTEkxjbYyzjYseREJSgBaUFnGnkfxBj3Mpg4BsM9/3LMEbpa44TqlauIuOmm/COjyd5/ny8ezTZu7xVlFL87fMtrE8v5aUrRzM4XruBOVZRSlFRVGuISLopJukV1FVbAfD08iAqKYiBE2KJTgkhJiWY8NiATh/0aFd2dpfsZk3uGlblrmJt3loq6isASA5O5vSU040SSo+xxAVpzxJtwZkWsouBEcB6pdS1ItIDeN21Zmm6ElUrVpBx8x/xSUok+c038YqKalc8NrshLh+vzeS20/px1jD9Zz2WqK20kL2nlPwD5WYJpYLaKsNdvYenEJkQRN8xMcSkhBCdEkxEfCCebhhBr5QirSyN1bmrWZ27mtTcVErqDG9ViUGJTEuZxrjYcYzrMY4egT063b5jCWcEpkYpZRcRq4iEYHQrdnqQpaZ7U7lsOZl//CM+KSkkv/UmXhER7YqnzmrjjoUb+HZLLn88pQ9/Ol27gTlWKM2vZuP/Mtj+ew42ix3xECLiA+k1MooYs2QSGR+Ep7d72tmUUmRUZLAqdxVrctawJm8NhTWFgNGGcmLiiYyPHc/42PG6hNLBOCMwqSISBryG0ZusEljtSqM0XYPKX38l85Zb8endm+Q357dp8ORh8dRZueGdVJbvKeJv5wzi+hP198mxQF5aOet/PMDe9QV4eAoDJ8QycHI80UlBbp84K7sym1U5q1iTu4bVuavJq84DIMo/6qCYjI8dT2Jwom5DcSHONPLfbG6+LCLfASFKqU2uNUvjbip+/pms227Hp19fUubPxzMsrF3xFFfVc82bq9maXc6/LhnBRWMSO9ZQTaei7IoDW4tY/0M62btL8Q3wYvSZKQw/JZHAUPd21sipzOGrfV/x1d6v2F++H4Bw33DGxY5jfOx4xsWNo1dILy0onUhLAy1Ht3RMKbXONSZp3E3FkiVk3n4HfgMGkPzG63iGhrYrnqzSGma/sYqskhpemTWG0wfr+uzuis1qZ9fqPNb/mE5JThVB4b5Mubgvg0+Id+tgx2pLNT+l/8QXe79gdc5qFIpxseP4w8A/MC52HH3D+uIhugu8u2gpZ/zLXPsBY4GNGONahmM4rTzBtaZp3EH5jz+S9ac/4zd4MMmvv+a0m/3G7MmvYPYbq6mstfLOdRMY36t9bTca91JXY2Xrb1ls+imDqrJ6IhOCOP3awfQdG+OWBnow2lTW5a/jiz1f8P3+76m2VpMQlMBNI29iZu+ZJAbrUnJXoaWBlqcAiMhCYJ5SarP5eyhwV+eYp+lMyr/7nqy77sJ/yBCSXn8Nz+DgdsWzIaOUa99cjaeHBx/eMEl3Re6GVJbUsWlJBlt+y8JSayNxYDinXjWIpMERbqtiyqrM4su9X/Llni/JrMwkwCuAM3ueybl9zmV0j9G6pNIFcaZsO7BBXACUUltEZKTrTNK4g/JvviHr//6C/4gRJL36Cp5BQe2K57fdBdzwzloig3x497oJpER2b8+2xxtFWZVs+DGdXWvyUHZF3zExjDojhejk9n1sHC3Vlmp+PPAjX+z9gjW5axCE8XHjuXnkzZyWfFq39TJ8vOCMwGwXkdeBdzHmgZkFbHepVZpOpeyrxWTffTf+o0eR9PIreAa1TxS+3pTDHR+up090EG/PGU9MiJ7YqbuQs6eUtd8f4MDmIrx8PBhyUgIjT0tyi98vu7KzNm8tX+z5gh8O/ECNtYbk4GRuGXkLM/vMJD6oVV+7mi6CMwJzLXATcLv5+1fgJZdZpOlUyr78kux7/krA2LEkvfwSHgHt+yJ8d+UB7v9iC2OSw3nj6nGEBhyfzv26GwXpFaz6ch8HthThF+TN+Jm9GHZyIn5BR/f8lFLU2+upsTRyS2+tptZa26TL+lprLZWWSlZkryCrMotA70DO7nU25/U9j5HRI3Xvr26IM92Ua4FnzUVzDFH62efk3HsvARMmkPTSf/Hwb/vXqlKKF3/ew9M/7OLUgTG8eMVo/N08BkLTOiW5Vaz6Mo296/LxDfBi0gV9GDY1EW/ftj+7tLI0fs74maUZS0kvTz84p4ld2dsUj5+nH35efgyKGMSto27l1ORT8fdyr+dkzdHRUjflRUqpS0VkM4dPmQyAUmq4Sy3TuJTSjz8m5/4HCJw0icQXX2iXuNjtike/3saby/dzwagEnrx4ON5u6lmkcY7ywhrWfJ3GzpW5ePl4Mvbsnoycloyvv/Ndje3KzqaCTfyc8TM/Z/xMWlkaAIMiBjE1aWqz85r4efrh7+1/2D5/L2NuFD8vP91IfwzSUq5qqBKb0RmGaDqPkg8XkfvggwSecAKJL/wHD7+2t5VYbHb+8vEmPlufxZwpvfjbOYO6zIyCmiOpKqtj7Tf72bosGxFh+GlJjDkzBf9gH6fOr7PVsSpnFUvSl7A0YylFtUV4iRdjYsdw2YDLOCXpFN02ojmClrop55jrA51njsbVlHzwAbkPP0LgySeR+PzzePi2ffR1Tb2NP76/jiU78vm/Mwdw89Q+un68i1JbZWH9DwfYtCQTu00xaEocY8/uSVB46x8VZXVl/Jr5K0vSl7A8ezk11hoCvAI4MfFETkk6hRMSTiDUt32DcDXHBy1VkVXQRNUYxmBLpZTSgxu6GcXvvkfe3/9O0CmnkPDcv/Hwce7r1ZGyagvXLVjD2vQSHrtgKFdO0NMcd0Xqa61s/CmDDT+mU19no//4Hoyf0YvQ6JY7cWRWZB6s+lqXtw6bshHjH8PM3jM5JfkUxseOx8ez7flGc3zSUgnmqDq+i8h8jOq1fKXUUHPfQ8BcoMAMdq9S6pujSUfjHCULFxrictppJD77DNIOcSmsrGPW66vYW1DJC5eP5pzh2vNsV8Nab2PLr1ms/e4AtZUWeo2IYsK5vYlMOHxcU1ldGVmVWcZSkUVmZSbr89ezq2QXAH3D+jJn6BxOTT6VwZGDdfuIpl043bInIjEcPqNleiunvAW8wJETkz2rlHra2XQ1R0/pJ5+S+9DDBE2d2m5xya+o5crXVpFRUs38a8ZxYr9oF1iqaS82m53ty3NI/WY/VaV1xA8MJfk0f6rCC/m+/EuysrMOE5QKS8Vh54f4hNA/vD93jb2LU5NOJSkkyU1XojmWcGZGy3Mx/JLFY8wFk4Ix0HJIS+cppX4VkZ4dYKPmKCj7ajE5f/sbgVOmkPDcv9slLnnltVz+2kpyy2p569rxTOwd6QJLNW1FKUXWgUJ+X72ZvDX1SIUP5eF5rBv5HTv814GDO1o/Tz/ig+JJDE5kVMwoEoISSAxKJCE4gYSgBIJ93DNSX3Ns40wJ5lFgIvA/pdQoETkFuPwo0rxFRK4CUoE7lVIlTQUSkXnAPIDk5OSjSO74pfz7H8i+5x4Cxo0zeou1o0E/u7SGK15bSUFFHQvmjGdcT+200p3UVNSzeUMam9btpTJN4V1rdC8vDMxl38jV+PSsZ3BIT6YFTSEhyBCPxOBEIv0idUcMTacjSjXVju8QQCRVKTVWRDYCo8zZLVcrpca3GrlRglns0AbTAyjE6DzwKBCnlJrTWjxjx45VqamprV+N5iAVS34m87bb8B82jOTXX8MjsO3uXzJLqrn8tZWUVllYcN14Rie3b8IxTfuxWe3k7C1l3dqdpG8rhkI/BKHWq4qiyHQi+/kxduwgJvcbh7en9p6gORwRWauUGuuu9J0pwZSKSBCGi5j3RCQfsLYnMaVUXsO2iLwGLG5PPJqWqVy2nKzbb8dv0CCSXn2lXeKSXmSIS0WthXevn8CIpLCON1TTJKX51ezZnMOW9fup2G/Dw+qFHRt5wTnYBpbRZ1gs00dNpHf4DF0q0XRpnBGY84Aa4E/AlUAo8Eh7EhORuIbxNcAFwJb2xKNpnqpVq8n84x/x6dvXmM+lHS739xdWcflrK6mx2Hh/7kSGJuixDq6krsZK1s4Stm9MJ31bEfYy429Z7ltEbvRewvp6M2b0QK7qfYked6LpVjgjMPOAj5RSmcACZyMWkQ+AqUCUiGQCDwJTTVf/CtgP3NBGezUtUL1uHRk33YRPclK7Z6LcW1DJFa+txGJTvH/9RD2Xi4uorbSwb0MBm1cdoGBPNaKEeo9askJ3UzOogN5De3D6kImMjLkAbw9d9aXpnjgjMCHA9yJSDCwEPnas6moOpVRTHQHeaKN9Giep2bSJjLnz8I6JIXn+fLwi2t4YvzuvgiteX4VSig/mTmRArO5Z1JHUVlrYt7GAPWvzydhRDHYo8ysgLX4TAb3tjBo2kAtSzqNnaE93m6rRdAjOeFN+GHhYRIYDlwG/iEimUup0l1uncYra7dtJv34unhERJC94C6/oto9R2ZlbwRWvrcTDQ1g4byJ9Y7S4dAS1VRbSTFHJ3F6C3a6oC6xga9xKcmN3cuboqTwx+M9E+uuu35pjD+ddqBpjYHKBIiDGNeZo2krtrl2kXzsHj6BAUt56E+8ePdocx7bscq58fSU+Xh68P3cifaLbN5ulxsAQlUJTVIqx2xVeoYr9vTawOuB/eETVM3vIbC7ufx9BPvpea45dnBloeRNGySUa+BiYq5Ta5mrDNK1Tty+N9DnXIT4+pLz5Jt4JCW2OY0tWGbPeWEWAtyfvz51Izyg9xXF7qKu2kLbJEJWMbcXYbYqgSF/8R9fwg9cnbGY1KaEp3Dp0LjN6z9D+vDTHBc6UYFKAO5RSG1xsi6YN1Kenk37NNaAUyW+9iU9K251ObswoZfYbqwj282bhvIkkRej5zdtCdXk9GduK2LOuwOj9ZVUERfgy6OQe7I3cwILC1ymoLWBw5GCeGfYMpyadiqeHnoxNc/zgTBvMPZ1hiMZ5LFlZHLjmGlR9PclvL8C3d+82x7H2QAnXzF9NWKA3H8ydSGK4FpfWqCiuJXt3Kdl7SsneVUppXjUAQeG+DJuaSMxQX76r+px7dy2kIrOCCXETeGzoY0yMm6jHq2jaTlURFO6EmMHgH+Zua9pFW9pgNF0AS14eB665FntlFclvzsevf/82x7FmfzHXzF9NdLAv78+dSHyYnpa2MUopygpqDEExl4qiWgB8/L2I6xvKoClxJPQPpz68jLe3v81nqZ9Rb6vn9JTTmTN0DkOjhrr5KjRdHrsdyjKgcBcU7DTWDds1xUaYKz6C/me41852ogWmG2EtKCD96muwFReTPP8N/Ie06G+0SVbuK2LOW2uIDfHj/bkTiQ1t+2yWxyLKrijOrSJndylZpqBUl9UD4B/sTXzfMEaclkR8vzAi4gPJr8ljU+EmPkxfwve/fo+IcG6fc7lmyDX0Cu3l5qvRtAu7DcqzoXgflKaDeIBvEPgEgW+Iw3YQ+ASDZxten9Y6KNp7uIAU7oTCPWCtORTOPwKiB8CgGRA1wNhOdJunl6NGC0w3wVpSQvqcOVjy80l+7VX8R4xocxzL9xRy3YI1JIYH8P7cCcQEH7/iopSiMKOS7N2lZO0qIWdPGbVVFgACw3xJ6B9OfL8w4vuF4RVhY2vRVlYXrmTT7k1s+X0LhTWFAAR4BTBr0CxmD55Nj8C29+DTdDLWOkM8itMMISlJO7RdegBs9c7H5eV/pOj4BoFvsLHPy88onRTshJL9oGyHzg1Ngqj+0PNEYx09wFgHRnX4JbsTLTDdAGWxkHHDjdSnZ5D0yisEjBnT5jjW7C/mugVrSIkI5L25E4gKartn5WOB2koLO1bmsG1ZNiW5RhtKSJQfPUdEEd83jJi+geR4pLO1cAu/FG5i86rNpJWlHTy/Z0hPJsVNYlj0MIZFDWNA+ADtZLKroJQhEPVVUJZ5uHiUpEHxfuOF7zhRr08QhPeCmIEw8GxjO6IXhKWACNRVQn0l1FUYS32lsa+uAuorGh2vhMo8o6RSXwn11RCaAD2GwJALDolIVD/wOT56a2qB6QYUvfEGtZs2kfDvZwmcOKHN52/NLmPOW2uID/U/LsVFKUXOnjK2/pbF3nUF2Kx2evQKYeqsAXin1LHXupPUgt/YXLiZHT/soM5WB0CEXwTDooZxTq9zGBY1jCFRQ7QvMFdSUwo5G42XdMML2lJ9aLu+CixVxrq++vDthmP2JvzwBkRCRG9InggRlxvbDUISGG0IicYlaIHp4tTu2kXBi/8l5OyzCJk+vc3npxVWcfX81QT5evHO9e4Xl8yKTF7a+BKldaXYlA2b3YZd2bHardiV3dhW1sP2HRZOHQrXFILxshARvC1+pOQOp3fWaEKqo7F41pIeu4X9CespC86nNqOW8r3lAPh6+jI4cjCXDbiMYVHDGBY9jPjAeN37y1XUV0HuZshaB9nrjHXx3qbDevqCTwB4Bxpf/j4BRskjKNbcDjz8mHcghMQdEhE//VHgLrTAdGGU1UrOX+/FMziYHn/7W5vPzymrYdbrq7AreOe6CSS4sbeYUopPd3/Kk2ueBCAlJAUvDy88xANP8cTTwxNv8cZLzH0ensZ+c/Hw8Dj028MTDzwQERznM1IoUOBZEIzfzlh8D0QhNk8sUeVUjNhJbc8CQrztDKM/0B8v8WJAxACGRQ2jb3hf7VTSVVjrIW+LISTZ6yFrPRRsh4aPhOB4SBgNI6+A+FFG9ZSjcLSlMV3TpdBPrgtT9MZ8arduJeHf/26z88riqnpmv7GashoLH8ydSN8Y97kkKawp5MEVD/Jr5q9MiJ3Ao1MeJS4orkPTqKu2sHNVLlt/y6Y4uwpvP0/6T4llyInxRCdpv2qdht1mNGo3lEqy1xvi0tB47h9hiMnAc4x1/CgIjnWvzRqXoQWmi1K3ezeFL7xA8PTphEw/s03nVtZZufbN1aQXV7Pg2vEMS3RfFcEP+3/g0ZWPUmOt4Z7x93D5wMvxEI8OiVspRV5aOVt/zWLP2nysFjsxKcGcMmsgfcfG4OOns7fLqa+CjNVwYIWxZK8z2k3A6FUVPxIm3GiKyWgIS9ZtHscR+h/YBVFWK9n33odHUBCx97etaqzWYmPe26lsyS7n5VljmNTHPV56y+rK+Mfqf/D1vq8ZGjmUx058jN6hbfc40BhLvY2SnCpy9paxfXk2RVlVePt60n9iLENPTCA6+RgqrdjtUFduLLVlUNuwbf6uc9gnnhA9EGIGGYururvWlED6Kjiw3BCUnA1Gw7p4QOxwGDX7kJhE9gWPjvmY0HRPjmmB2behgMztxZz4h/7dqrG26M03qd28mYRnn8Er0nmBsNrs3PbBelbsLeKZS0cwbbB7xmWsyF7B/cvvp7immJtH3szcYXPx8mhbVrPb7JTm11CUVUlxdtXBdVlhzcFeptHJwUy9cgD9xvXonqWV0nTY8Q1krTUFpOxwAamvaD0OT1+jEdtaZwhOA4HRptgMNoVnsNEVt60N3pX5h0onB1YY1V0o8PSBhDEw5XZImQyJ48FPT06nOZxu+K90nuxlW9i8RREaE8CI05LcbY5T1O3ZQ+Hz/yH4jDMIbkOvMbtdcc+nm/lhWx4PzBjMhaMTXWhl01Rbqnl27bMs3LmQ3qG9ef7U5xkS2bK3AaUUlSV1hwlJUXYVJblV2K2GkohAaEwAUUlB9J8QS2RCIJEJQYTFdDP/aUoZL+gdX8OOxUYvKoCQRAiMNEaLR/Q2RMA3xHhh+4YYvw9uh4Bf2KFtL99DcVfkQP72Q0vBdlj3jtF9t4GQhEOlnOiG9YBD4zJK0+HA74dKKEW7jf3eAZA0Hk651xCUhDHgrV0MaVrGZQIjIvOBGUC+UmqouS8C+BDoiTFl8qVKqRJX2dDPuomsQjvLP1JEJQaRMCDcVUl1CAerxgIDiX3gfqdLXUopHvtmOx+vzeT20/ox54TOd1WysWAj9y27j/TydK4afBW3jroVP68jPQVY623sXJVLfnoFxVlVFGdXUl97aIRzULgvEfFBJA+KIDIhkIj4IMLjAvDy7qZeiG1WSP/dFJWvoSwdEEiaANMeNRq7I/scfToiEBJvLH1PO7TfbjfSzN8B+dugwFyn/QbmeB8QCE8xGujLMoxdvqGQMglGz4aUKRA3AvSAUk0bEcdunh0aschJQCXwtoPAPAkUK6WeEJF7gHCl1N2txTV27FiVmpraZhuUUqTf+yBLMgdiC4vhsodPIDii67pHKXrjDfKfepr4fz1N6DnnOH3eC0t28/QPu7hmck8enDm4U6sDLTYLL218iTe2vEGPgB48dsJjjIsdd0Q4u12xa1Uuq77cR2VJHb4BXkQmBBERH3hoHR+Ib8Ax8BKrr4K9SwxB2fWd0W7h6Qt9ToEBZ8OAsyDIzXP22ayG+5L8bWaJx5ziKWWyscQMBj21QLdHRNYqpdzmzMxlAgMgIj2BxQ4CsxOYqpTKEZE4YKlSakBr8bRXYMAoFey45a/8Yp1KaJQflzwyFS+frvfHqdu3j7TzLyDo5JNIeP55p0XinZUHuP/zLVwwKoF/XTICD4/OE5fdJbu5d9m97Cjewfl9z+fucXc3OUNjxrZiln+6h6LMSmJSgpl8YV/i+4e5r13MboPsDUYDtXeAWQXlsPiHGQP52mJfVSHs/NYQlX0/g7XWqMrqP90opfQ51fBTpdF0Iu4WmM5ug+mhlMoBMEXG5Z9x4uXFgGcfoXzug6SWTud/zy/nzDtP7FKN/spmI+ev9+Lh70/sAw84bdsXG7J44IstnDYwhicvHt5p4mKz23h729v8Z/1/CPYJ5vlTnueU5FOOCFeYWcnvn+4hfVsxwZF+nHHdEPqOiUE6UQQPUrIf9v5svPz3/QK1pS2HF48jhccv7MhtS7VRSslYZQwcDE2CMdcYopI8SVcraY5rumwjv4jMA+YBJCcnH1VcHv7+jPnPXym96QX27JnC2oXrGHt52x1GuoriBW9Ts3Ej8U89hVd0tFPn/LwjnzsXbWRczwhevHI03p6d0x00oyKDvy37G+vy13Fa8mk8MOkBIvwOHwRaWVLHqq/2seP3HHz9vZhycV+GnZyIp3cndlmtKYX9vxlVVXt/NpwdgtHIPXCGUV2VNMHoYltbeqgXl+NS02h/4e5D244N5z2GwUl/MZwlxg7X4zw0GpPOFpg8EYlzqCLLby6gUupV4FUwqsiONmGv8HBO+dccyv/vc1YvHUB08m5SpvQ72miPmrp9aRQ89xxBp51GyAzn2l3W7C/mpvfWMiA2mNevHotfJzSAF9YU8uaWN1m0cxFeHl48fsLjzOg947DSVn2NlXXfH2DjTxnYlWLkaUmMOasnfoGd8BVvs0DmmkOllKy1RonCJwh6nmAM9utzquHJtiMEwFpvdClWCoKc+yjQaI43OltgvgSuBp4w1190ZuI+CQmcec9pfPKvDXz/Vi2XxIUQ3tt9c3gom42c++5D/PyIfdC5qjFHz8gL5ownxM+1L++C6gLmb5nPR7s+wmK3MKP3DG4Zecthrl5sNjvbfstmzddp1FRY6DeuBxPP601IlAu7sSpllCj2/WyUUvYvM7zuiofRhfbEu4xSSuI411RTefmA17E1d4dG09G4spvyB8BUIEpEMoEHMYRlkYhcB6QDl7gq/eYIGT6Q6bPK+OLDQhY/vpTLnj4HnzD3NL4Wv/MONevXE//kP/GOab05qjM9I+dX5zN/y3w+3vUxVruVGb1nMG/4PJJDDlVXKqVI21DI75/vpTSvmoT+YUy+pS8xKS4acGe3Q1YqbPkUtn8F5ZnG/vBeMPxSo4TS88RuO3+5RnOs4dJeZB3F0fQia45tb//Iz8uFRNKZ+Z9ZePj4dGj8rVG/fz/7zjufwMmTSfzvi62WXnLLarnopRXUWGwsumGSy5xX5lblMn/LfD7Z9Qk2ZePcPucyd9hckkIOH6iau6+MFZ/sIWdvGeGxAUy+sC8pwyI7vvOEUkZ119bPYOvnhqh4+kLf06HfNKOUEt6zY9PUaI4RjrdeZF2GwVdNozD7Kzbv78mye+Zz4r9u6LSeZcpmI/ve+xBfX2IfeqjVdPfkV3D9glSXekbOrcrl9c2v8+nuT1FKcV7f87h+2PUkBh/uEaA0v5qVn+9l77oC/EN8mHrlAAZNjsOjIzsZKGV44W0QlbJ08PA2ROW0B4xxJNotiUbT5TluBQbgxL/MoPjuL9hS3oeIx15j6N/mdUq6Je+9R826dcQ98Q+8e7RcNfbdllzuXLQBfx9PFswZ1+GekXMqcwxh2fMpAOf3PZ/rh11PQlDCYeHqa62s/fYAG/6XjoenMO6cnoycltxxPsCUgtxNRvXX1s+M+dE9vIxqr1P+agxQ1FVfGk234ritImugrsbCh3d9R22NnbMmVZM093KXpNNA/YEDRtXYhAkkvvxSs6UXu13x7P928Z8lexiRGMrLs8cQF9pxjeZZlVm8vvl1Pt/zOQAX9r2Q64ZdR3xQ/GHhlFLsSc1n+Sd7qCqtY+DEWCZe0IfA0A5o/2nwzbX1M2Mp3md4Be49FYZeaIhKQNvmwdFoNIfQVWRuxtffm5n3TWXRI8tZsrSUmbHfEjHzLJekpex2su+7D/H2JvaRh5sVl7IaC3csXM/POwu4ZEwij54/tMO6ImdWZPL65tf5Ys8XiAgX9buI64ddT2zgkZM+FWVV8uvCXWTvLiU6OZjp84YS27sDSlD52w+VVIp2Gz2/ep0EU+4wxqgEumeKAY1G07Ec9wIDEB4fzBlzh/PNq9v5+c21nBkVRtCkSR2eTsl771OTupa4xx/Hu0fT3aN35VUw7+1UMktqePS8IcyamHLUbUN2ZSc1N5Uv9n7BN/u+wUM8uGTAJcwZOqdJYamrtrB6cRqbl2bh4+/JyVcMYPAJ8UfnKcBmge1fwurXDOeP4mE4UZx0Mww613Xzl2g0GrehBcak15h4xp1ZzpofhBWPLuKkp0PxGzy4w+KvT08n/5lnCDz5JEIvOL/JMN9uzuHOjzYS4OPFB/MmMq7n0VUP7SnZw1f7vuLrfV+TV51HoHcglw64lDlD59Aj8EiBU3bFjpW5/P7ZHmoqLQw5MYGJ5/bGL+goxpFU5MHatyB1PlTmGvOtT3sUhl8Gwe4bg6TRaFyPFhgHxp0/gIL0Cvaocwj50xOMfv0xfJKOfh4ZZbeTc+99iJcXcY88ckSJxGZX/OuHnfx36V5GJoXx8qwxxIa2z+tzQXUB36R9w+J9i9lRvANP8WRKwhTuHHsnU5Om4u/VdDtO/oFyfl24i7y0cmJ7hzDz1pHtnx1SKWNU/epXjV5gdgv0OQ3Ofd7oCaa99Go0xwVaYBwQD2HajaP46NHf2WS7hMAb/8ygt19u06ySSilspaVYCwoOLjXrN1CdmkrcY48dUTVWVm3htoXr+WVXAX8Yl8TD5w3B16ttL+BqSzU/pf/E4n2LWZmzEruyMzRyKPeMv4fpPacT6d+8/bWVFlZ+sZety7LxD/LmtKsHMWBCbPscUlpqYcsnhrDkbDAmxRp3vbFE9W17fBqNplujBaYRPn5enHPbGD56bBXrIs7F/4Zb6L3gdcTHB2txMdb8gsPEw1pYgLWg0OF3IVgsR8QbfNZ0Qi+84LB9O3MrmPdOKtmlNTx+wTCumOC8U0+r3cqqnFV8te8rlqQvocZaQ0JQAnOHzeWc3ufQK7TlScfsdsW2Zdms/GIv9TU2RpyaxLgZvfD1b0eWKM2A1Ddg7QKoKTam6D3nX0Y1mG87S0EajabbowWmCcJ6BDBt7jC+flGxoWoUlhNPgpoao+qnEZ5hYXhFR+MVHY1vr154RUcd/N2weEZF4xkUeNh5X2/K4f8+3kigrxcL501kTErr7S1KKbYXb2fxvsV8m/YthTWFhPiEMKP3DGb2mcnI6JFOdQjI2VvGrwt3UphRScKAME68rD+R8W0cvKkUpP1qlFZ2fmPsG3A2jJ9n9AjTHoU1muMeLTDN0HNYFBPO682qLyAwJY6EaCuR8YEEJ0biHWOKR2Qk0kYXMza74qnvd/LyL3sZnRzGS7PG0COk5fYWpRSLdi7igx0fsLdsL94e3pyceDIzes/gxMQT8fFs3QalFFWldaz8Yh87V+YSFO7LGdeb87O0RQzqKmHTQqM3WMEO8I+AKbfD2Osg7OjbqzQazbGDFpgWGDM9hdLcanaugn3pQDr4+HkSEW8hIqGMyHgrEXHGvPEBIa2/5Eur67n1g/X8truQKyYk8+DMwa22t1TUV3D/8vv5Kf0nRkSP4IFJD3BGyhmE+h4+HsVab6OypI6Kkloqi2upLKk7uK4w15Y6Gx6ewujpKYyZnuL8KPyqQtj9g1FS2bPEmAslbiSc/xIMuRC8u+401BqNxn0c9yP5naG20kJxTiXF2VUUZVeZ60rqqqwHw/gHex8Um4b55SMc5pjfnlPOvHdSySur4+HzhnD5+ObbW5RSxhz2+bu575e/kVdRwNzBN3BGzHQqS+uoLDbEo6KkjsqSWiqL66itOrLdxz/Eh+BwX4LC/Qgy171GRBHWI6DlC25whb/zm8NnawyOhwHTYcTlhht8XQ2m0XRp3D2SXwtMO1FKUV1eT7GD4DRsW+psB8MFhPpQF+jJtqJK/Dw8GJEQSqCnJzaLHZvVjtVix2axYbPYsVrtxn6LvanmnsPwDfA6KBpBEYaAHBSTCF+CwvzaNoOkzWoIyc5vjLnli/ca+2OHG20rA86CuBFaVDSaboS7BUZXkbUTESEw1JfAUF+SBh1qoFdKUVFUy8oNuazakMeOzArCK4VkTy96hPjhXa+we9vx8vHAN9ALLy8PPL098PL2wNPbE/FUrClczcbi9cSG9OC8AecRFhiCp5cH/kHeBwWkQ5xM1lXAnp8MQdn9PdSUGF6Le50EE28yRCU0sfV4NBqNpgm0wHQguWW1fLIuk4/XZpJWWEWgjyczT4znvLFJjE4Oa7UxPb86nzuX3smG6g3MHjubP435E94eHTwbY2mGUe218xtjFkhbPfiHQ//pxtLnVO0KX6PRdAhaYI6SOquNn7bnsyg1g193FWBXML5XBH88pS9nD4slwMe5W7wmdw3/98v/UW2t5qmTn2J6z+lHb5zdDkV7jFH1mashYzXkbzOORfSBCTcY1V+J48FTZwWNRtOx6LdKO9mWXc5HazP4fH0WJdUWYkP8uHlqXy4ek0jPqMDWIzBRSvH2trd5du2zJAUn8caZb9AnrE/7jKotg8xUc1ltrGtLjWO+oZA4Bkb8wRCVqH7tS0Oj0WicxC0CIyL7gQrABljd2QjVFsqqLXyxMYtFqRlsySrHx9ODaYN7cMnYRE7sF41nG92rVFmquH/5/fx44EempUzjkcmPEOTj5IBHux0Kdxqlksw1xlKwE1CAQMwgGHyuUTpJHAdR/cGjA2ed1Gg0mlZwZwnmFKVUoRvTdwqbXbFibyGLUjP5fmsu9VY7g+JCeGjmYM4bmUB4YNsGWjawt3Qvd/x8BxkVGdw55k6uHnJ1y200tWWGmDQIStZaqCs3jvmFGSIy9CJjnTAa/Dp25kuNRqNpK7qKrAXyy2u58d21rEsvJdTfm8vHJXHJ2CSGJhzdy/u7/d/xwPIH8Pfy57UzXmNc7LjmA+dugdWvwKaPwFpjzKMSM8QQkySzdBLZV3cf1mg0XQ53CYwCfhARBbyilHq1cQARmQfMA0hOdt4JZEexMaOUG95ZS1mNhX9eNIzzRiYc9aySFruFZ1Kf4d3t7zIyeiRPn/x0k/OyYLPCjsWGn68Dy8HLH4ZfAkMvNkon2oGkRqPpBrhLYKYopbJFJAb4UUR2KKV+dQxgis6rYAy07EzjPl+fxV8+2UR0kC+f3DSZwfFH3223oLqAu365i3X567hi4BXcNfYuvD0bdUGuKjw0OVd5FoQmw7RHYNRsPTe9RqPpdrhFYJRS2eY6X0Q+A8YDv7Z8luux2RVPfreDV37dx4ReEfz3ytFEBvkedbyrc1Zz9293U2Wp4okTn+Cc3uccHiB7g1Fa2fwx2OqMgY5nPWkMdNSTc2k0mm5KpwuMiAQCHkqpCnP7DOCRzrajMWU1Fm5fuJ6lOwuYPTGFB2YOxtvz6HpdZZRn8Oy6Z/nxwI+khKTw6rRX6Rdudg+2WWDbF4awZKwC7wAYdaXh7j5mUAdckUaj0bgXd5RgegCfmT2mvID3lVLfucGOg+wtqGTu26mkF1Xz2AVDuXJCylHFV1ZXxmubXuO9He/h7eHNzSNv5urBVxPgHQCV+ZD65qE56sN7wpmPw8grwT+sQ65Ho9FougKdLjBKqX3AiM5Otzl+3pnPbR+sx9vTg/eun8CE3s5Pj9wYi93Cop2LeGnjS5TXlXN+3/O5ZdQtxATEQOZaozfYlk8bzVE/TY9P0Wg0xyTHbTdlpRSv/rqPf363gwGxIbx21RgSw1txY99CXEszlvLM2mfYX76fCbETuGvcXQyMGGh0M/7wWjiwDHyCYOy1RjWYHkmv0WiOcY5pgcmrysPH04dwv/DD9tdabPz10818tj6Lc4bF8dQlw532GdaYHcU7eGrNU6zOXU3PkJ68cOoLnJR4ElJbBt/ebcz86BcCZ/4DRs3SjiQ1Gs1xwzEtMK9vfp2FOxfSL7wf43qMY1zsOJL8h/KXRXvYmFnGndP6c8upfds2ZbBJfnU+/1n/H77Y8wWhvqHcO+FeLu5/Md54wob34X8PGt2Ox14Lp96vuxlrNJrjjmNaYC7sdyExATGsyV3DZ3s+4/0d7wOgfOI4++QJDO7rR1ldNGF+YU7HWW2pZsG2Bby55U0sdgtXD7maucPnEuITAjkb4eu7DEeTiePgyo8hfqRrLk6j0Wi6OMfNjJYfrknjge++IyTiAP1T8tlVuplaWy0A/cP7My52HON6jGNMjzFNCo5d2flq71c8v+558mvymZYyjT+N/hNJIUlQXQw/P2b0DPOPgGkPw4grdOO9RqNxK3pGSxdjtdn5x7c7eGNZGpP7jOLFK64jPNAHi83ClqItrMldw5rcNXyy6xPe2/4ecKTg7C7dzVNrnmJ78XaGRg7lqZOfYnSP0YZH47UL4KeHjdkgx82FU+7V3Y01Go2GY7wEU1Zt4ZYP1vHb7kKumdyTv50zCK9mBk82FpwN+RsOlnAAYgNjuWP0HZzV6yw8xAOy1sE3dxlejZMnwdlPQeywdl+jRqPRdDTuLsEc0wJz+8L1fLM5h8fOH8al45LadK6j4Ph7+XNJ/0vw8/KDqiKjxLLubQiKgWmPwvBLtTdjjUbT5dAC4wTtFZj88loySqoZk9IBPbjsNsMR5ZJHobYcJt4EJ9+tux1rNJoui7sF5phug4kpXktM4U4o8QdvP/AyF29/h20/wx1+w3FPnyNLIxlr4Js7jV5iPU80qsO0vzCNRqNpkWNaYNjysdGzq02IKUC+hvB4+UJJGgTHw8XzYciFujpMo9FonODYFphpj8JJfzFmgrTUgtVcLDVgrXN+//DLYPKt4Bvk7ivSaDSabsOxLTC+QVoUNBqNxk3okYAajUajcQlaYDQajUbjErTAaDQajcYlaIHRaDQajUtwi8CIyHQR2Skie0TkHnfYoNFoNBrX0ukCIyKewIvAWcBg4HIRGdzZdmg0Go3GtbijBDMe2KOU2qeUqgcWAue5wQ6NRqPRuBB3CEwCkOHwO9PcdxgiMk9EUkUktaCgoNOM02g0Gk3H4I6Blk35WTnC46ZS6lXgVQARKRCRA6427CiJAgrdbYQTaDs7lu5iJ3QfW7WdHUeKOxN3h8BkAo6+8xOB7JZOUEpFu9SiDkBEUt3ptdRZtJ0dS3exE7qPrdrOYwd3VJGtAfqJSC8R8QH+AHzpBjs0Go1G40I6vQSjlLKKyC3A94AnMF8ptbWz7dBoNBqNa3GLs0ul1DfAN+5I24W86m4DnETb2bF0Fzuh+9iq7TxG6BYzWmo0Go2m+6FdxWg0Go3GJWiB0Wg0Go1L0ALjJCKSJCI/i8h2EdkqIrc3EWaqiJSJyAZzecAdtpq27BeRzaYdqU0cFxF53vQHt0lERrvBxgEO92qDiJSLyB2NwrjlnorIfBHJF5EtDvsiRORHEdltrsObObdTfe01Y+tTIrLDfLafiUhYM+e2mE86wc6HRCTL4fme3cy5nXZPm7HzQwcb94vIhmbO7bT72S1QSunFiQWIA0ab28HALmBwozBTgcXuttW0ZT8Q1cLxs4FvMQa+TgRWudleTyAXSOkK9xQ4CRgNbHHY9yRwj7l9D/DPZq5jL9Ab8AE2Ns4nnWTrGYCXuf3Ppmx1Jp90gp0PAXc5kTc67Z42ZWej4/8CHnD3/ewOiy7BOIlSKkcptc7crgC204SLm27EecDbymAlECYicW605zRgr1KqS3hsUEr9ChQ32n0esMDcXgCc38Spne5rrylblVI/KKWs5s+VGAOa3Uoz99QZOvWetmSniAhwKfCBq9I/ltAC0w5EpCcwCljVxOFJIrJRRL4VkSGda9lhKOAHEVkrIvOaOO6UT7hO5A80/6ftKve0h1IqB4wPDiCmiTBd7b4CzMEorTZFa/mkM7jFrMqb30y1Y1e6pycCeUqp3c0c7wr3s8ugBaaNiEgQ8Alwh1KqvNHhdRhVPCOA/wCfd7J5jkxRSo3GmBbhjyJyUqPjTvmE6wxMjw7nAh81cbgr3VNn6DL3FUBE7gOswHvNBGktn7ial4A+wEggB6P6qTFd6Z5eTsulF3ffzy6FFpg2ICLeGOLynlLq08bHlVLlSqlKc/sbwFtEojrZzAZbss11PvAZRjWDI232CedCzgLWKaXyGh/oSvcUyGuoRjTX+U2E6TL3VUSuBmYAVyqzgaAxTuQTl6KUylNK2ZRSduC1ZtLvEvdURLyAC4EPmwvj7vvZ1dAC4yRm3esbwHal1DPNhIk1wyEi4zHub1HnWXnQjkARCW7Yxmjw3dIo2JfAVWZvsolAWUP1jxto9quwq9xTky+Bq83tq4EvmgjTJXztich04G7gXKVUdTNhnMknLqVRu98FzaTfJe4pcDqwQymV2dTBrnA/uxzu7mXQXRbgBIxi+SZgg7mcDdwI3GiGuQXYitHLZSUw2U229jZt2Gjac5+539FWwZhZdC+wGRjrJlsDMAQj1GGf2+8phuDlABaML+jrgEjgJ2C3uY4ww8YD3zicezZGL8O9DffeDbbuwWi3aMirLze2tbl80sl2vmPmv00YohHn7nvalJ3m/rca8qVDWLfdz+6waFcxGo1Go3EJuopMo9FoNC5BC4xGo9FoXIIWGI1Go9G4BC0wGo1Go3EJWmA0Go1G4xK0wGiOWUxPvXeZ24+IyOlNhJkqIotbiWdkc15+Wzin1Xjbiivi1GhciVumTNZoOhul1NG4+R8JjOXYm+Zbo3EpugSj6RKIyFWmw8ONIvKOuW+miKwSkfUi8j8R6WHuf8h0jLhURPaJyG0O8dxnzhvyP2CAw/63RORic3u6GHOlLMNw/dEQZryIrDDTWyHGfDU+wCPAZeYcH5eZI7bni8gaM2yLnn1FZJwZrnej/ascnXea1zOmKTuaiPNg6cz8vcV0woqIzBKR1aa9r4iIp7m8ZYbbLCJ/curBaDRHgS7BaNyO+ZK9D8NRYKGIRJiHlgETlVJKRK4H/gLcaR4bCJyCMTfPThF5CRiO4UZkFEbeXgesbZSWH4bPq1MxRrs7+pXaAZyklLKa1WmPK6UuEmOSs7FKqVvMOB4Hliil5ogxkddqEfmfUqqqiWubjOGk8zylVHqjwwsxXL8/aLpMiVdKrRWRkMZ2ABc5eS8HAZeZ99IiIv8FrsQYWZ6glBpqhgtzJj6N5mjQAqPpCpwKfKyUKgRQSjXMxZEIfGi+fH2ANIdzvlZK1QF1IpIP9MBwpf6ZMn1viUhT/qoGAmnKdLcuIu8CDW7VQ4EFItIPwy2QdzP2ngGc61CC8AOSMeYIcmQQ8CpwhjKdIDZiEfAj8CCG0DR4k3bWjqY4DRgDrDFduPljOOX8CugtIv8BvgZ+aEOcGk270FVkmq6A0LT79f8ALyilhgE3YLzIG6hz2LZx6GPJGd9HzYV5FPjZ/Mqf2Si9xvZepJQaaS7JSqnG4gKGP6tajBLVkUYolQUUichwjFLHwjbYYeXw/29DGAEWONg2QCn1kFKqBBgBLAX+CLzezLVpNB2GFhhNV+An4FIRiQRwqCILBbLM7aubOrERvwIXiIi/6dV2ZhNhdgC9RKSP+ftyh2OO6V3jsL8Coyquge+BWx28PDcpIEApcA7wuIhMbSbMQoyqv1Cl1OZW7HBkP8a0vojIaKCXuf8n4GIRiTGPRYhIihhTHHgopT4B7m84V6NxJVpgNG5HKbUVeAz4RUQ2Ag3TITwEfCQivwGFTsSzDqNNZQPGvD2/NRGmFqNK7Guzkd9xiuYngX+IyHKMeeAb+BkY3NDIj1HC8AY2icgW83dzNuVhCN2LIjKhiSAfY7QbLXLCDkc+ASJEZANwE4anYZRS24C/YcyquAmjCi4OYwbIpWb4t4C/NmezRtNRaG/KGo1Go3EJugSj0Wg0GpegBUaj0Wg0LkELjEaj0WhcghYYjUaj0bgELTAajUajcQlaYDQajUbjErTAaDQajcYl/D/HRvedw9xArgAAAABJRU5ErkJggg==
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that the error is largest ar k=1 for the test data, this is consistent with the assertion that we have strong overfitting at small values of k (more analysis on that to follow later).</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># find optimal k values for each fold using R2 score</span>
<span class="n">k_opt_arr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">k_opt</span> <span class="o">=</span> <span class="n">k_arr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">R2</span><span class="p">[:,</span><span class="n">i</span><span class="p">])]</span>
        <span class="n">k_opt_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k_opt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;List of optimal k values for each fold (using R2 score):&#39;</span><span class="p">,</span> <span class="n">k_opt_arr</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>List of optimal k values for each fold (using R2 score): [1, 2, 2, 2, 3]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Find optimal k for folds and show plot of errors for one of the folds:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[492]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get maximum value of R2 score</span>
<span class="n">fold_index</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">k_opt3</span> <span class="o">=</span> <span class="n">k_arr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">R2</span><span class="p">[:,</span><span class="n">fold_index</span><span class="p">])]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal k for fold 3 calculated with R2 score is k =&#39;</span><span class="p">,</span><span class="n">k_opt3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">R2</span><span class="p">[:,</span><span class="n">fold_index</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fold 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_opt3</span><span class="p">,</span><span class="n">R2</span><span class="p">[</span><span class="n">k_opt3</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">fold_index</span><span class="p">],</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;smallest error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R2 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;R2 scores calculated over fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">fold_index</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># get minimum value of MSE</span>
<span class="n">k_opt3</span> <span class="o">=</span> <span class="n">k_arr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ERR_in</span><span class="p">[:,</span><span class="n">fold_index</span><span class="p">])]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal k for fold 2 calculated with validation MSE is k =&#39;</span><span class="p">,</span><span class="n">k_opt3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">ERR_in</span><span class="p">[:,</span><span class="n">fold_index</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fold 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_opt3</span><span class="p">,</span><span class="n">ERR_in</span><span class="p">[</span><span class="n">k_opt3</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">fold_index</span><span class="p">],</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;smallest error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;validation MSEs calculated over fold &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">fold_index</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Optimal k for fold 3 calculated with R2 score is k = 2
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Optimal k for fold 3 calculated with validation MSE is k = 2
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The optimal k calculated using the MSE for this fold and the R2 score (errors) for this fold is the same. We see explicitly that these criteria for optimising the hyperparameter are equivalent.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="1.3.2.">1.3.2.<a class="anchor-link" href="#1.3.2.">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now analyse the in-sample and out-of-sample MSE to determine the optimal k:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[491]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># in-sample validation MSE </span>
<span class="n">mse_avg_in</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">ERR_in</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># get the average over the 5 folds of the ERR_val matrix</span>
<span class="c1"># get minimum k over the avg of five folds</span>
<span class="n">k_opt_mse_in</span> <span class="o">=</span> <span class="n">k_arr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_avg_in</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">mse_avg_in</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;in-sample&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_opt_mse_in</span><span class="p">,</span><span class="n">mse_avg_in</span><span class="p">[</span><span class="n">k_opt_mse_in</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;smallest error in&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;MSE averaged over the 5 folds for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Minimal in-sample MSE at optimal k =&#39;</span><span class="p">,</span><span class="n">k_opt_mse_in</span><span class="p">,</span><span class="s1">&#39;, averaged over the 5 folds:&#39;</span><span class="p">,</span><span class="n">mse_avg_in</span><span class="p">[</span><span class="n">k_opt_mse_in</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


<span class="c1"># out-of-sample MSE</span>
<span class="n">mse_avg_out</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">ERR_out</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># get the average over the 5 folds of the ERR_out matrix</span>
<span class="n">k_opt_mse_out</span> <span class="o">=</span> <span class="n">k_arr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_avg_out</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_arr</span><span class="p">,</span><span class="n">mse_avg_out</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;out-of-sample&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_opt_mse_out</span><span class="p">,</span><span class="n">mse_avg_out</span><span class="p">[</span><span class="n">k_opt_mse_out</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;smallest error out&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;MSE averaged over the 5 folds for candidate k values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Minimal out-of-sample MSE at optimal k =&#39;</span><span class="p">,</span><span class="n">k_opt_mse_out</span><span class="p">,</span><span class="s1">&#39;, averaged over the 5 folds:&#39;</span><span class="p">,</span><span class="n">mse_avg_out</span><span class="p">[</span><span class="n">k_opt_mse_out</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Minimal in-sample MSE at optimal k = 2 , averaged over the 5 folds: 4.61993125
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Minimal out-of-sample MSE at optimal k = 4 , averaged over the 5 folds: 14.627162990196078
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>This is significantly better than the linear or Ridge regression, importantly, there is a reduction from 19.17 to 14.627 in the out-of-sample MSE. Note that the kNN can reduce overfitting, for a suitable choice of k.</p>
<p>We get the relatively small optimal k=2 in the in-sample MSE, because the training set has been memorised in this case and we have overfitted the data, clearly having k=2 results in overfitting in the out-of-sample MSE. Even more so if we choose k=1, where the out-of-sample MSE is largest. This, again, is because we have high accuracy but high variance.</p>
<p>As we increase k seekin glower variance, we are tweaking the bias-variance balance and get lower accuracy (higher bias). This is reflected in the increasing in-sample MSE values as we increase k. However, looking at the out-of-sample MSE, we see that it is significantly smaller for k=3,4,5 than for k=1,2, suggesting we are decreasing the variance (at the cost of bias/accuracy). Our cross-validation results suggest that the optimal parameter k that minimises the out-of-sample MSE is k=4.</p>
<p>Therefore, I would take k=3 or k=4 for a reasonable bias-variance balance. Let us check whether these values of k are indeed the optimal for the testing set.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Let us check the MSE for varying values of k on the test set</span>
<span class="n">mse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">y_knn</span> <span class="o">=</span> <span class="n">reg_predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_knn</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_out</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span><span class="n">mse</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Quality of prediction on the test set depending on values of k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">min_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The minimal value of the MSE for the test set is&#39;</span><span class="p">,</span><span class="n">mse</span><span class="p">[</span><span class="n">min_k</span><span class="p">],</span><span class="s1">&#39;at k =&#39;</span><span class="p">,</span><span class="n">min_k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>The minimal value of the MSE for the test set is 12.530446623093683 at k = 3
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The reason why kNN works so much better may be that our data is non-linear (predictors are non-linearly distributed), thus local methods such as kNN are better-suited to work with rather than linear methods that were shown to produce MSEs that are almost twice as large.</p>
<p>Moreover, if we had not cleaned the data from collinear columns, we probably have gotten a smaller value of k as optimal foro the training set, which would lead to overfitting as the data would be more clustered in this case. This justifies removing the collinear columns.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Task-2:-Classification">Task 2: Classification<a class="anchor-link" href="#Task-2:-Classification">&#182;</a></h2>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Loading-and-cleaning-the-classification-dataset">Loading and cleaning the classification dataset<a class="anchor-link" href="#Loading-and-cleaning-the-classification-dataset">&#182;</a></h3>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Save-the-data">Save the data<a class="anchor-link" href="#Save-the-data">&#182;</a></h4>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Train data</span>
<span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_train.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.161765</td>
      <td>0.25</td>
      <td>0.363156</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.267857</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.470588</td>
      <td>0.50</td>
      <td>0.858754</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.428571</td>
      <td>1.000000</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.117647</td>
      <td>0.00</td>
      <td>0.138054</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>0.333333</td>
      <td>1.000000</td>
      <td>0.333333</td>
      <td>0.267857</td>
      <td>0.666667</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check for duplicate rows, none found</span>
<span class="n">dup</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dup</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">dup</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;found duplicate at&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>

<span class="n">dup_rows</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="n">data_train</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Duplicate rows dataframe:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dup_rows</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Duplicate rows dataframe:
Empty DataFrame
Columns: [col0, col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11]
Index: []
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check for collinearity with a boxplot</span>
<span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span> 
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Columns 5 and 6 look colinear, remove them</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test data</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_test.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[9]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.205882</td>
      <td>0.5</td>
      <td>0.069055</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>1.000000</td>
      <td>0.333333</td>
      <td>1.0</td>
      <td>0.232143</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.382353</td>
      <td>0.0</td>
      <td>0.238418</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.0</td>
      <td>0.232143</td>
      <td>0.666667</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check for colinearity with a boxplot</span>
<span class="n">header1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
<span class="n">boxplot</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">header1</span><span class="p">)</span> 
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Column 5 and column 6 look colinear, we need to eliminate them</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get X (predictors) and y (target variable) for train and test from dataframes</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;N =&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">data_train</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>N = 800
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># training set into matrix</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;full dataset size&#39;</span><span class="p">,</span><span class="n">arr_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># eliminate the sixth column in train set</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_train</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># shuffle it with the same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_train</span><span class="p">)</span>
<span class="c1"># split it</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;shape of matrix X containing training predictors&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;length of y_train&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="c1"># test set into matrix</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1"># eliminate the sixth column in train set and test set</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_test</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># shuffle it with same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_test</span><span class="p">)</span>
<span class="c1"># split it</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">shapes of X_train and X_test:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>full dataset size (800, 12)
shape of matrix X containing training predictors (10, 800)
length of y_train 800

shapes of X_train and X_test:
 (10, 800)
(10, 200)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Our data set that has features over different ranges: we must standardise</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># standardize the X_train and X_test</span>
<span class="k">def</span> <span class="nf">standardise</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
  <span class="k">return</span> <span class="n">X_std</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="2.1.-Logistic-Regression">2.1. Logistic Regression<a class="anchor-link" href="#2.1.-Logistic-Regression">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="2.1.1.">2.1.1.<a class="anchor-link" href="#2.1.1.">&#182;</a></h5><p>In this subsection, we implement logistic regression for classification with gradient descent for 5000 iterations; and perform a grid-search with 5-fold cross validation to find optimal set of hyperparameters: learning rate and decision threshold.</p>
<p>First, we define the functions to implement the logistic regression model.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define the functions we will need in this part for logistic regression</span>
<span class="k">def</span> <span class="nf">logistic</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">predict_log</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">):</span>
    <span class="n">y_log</span> <span class="o">=</span> <span class="n">logistic</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">beta_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_log</span>


<span class="k">def</span> <span class="nf">initialise</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">beta_0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">beta_0</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span>


<span class="k">def</span> <span class="nf">propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_log</span> <span class="o">=</span> <span class="n">predict_log</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">)</span>

    <span class="c1"># cost function</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_log</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_log</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># derivatives</span>
    <span class="n">dbeta</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">y_log</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">dbeta_0</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_log</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span> 

    <span class="k">assert</span><span class="p">(</span><span class="n">dbeta</span><span class="o">.</span><span class="n">shape</span><span class="o">==</span><span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">dbeta_0</span><span class="o">.</span><span class="n">dtype</span><span class="o">==</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">cost</span><span class="o">.</span><span class="n">shape</span><span class="o">==</span><span class="p">())</span>

    <span class="c1"># store gradients in a dictionary</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dbeta&quot;</span><span class="p">:</span> <span class="n">dbeta</span><span class="p">,</span> <span class="s2">&quot;dbeta_0&quot;</span><span class="p">:</span> <span class="n">dbeta_0</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">grads</span><span class="p">,</span> <span class="n">cost</span>


<span class="k">def</span> <span class="nf">optimise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>

        <span class="c1"># calculate cost and gradients</span>
        <span class="n">grads</span><span class="p">,</span> <span class="n">cost</span> <span class="o">=</span> <span class="n">propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">)</span>

        <span class="c1"># retrieve derivatives from grads</span>
        <span class="n">dbeta</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dbeta&quot;</span><span class="p">]</span>
        <span class="n">dbeta_0</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dbeta_0&quot;</span><span class="p">]</span>

        <span class="c1"># updating procedure</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dbeta</span> 
        <span class="n">beta_0</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dbeta_0</span> 

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span> <span class="c1"># append the cost</span>
      
        <span class="c1"># print the cost every 100 iterations</span>
        <span class="k">if</span> <span class="n">print_cost</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;cost after iteration </span><span class="si">%i</span><span class="s2">: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>
  
    <span class="c1"># save parameters and gradients in dictionary</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="n">beta</span><span class="p">,</span> <span class="s2">&quot;beta_0&quot;</span><span class="p">:</span> <span class="n">beta_0</span><span class="p">}</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dbeta&quot;</span><span class="p">:</span> <span class="n">dbeta</span><span class="p">,</span> <span class="s2">&quot;dbeta_0&quot;</span><span class="p">:</span> <span class="n">dbeta_0</span><span class="p">}</span>
  
    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">costs</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># function to predict the classification labels </span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">):</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
  <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
  
  <span class="c1"># compute vector y_log predicting the probabilities</span>
  <span class="n">y_log</span> <span class="o">=</span> <span class="n">predict_log</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">)</span>
  
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_log</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
      <span class="c1"># convert probabilities y_log to actual predictions y_pred</span>
      <span class="k">if</span> <span class="n">y_log</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">decision_threshold</span><span class="p">:</span>
          <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
          <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  
  <span class="k">assert</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">y_pred</span>


<span class="c1"># define model</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="c1"># initialize parameters with zeros</span>
  <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span> <span class="o">=</span> <span class="n">initialise</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

  <span class="c1"># gradient descent</span>
  <span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="n">optimise</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="n">print_cost</span><span class="p">)</span>

  <span class="c1"># retrieve parameters beta and beta_0 from dictionary &quot;parameters&quot;</span>
  <span class="n">beta</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span>
  <span class="n">beta_0</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;beta_0&quot;</span><span class="p">]</span>

  <span class="c1"># predict test and train set examples</span>
  <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">)</span>
  <span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">)</span>
  
  <span class="c1"># print train/test Errors</span>
  <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_pred_train</span> <span class="o">-</span> <span class="n">y_train</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
  <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_pred_test</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
  <span class="k">if</span> <span class="n">print_acc</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train accuracy: </span><span class="si">{}</span><span class="s2"> %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_acc</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test accuracy: </span><span class="si">{}</span><span class="s2"> %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

  <span class="c1"># saving all information</span>
  <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;costs&quot;</span><span class="p">:</span> <span class="n">costs</span><span class="p">,</span> <span class="s2">&quot;y_pred_test&quot;</span><span class="p">:</span> <span class="n">y_pred_test</span><span class="p">,</span> <span class="s2">&quot;y_pred_train&quot;</span><span class="p">:</span> <span class="n">y_pred_train</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="n">beta</span><span class="p">,</span> <span class="s2">&quot;beta_0&quot;</span><span class="p">:</span> <span class="n">beta_0</span><span class="p">,</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="s2">&quot;num_iterations&quot;</span><span class="p">:</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="s2">&quot;train_acc&quot;</span><span class="p">:</span> <span class="n">train_acc</span><span class="p">,</span> <span class="s2">&quot;test_acc&quot;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">}</span>
  
  <span class="k">return</span> <span class="n">d</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Investigate the sensitivity of the model to slight variations in the decision threshold and learning rate.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">d1</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d4</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d5</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.002</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>(10, 800)
(800,)
(10, 200)
(200,)
train accuracy: 72.125 %
test accuracy: 76.0 %
train accuracy: 72.0 %
test accuracy: 74.5 %
train accuracy: 72.875 %
test accuracy: 71.5 %
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Get ready for a 5-fold cross validation: split the datasets in folds</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>

    <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>  <span class="c1"># we get transposed folds, data is (800, 11) dimensional</span>

    <span class="n">train_accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_accs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># define the training set</span>
        <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># transpose the data to use logistic regression</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># define the validation set</span>
        <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># train the model</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># evaluate</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;train_acc&quot;</span><span class="p">]</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span>

        <span class="n">train_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">val_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_accs</span><span class="p">,</span> <span class="n">val_accs</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now turn to the hyperparameters - learning_rate and decision_threshold, and build a 5x5 hyperparameter grid to find their optimal values based on the accuracy of their predictions.</p>
<p>The learning rate determines how fast we converge to the desired values; if it is too small, we will need too many iterations to converge to the desired values. The decision threshold is the probability threshold at which we assign 1 to the prediction, essentially, if the probability y_log is above the decision threshold, the preciction is 1.</p>
<p>Now, define a function grid() where we perform a grid search through the candidate hyperparameters. It is a double for loop, where at each iteration we save the accuracies and the two parameters used to get that accuracy in three separate lists, recording their indices. When done looping over the parameters, we find the index of the largest accuracy and then look up the (optimal) parameters used to get that maximum accuracy.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define a 5x5 hyperparameter grid </span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.003</span><span class="p">,</span><span class="mf">0.005</span><span class="p">,</span><span class="mf">0.007</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]</span>
<span class="n">dec_thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.45</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">]</span>

<span class="c1"># take the validation accuracy as the metric</span>
<span class="k">def</span> <span class="nf">grid</span><span class="p">(</span><span class="n">data_train</span><span class="p">):</span>
    <span class="n">list_lr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">list_dt</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">list_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Learning rate&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
        <span class="n">list_lr_row</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">list_dt_row</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">list_accuracy_row</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">dec_thresholds</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Decision threshold&#39;</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
            <span class="c1"># returns lists of training and validation accuracies</span>
            <span class="n">train_accs</span><span class="p">,</span> <span class="n">val_accs</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="c1"># 5 is the number of folds</span>
            <span class="c1"># get average over the 5 folds</span>
            <span class="n">val_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_accs</span><span class="p">)</span>
            <span class="n">list_lr_row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">list_dt_row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
            <span class="n">list_accuracy_row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
        <span class="n">list_lr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_lr_row</span><span class="p">)</span>
        <span class="n">list_dt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_dt_row</span><span class="p">)</span>
        <span class="n">list_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_accuracy_row</span><span class="p">)</span>

    <span class="n">list_lr</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list_lr</span><span class="p">)</span>
    <span class="n">list_dt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list_dt</span><span class="p">)</span>
    <span class="n">list_accuracy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list_accuracy</span><span class="p">)</span>
    
    <span class="n">max_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">list_accuracy</span><span class="p">)</span>
    <span class="n">index_max_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">list_accuracy</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">list_accuracy</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Maximum validation accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">max_acc</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal learning value: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">list_lr</span><span class="p">[</span><span class="n">index_max_acc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">index_max_acc</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal decision threshold: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">list_dt</span><span class="p">[</span><span class="n">index_max_acc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">index_max_acc</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
    <span class="k">return</span> <span class="n">list_lr</span><span class="p">,</span><span class="n">list_dt</span><span class="p">,</span><span class="n">list_accuracy</span>

<span class="c1"># TODO: output the folds and use them in the random forest just to be sure</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># stack X_train and y_train together, delete the as.array in &quot;train_set =&quot;</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of stacked X and y cleaned train data&#39;</span><span class="p">,</span><span class="n">data_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># perform grid search</span>
<span class="n">learn_rate</span><span class="p">,</span><span class="n">dec_thr</span><span class="p">,</span><span class="n">val_acc</span> <span class="o">=</span> <span class="n">grid</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Shape of stacked X and y cleaned train data (800, 11)

Learning rate 0.001
Decision threshold 0.35
Fold 1
train accuracy: 70.3125 %
test accuracy: 73.5 %
Fold 2
train accuracy: 70.625 %
test accuracy: 73.5 %
Fold 3
train accuracy: 70.625 %
test accuracy: 73.5 %
Fold 4
train accuracy: 70.15625 %
test accuracy: 73.5 %
Fold 5
train accuracy: 70.3125 %
test accuracy: 73.5 %
Decision threshold 0.4
Fold 1
train accuracy: 72.1875 %
test accuracy: 74.5 %
Fold 2
train accuracy: 72.1875 %
test accuracy: 74.5 %
Fold 3
train accuracy: 72.34375 %
test accuracy: 74.5 %
Fold 4
train accuracy: 72.1875 %
test accuracy: 74.5 %
Fold 5
train accuracy: 71.71875 %
test accuracy: 74.5 %
Decision threshold 0.45
Fold 1
train accuracy: 72.5 %
test accuracy: 72.5 %
Fold 2
train accuracy: 74.21875 %
test accuracy: 75.0 %
Fold 3
train accuracy: 73.59375 %
test accuracy: 74.0 %
Fold 4
train accuracy: 73.90625 %
test accuracy: 74.5 %
Fold 5
train accuracy: 71.5625 %
test accuracy: 71.0 %
Decision threshold 0.5
Fold 1
train accuracy: 72.34375 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.125 %
test accuracy: 76.0 %
Fold 3
train accuracy: 72.34375 %
test accuracy: 76.0 %
Fold 4
train accuracy: 73.90625 %
test accuracy: 73.0 %
Fold 5
train accuracy: 71.40625 %
test accuracy: 75.5 %
Decision threshold 0.6
Fold 1
train accuracy: 74.21875 %
test accuracy: 73.0 %
Fold 2
train accuracy: 72.5 %
test accuracy: 71.5 %
Fold 3
train accuracy: 72.65625 %
test accuracy: 71.5 %
Fold 4
train accuracy: 72.1875 %
test accuracy: 69.0 %
Fold 5
train accuracy: 72.5 %
test accuracy: 68.5 %

Learning rate 0.003
Decision threshold 0.35
Fold 1
train accuracy: 73.75 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.90625 %
test accuracy: 73.0 %
Fold 3
train accuracy: 74.21875 %
test accuracy: 75.0 %
Fold 4
train accuracy: 73.4375 %
test accuracy: 75.0 %
Fold 5
train accuracy: 72.5 %
test accuracy: 74.5 %
Decision threshold 0.4
Fold 1
train accuracy: 73.90625 %
test accuracy: 73.5 %
Fold 2
train accuracy: 74.0625 %
test accuracy: 75.0 %
Fold 3
train accuracy: 74.375 %
test accuracy: 77.5 %
Fold 4
train accuracy: 73.90625 %
test accuracy: 75.0 %
Fold 5
train accuracy: 72.5 %
test accuracy: 76.0 %
Decision threshold 0.45
Fold 1
train accuracy: 73.4375 %
test accuracy: 78.0 %
Fold 2
train accuracy: 73.75 %
test accuracy: 72.5 %
Fold 3
train accuracy: 73.4375 %
test accuracy: 71.5 %
Fold 4
train accuracy: 75.625 %
test accuracy: 71.5 %
Fold 5
train accuracy: 72.1875 %
test accuracy: 76.0 %
Decision threshold 0.5
Fold 1
train accuracy: 73.4375 %
test accuracy: 70.5 %
Fold 2
train accuracy: 74.84375 %
test accuracy: 73.5 %
Fold 3
train accuracy: 75.15625 %
test accuracy: 69.5 %
Fold 4
train accuracy: 73.125 %
test accuracy: 71.0 %
Fold 5
train accuracy: 72.65625 %
test accuracy: 65.0 %
Decision threshold 0.6
Fold 1
train accuracy: 74.0625 %
test accuracy: 68.5 %
Fold 2
train accuracy: 72.03125 %
test accuracy: 70.0 %
Fold 3
train accuracy: 72.65625 %
test accuracy: 68.5 %
Fold 4
train accuracy: 72.8125 %
test accuracy: 68.5 %
Fold 5
train accuracy: 71.875 %
test accuracy: 68.5 %

Learning rate 0.005
Decision threshold 0.35
Fold 1
train accuracy: 73.90625 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.90625 %
test accuracy: 73.0 %
Fold 3
train accuracy: 74.0625 %
test accuracy: 76.0 %
Fold 4
train accuracy: 73.59375 %
test accuracy: 76.0 %
Fold 5
train accuracy: 72.96875 %
test accuracy: 74.5 %
Decision threshold 0.4
Fold 1
train accuracy: 74.21875 %
test accuracy: 76.0 %
Fold 2
train accuracy: 73.90625 %
test accuracy: 76.5 %
Fold 3
train accuracy: 74.0625 %
test accuracy: 75.0 %
Fold 4
train accuracy: 74.53125 %
test accuracy: 75.0 %
Fold 5
train accuracy: 71.875 %
test accuracy: 76.0 %
Decision threshold 0.45
Fold 1
train accuracy: 72.65625 %
test accuracy: 76.5 %
Fold 2
train accuracy: 75.3125 %
test accuracy: 71.5 %
Fold 3
train accuracy: 74.21875 %
test accuracy: 68.5 %
Fold 4
train accuracy: 75.78125 %
test accuracy: 72.5 %
Fold 5
train accuracy: 72.34375 %
test accuracy: 72.5 %
Decision threshold 0.5
Fold 1
train accuracy: 74.53125 %
test accuracy: 71.0 %
Fold 2
train accuracy: 75.0 %
test accuracy: 67.0 %
Fold 3
train accuracy: 75.15625 %
test accuracy: 65.5 %
Fold 4
train accuracy: 73.59375 %
test accuracy: 68.0 %
Fold 5
train accuracy: 73.59375 %
test accuracy: 67.0 %
Decision threshold 0.6
Fold 1
train accuracy: 73.59375 %
test accuracy: 68.0 %
Fold 2
train accuracy: 73.28125 %
test accuracy: 68.5 %
Fold 3
train accuracy: 72.5 %
test accuracy: 67.5 %
Fold 4
train accuracy: 72.65625 %
test accuracy: 68.5 %
Fold 5
train accuracy: 71.25 %
test accuracy: 68.5 %

Learning rate 0.007
Decision threshold 0.35
Fold 1
train accuracy: 73.90625 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.28125 %
test accuracy: 73.0 %
Fold 3
train accuracy: 74.0625 %
test accuracy: 76.0 %
Fold 4
train accuracy: 73.75 %
test accuracy: 76.0 %
Fold 5
train accuracy: 72.96875 %
test accuracy: 74.5 %
Decision threshold 0.4
Fold 1
train accuracy: 74.0625 %
test accuracy: 76.0 %
Fold 2
train accuracy: 74.0625 %
test accuracy: 76.0 %
Fold 3
train accuracy: 73.90625 %
test accuracy: 75.0 %
Fold 4
train accuracy: 73.4375 %
test accuracy: 74.0 %
Fold 5
train accuracy: 71.40625 %
test accuracy: 72.5 %
Decision threshold 0.45
Fold 1
train accuracy: 72.65625 %
test accuracy: 75.5 %
Fold 2
train accuracy: 75.15625 %
test accuracy: 73.0 %
Fold 3
train accuracy: 74.0625 %
test accuracy: 72.0 %
Fold 4
train accuracy: 75.3125 %
test accuracy: 72.0 %
Fold 5
train accuracy: 72.8125 %
test accuracy: 72.5 %
Decision threshold 0.5
Fold 1
train accuracy: 74.6875 %
test accuracy: 68.0 %
Fold 2
train accuracy: 75.15625 %
test accuracy: 65.0 %
Fold 3
train accuracy: 75.46875 %
test accuracy: 65.5 %
Fold 4
train accuracy: 73.59375 %
test accuracy: 68.0 %
Fold 5
train accuracy: 73.59375 %
test accuracy: 68.0 %
Decision threshold 0.6
Fold 1
train accuracy: 72.8125 %
test accuracy: 68.0 %
Fold 2
train accuracy: 73.59375 %
test accuracy: 68.0 %
Fold 3
train accuracy: 72.8125 %
test accuracy: 67.5 %
Fold 4
train accuracy: 72.34375 %
test accuracy: 68.5 %
Fold 5
train accuracy: 71.09375 %
test accuracy: 67.5 %

Learning rate 0.1
Decision threshold 0.35
Fold 1
train accuracy: 72.96875 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.75 %
test accuracy: 72.5 %
Fold 3
train accuracy: 72.96875 %
test accuracy: 74.5 %
Fold 4
train accuracy: 74.53125 %
test accuracy: 75.0 %
Fold 5
train accuracy: 73.28125 %
test accuracy: 74.0 %
Decision threshold 0.4
Fold 1
train accuracy: 74.53125 %
test accuracy: 74.5 %
Fold 2
train accuracy: 73.4375 %
test accuracy: 74.0 %
Fold 3
train accuracy: 74.375 %
test accuracy: 74.0 %
Fold 4
train accuracy: 73.90625 %
test accuracy: 72.5 %
Fold 5
train accuracy: 72.1875 %
test accuracy: 73.0 %
Decision threshold 0.45
Fold 1
train accuracy: 74.0625 %
test accuracy: 74.0 %
Fold 2
train accuracy: 75.9375 %
test accuracy: 69.5 %
Fold 3
train accuracy: 74.6875 %
test accuracy: 65.5 %
Fold 4
train accuracy: 73.90625 %
test accuracy: 72.0 %
Fold 5
train accuracy: 71.875 %
test accuracy: 68.0 %
Decision threshold 0.5
Fold 1
train accuracy: 74.21875 %
test accuracy: 70.0 %
Fold 2
train accuracy: 75.9375 %
test accuracy: 64.0 %
Fold 3
train accuracy: 74.6875 %
test accuracy: 67.5 %
Fold 4
train accuracy: 74.375 %
test accuracy: 68.0 %
Fold 5
train accuracy: 72.96875 %
test accuracy: 70.0 %
Decision threshold 0.6
Fold 1
train accuracy: 72.65625 %
test accuracy: 66.0 %
Fold 2
train accuracy: 73.59375 %
test accuracy: 67.5 %
Fold 3
train accuracy: 73.59375 %
test accuracy: 67.0 %
Fold 4
train accuracy: 73.75 %
test accuracy: 67.5 %
Fold 5
train accuracy: 72.5 %
test accuracy: 68.5 %
Maximum validation accuracy: 75.700000
Optimal learning value: 0.005000
Optimal decision threshold: 0.400000
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Print the grid search results:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># results:</span>
<span class="n">max_acc1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">val_acc</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">val_acc</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Maximum validation accuracy:&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">val_acc</span><span class="p">),</span><span class="s1">&#39;%&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal learning rate:&#39;</span><span class="p">,</span><span class="n">learn_rate</span><span class="p">[</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal decision threshold:&#39;</span><span class="p">,</span><span class="n">dec_thr</span><span class="p">[</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Maximum validation accuracy: 75.7 %
Optimal learning rate: 0.005
Optimal decision threshold: 0.4
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>It is very slow, grid search which is a brute-force method which is not the best way to search for optimal parameters.</p>
<p>Now investigate how the cost decreases for different learning rates as we go through the iterations with our fixed decision threshold, this is to see how fast the convergence is.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># candidate learning rates</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.003</span><span class="p">,</span><span class="mf">0.005</span><span class="p">,</span><span class="mf">0.007</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;costs&#39;</span><span class="p">]),</span><span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;cost&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of iterations in hundreds&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that we get the best accuracy results for learning rate 0.005. We see that it is among the faster convergent learning rates. Note that merely looking at the cost is not enough because if we choose the cost too low, there is a danger of overfitting. And with a very small learning rate we see that the cost is higher, convergence is not as fast and we are in danger of having a model that is too general and has high variance.</p>
<p>In the next subsection, we will check the difference between the train and test accuracies - we will see that the model is overfitting if the train accuracy is higher than the test accuracy. This will justify and guide our choice of the optimal parameters.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="2.1.2.">2.1.2.<a class="anchor-link" href="#2.1.2.">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now compare the performance of the optimal model on the training data and on the test data by their mean accuracies.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># optimal hyperparameters</span>
<span class="n">learning_rate_opt</span> <span class="o">=</span> <span class="n">learn_rate</span><span class="p">[</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">decision_threshold_opt</span> <span class="o">=</span> <span class="n">dec_thr</span><span class="p">[</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">max_acc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Optimal:</span><span class="se">\n</span><span class="s1">Learning rate:&#39;</span><span class="p">,</span><span class="n">learning_rate_opt</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Decision threshold:&#39;</span><span class="p">,</span><span class="n">decision_threshold_opt</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold_opt</span><span class="p">,</span> <span class="n">learning_rate_opt</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># vary learning_rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">decision_threshold</span> <span class="o">=</span> <span class="n">decision_threshold_opt</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Varying learning rate:</span><span class="se">\n</span><span class="s1">Learning rate:&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Decision threshold:&#39;</span><span class="p">,</span><span class="n">decision_threshold</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">decision_threshold</span> <span class="o">=</span> <span class="n">decision_threshold_opt</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Learning rate:&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Decision threshold:&#39;</span><span class="p">,</span><span class="n">decision_threshold</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># vary decision_threshold</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate_opt</span>
<span class="n">decision_threshold</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Varying decision threshold:</span><span class="se">\n</span><span class="s1">Learning rate:&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Decision threshold:&#39;</span><span class="p">,</span><span class="n">decision_threshold</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate_opt</span>
<span class="n">decision_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Learning rate:&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Decision threshold:&#39;</span><span class="p">,</span><span class="n">decision_threshold</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decision_threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">print_acc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Optimal:
Learning rate: 0.005 
Decision threshold: 0.4
train accuracy: 74.125 %
test accuracy: 76.0 %

Varying learning rate:
Learning rate: 0.001 
Decision threshold: 0.4
train accuracy: 72.0 %
test accuracy: 74.5 %

Learning rate: 0.05 
Decision threshold: 0.4
train accuracy: 73.375 %
test accuracy: 75.5 %

Varying decision threshold:
Learning rate: 0.005 
Decision threshold: 0.3
train accuracy: 73.5 %
test accuracy: 74.5 %

Learning rate: 0.005 
Decision threshold: 0.5
train accuracy: 74.625 %
test accuracy: 67.0 %
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>For the optimal parameters we found using the grid search, the difference between the train accuracy and test accuracy (averaged over the 5 folds) is quite small, the test accuracy is bigger which means our model is not overfitted. It is not performing very well, thus suggesting that it may have larger variance than we would want.</p>
<p>Also, comparing to these accuracies to some accuracies computed with non-optimal values, both the train and test accuracy is significantly better than with non-optimal parameters. This means that the model is well-fitted to the training data, but it is not overfitting due to cross-validation, as can be seen by the improved mean test accuracy.</p>
<p>Varying the parameters a bit and comparing the accuracies we get, we see that the model is more sensitive to changes in decision threshold rather than learning rate.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="2.2.-Random-Forests">2.2. Random Forests<a class="anchor-link" href="#2.2.-Random-Forests">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="2.2.1.">2.2.1.<a class="anchor-link" href="#2.2.1.">&#182;</a></h5>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get the data ready</span>
<span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_train.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[65]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.161765</td>
      <td>0.25</td>
      <td>0.363156</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.267857</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.470588</td>
      <td>0.50</td>
      <td>0.858754</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.428571</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test data</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_test.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="n">data_test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[66]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col0</th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
      <th>col5</th>
      <th>col6</th>
      <th>col7</th>
      <th>col8</th>
      <th>col9</th>
      <th>col10</th>
      <th>col11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.205882</td>
      <td>0.5</td>
      <td>0.069055</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>1.000000</td>
      <td>0.333333</td>
      <td>1.0</td>
      <td>0.232143</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.382353</td>
      <td>0.0</td>
      <td>0.238418</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.0</td>
      <td>0.232143</td>
      <td>0.666667</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># training set into matrix</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;full dataset size&#39;</span><span class="p">,</span><span class="n">arr_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># eliminate the sixth column in train set</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_train</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># shuffle it with the same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_train</span><span class="p">)</span> <span class="c1"># this is a numpy array</span>

<span class="c1"># split it</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>



<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;shape of matrix X containing training predictors&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;length of y_train&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="c1"># test set into matrix</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1"># eliminate the sixth column in train set and test set</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_test</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># shuffle it with same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_test</span><span class="p">)</span>
<span class="c1"># split it</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">shapes of X_train and X_test:&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>full dataset size (800, 12)
shape of matrix X containing training predictors (800, 10)
length of y_train 800

shapes of X_train and X_test: (800, 10) (200, 10)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># standardize the X_train and X_test</span>
<span class="k">def</span> <span class="nf">standardise</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="k">return</span> <span class="n">X_std</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define cross-entropy loss function to account for information gain</span>
<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  
  <span class="n">entropy</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">num</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># number of labels</span>
  <span class="n">label_counts</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># calculate different labels in y，and store in label_counts</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
          <span class="n">label_counts</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">label_counts</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">sample_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  
  <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">label_counts</span><span class="p">:</span>
      <span class="n">prob</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">label_counts</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">))</span>
      <span class="n">entropy</span> <span class="o">-=</span> <span class="n">prob</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">entropy</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[76]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check if we get a reasonable value for the entropy</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>0.8687212463394132
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We have prepared the data and defined entropy, now define the functions for the random forest implementation.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">split_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">featVec</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="n">column</span><span class="p">]]</span>
  
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">featVec</span><span class="p">)):</span>
      <span class="k">if</span> <span class="n">featVec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="n">value</span><span class="p">:</span>
          <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  
  <span class="n">sub_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">ret</span><span class="p">,:]</span>
  <span class="n">sub_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ret</span><span class="p">]</span>
  <span class="n">sub_sample_weights</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">[</span><span class="n">ret</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">sub_X</span><span class="p">,</span> <span class="n">sub_y</span><span class="p">,</span> <span class="n">sub_sample_weights</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">entropy_purification</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  
  <span class="n">new_entropy</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">old_cost</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>
  
  <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">column</span><span class="p">])</span>

  <span class="n">new_cost</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="c1">#split the values of i-th feature and calculate the cost </span>
  <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">unique_vals</span><span class="p">:</span>
      <span class="n">sub_X</span><span class="p">,</span> <span class="n">sub_y</span><span class="p">,</span> <span class="n">sub_sample_weights</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>
      <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sub_sample_weights</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">))</span>
      <span class="n">new_cost</span> <span class="o">+=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="n">sub_y</span><span class="p">,</span> <span class="n">sub_sample_weights</span><span class="p">)</span>
  
  <span class="n">new_entropy</span> <span class="o">=</span> <span class="n">old_cost</span> <span class="o">-</span> <span class="n">new_cost</span> <span class="c1"># information gain</span>

  <span class="k">return</span> <span class="n">new_entropy</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># evaluate for feature 2</span>
<span class="n">entropy_purification</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[79]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>0.8452776369617089</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Function that determines the best feature to split by:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[80]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">choose_best_feature</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">n_features</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">best_feature_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">#   n_features = X.shape[1]    </span>
  
  <span class="c1"># use C4.5 algorirhm</span>
  <span class="n">best_gain_cost</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
      <span class="n">info_gain_cost</span> <span class="o">=</span> <span class="n">entropy_purification</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>        
      <span class="k">if</span> <span class="n">info_gain_cost</span> <span class="o">&gt;</span> <span class="n">best_gain_cost</span><span class="p">:</span>
          <span class="n">best_gain_cost</span> <span class="o">=</span> <span class="n">info_gain_cost</span>
          <span class="n">best_feature_idx</span> <span class="o">=</span> <span class="n">i</span>                

  <span class="k">return</span> <span class="n">best_feature_idx</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">choose_best_feature</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span><span class="n">n_features</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[81]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>2</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Analyse the predictor columns to notice why for any number of features larger than 2 we get the best feature as column 2:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of unique values in column&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;is&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Number of unique values in column 0 is 30
Number of unique values in column 1 is 5
Number of unique values in column 2 is 387
Number of unique values in column 3 is 5
Number of unique values in column 4 is 5
Number of unique values in column 5 is 4
Number of unique values in column 6 is 4
Number of unique values in column 7 is 49
Number of unique values in column 8 is 4
Number of unique values in column 9 is 2
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that in column 2 we have an unreasonably large number of unique values. The algorithm chooses the descriptoor with the most features as it gives the most information - the cross entropy is expected to have the largest value for column 2. As we choose column 2, very time there is an unique value, we get a new subtree and do not use the full possible depth. This will make the random forest memorise our data and overfit.</p>
<p>Check the cross entropy values:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[83]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">unique</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">entr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]))</span>
    <span class="n">unique</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">entropy_purification</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">entr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Column&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;cross entropy is&#39;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;unique values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">entr</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;index of column&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;unique values and entropy at each column&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Column 0 cross entropy is 0.11388863275776762
Column 1 cross entropy is 0.03381845069121381
Column 2 cross entropy is 0.8452776369617089
Column 3 cross entropy is 0.022995566261031164
Column 4 cross entropy is 0.01085462186586672
Column 5 cross entropy is 0.008291839223173891
Column 6 cross entropy is 0.037931868102222155
Column 7 cross entropy is 0.16044101435451585
Column 8 cross entropy is 0.021206763801311035
Column 9 cross entropy is 0.0012997664656910768
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We clearly see that the entropy which guides the choice in determining the best feature to split by is dependent on the unique values in the column. A way around this is to remove columns 2, 0 and 7 later to see whether we get better results for the random forest.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Majority vote function that gives us the classification label (in out case 0 or 1) that is most common in y:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">majority_vote</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  
  <span class="n">majority_label</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">dict_num</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="k">if</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dict_num</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
          <span class="n">dict_num</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
          <span class="n">dict_num</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">sample_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  
  <span class="n">majority_label</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dict_num</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">dict_num</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">majority_label</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">majority_vote</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[85]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>1.0</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define the decision tree building and training functions:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">mytree</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="c1"># include a clause for the cases where (i) no feature, (ii) all labels are the same, (iii) depth exceed, or (iv) X is too small</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">==</span><span class="mi">1</span> <span class="ow">or</span> <span class="n">depth</span><span class="o">&gt;=</span><span class="n">max_depth</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">min_samples_leaf</span><span class="p">:</span> 
        <span class="k">return</span> <span class="n">majority_vote</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">best_feature_idx</span> <span class="o">=</span> <span class="n">choose_best_feature</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>
        <span class="n">best_feature_name</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">best_feature_idx</span><span class="p">]</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[:]</span>
        <span class="n">feature_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">best_feature_name</span><span class="p">)</span>

    <span class="n">mytree</span> <span class="o">=</span> <span class="p">{</span><span class="n">best_feature_name</span><span class="p">:{}}</span>
    
    <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">best_feature_idx</span><span class="p">])</span>
    
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">unique_vals</span><span class="p">:</span>
        <span class="n">sub_X</span><span class="p">,</span> <span class="n">sub_y</span><span class="p">,</span> <span class="n">sub_sample_weights</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">best_feature_idx</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span> 
        <span class="n">mytree</span><span class="p">[</span><span class="n">best_feature_name</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">build_tree</span><span class="p">(</span><span class="n">sub_X</span><span class="p">,</span> <span class="n">sub_y</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">depth</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">sub_sample_weights</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mytree</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Build the decision tree according to the training data.</span>
<span class="sd">  Args:</span>
<span class="sd">      X: (pd.Dataframe) training features, of shape (N, D). Each X[i] is a training sample.</span>
<span class="sd">      y: (pd.Series) vector of training labels, of shape (N,). y[i] is the label for X[i], and each y[i] is</span>
<span class="sd">      an integer in the range 0 &lt;= y[i] &lt;= C. Here C = 1.</span>
<span class="sd">      sample_weights: weights for each samples, of shape (N,).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># if the sample weights is not provided, we assume the samples have uniform weights</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)</span>

  <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">tree</span> <span class="o">=</span> <span class="n">build_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">n_features</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Check the train function outputs a tree as expected</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># stack the standardised training data together and turn into dataframe</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span><span class="o">+</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>  
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>

<span class="c1"># dataframes</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># set default hyperparameters</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># fit the decision tree with training data</span>
<span class="n">tree3</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
<span class="c1"># print(tree3)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[89]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># stack the standardised testing data together and turn into dataframe</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">+</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>  
<span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="c1"># dataframes</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>  <span class="c1"># classify one element of y_pred with the fitted decision tree</span>
  <span class="n">feature_name</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># select first element of the tree dict - the feature name</span>
  <span class="n">second_dict</span> <span class="o">=</span> <span class="n">tree</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>            
  <span class="n">key</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">second_dict</span><span class="p">:</span>
      <span class="n">key</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">second_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
  <span class="n">value_of_key</span> <span class="o">=</span> <span class="n">second_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value_of_key</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="n">label</span> <span class="o">=</span> <span class="n">classify</span><span class="p">(</span><span class="n">value_of_key</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">label</span><span class="o">=</span><span class="n">value_of_key</span>
  <span class="k">return</span> <span class="n">label</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Finally, this function outputs a numpy array of the classification prediction using the above classification function that classifies each 'row' (element of y_pred) using the decision tree we trained.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tree</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">classify</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">results</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classify</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>  <span class="c1"># X_test and y_test are pandas dataframes</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="n">y_test</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)),</span> <span class="n">y_pred</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_acc</span><span class="p">,</span> <span class="n">tr_y_pred</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_1</span><span class="p">,</span> <span class="n">tree3</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
<span class="n">test_acc</span><span class="p">,</span> <span class="n">test_y_pred</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_2</span><span class="p">,</span> <span class="n">tree3</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training accuracy:&#39;</span><span class="p">,</span> <span class="n">tr_acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Training accuracy: 0.9975
Test accuracy: 0.54
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The model with default hyperparameters depth = 5, n_features = 5 has clearly overfitted the data because the training accuracy is very high and the test accuracy is much lower (nearly half of the train one). This may be due to the large number of unique values in the predictors.</p>
<p>Now we look for the optimal parameters:</p>
<p>1) number of decision trees: used in the random forest implementation</p>
<p>2) depth of trees: used in build_tree()</p>
<p>3) max number of descriptors (features) randomly chosen at each split: used in choose_best_feature()</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now that we have defined the functions to get a decision tree, we will perform a 5-fold cross validation to find the optimal parameters: we will run 5 models on different folds and judge the performance by the accuracy of the predictions.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">score2</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="n">y_test</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)),</span> <span class="n">y_pred</span>  <span class="c1"># accuracy of predictions</span>

<span class="c1"># data and data_test are np.arrays</span>
<span class="k">def</span> <span class="nf">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">print_accs</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  
    <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span> <span class="c1"># split data into folds</span>
    
    <span class="c1"># convert and split the test data into X_test and y_tests</span>
    <span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># initialise lists to contain the accuracies</span>
    <span class="n">train_accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_accs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">VAL_ACC</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">TEST_ACC</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># initialise the list to contain the prediction for the five folds</span>
    <span class="n">y_preds_val_fold</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_preds_test_fold</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">if</span> <span class="n">print_accs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">depth&#39;</span><span class="p">,</span><span class="n">depth</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;nb of trees&#39;</span><span class="p">,</span><span class="n">n_trees</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;nb of features&#39;</span><span class="p">,</span><span class="n">n_features</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">print_accs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">fold&#39;</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># define the training set</span>
        <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
        <span class="c1"># define the validation set</span>
        <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># convert to dataframes</span>
        <span class="n">train_folds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_folds</span><span class="p">)</span> <span class="c1"># train</span>
        <span class="n">val_fold</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">val_fold</span><span class="p">)</span> <span class="c1"># validation </span>

        <span class="c1"># get the lists for average accuracies for the forests</span>
        <span class="n">avg_train_accs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">avg_val_accs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">avg_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="n">y_trains_forest</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_val_forest</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_test_forest</span> <span class="o">=</span> <span class="p">[]</span>
        
        
        <span class="c1"># loop through the forest</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trees</span><span class="p">):</span>
            <span class="n">sample_tr</span> <span class="o">=</span> <span class="n">train_folds</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">train_folds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># change the random state to have different sampling for each tree</span>
            <span class="n">X_tr1</span> <span class="o">=</span> <span class="n">sample_tr</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">y_tr1</span> <span class="o">=</span> <span class="n">sample_tr</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1">#             sample_val = val_fold.sample(n=val_fold.shape[0], replace=True, random_state=1)</span>
            <span class="n">X_tr2</span> <span class="o">=</span> <span class="n">val_fold</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">y_tr2</span> <span class="o">=</span> <span class="n">val_fold</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            
            <span class="c1"># create the tree with this set of parameters and sampled training set</span>
            <span class="n">tree</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X_tr1</span><span class="p">,</span> <span class="n">y_tr1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>

            <span class="c1"># get the accuracy and prediction for each individual tree</span>
            <span class="n">train_acc</span><span class="p">,</span> <span class="n">tr_y_pred</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">X_tr1</span><span class="p">,</span> <span class="n">y_tr1</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>  <span class="c1"># we need to input the training set, the testing set and the hyperparameters </span>
            <span class="n">avg_train_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>

            <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_y_pred</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">X_tr2</span><span class="p">,</span> <span class="n">y_tr2</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
            <span class="n">avg_val_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
            
            <span class="n">test_acc</span><span class="p">,</span> <span class="n">test_y_pred</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
            <span class="n">avg_test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
            
            <span class="c1"># append the y_preds</span>
            <span class="n">y_trains_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tr_y_pred</span><span class="p">)</span>
            <span class="n">y_val_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_y_pred</span><span class="p">)</span>
            <span class="n">y_test_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_y_pred</span><span class="p">)</span>
        
        
        <span class="c1"># append the average of the validation and test accuracies over the individual trees</span>
        <span class="n">VAL_ACC</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">avg_val_accs</span><span class="p">))</span>
        <span class="n">TEST_ACC</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">avg_test_accs</span><span class="p">))</span>
            
        <span class="c1"># sum the predictions of the trees over the forest</span>
        <span class="n">y_tr_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">y_trains_forest</span><span class="p">)]</span>
        <span class="n">y_val_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">y_val_forest</span><span class="p">)]</span>
        <span class="n">y_test_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">y_test_forest</span><span class="p">)]</span>
        
        <span class="c1"># divide by the number of trees</span>
        <span class="n">y_tr_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">n_trees</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_tr_sum_forest</span><span class="p">]</span>
        <span class="n">y_val_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">n_trees</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_val_sum_forest</span><span class="p">]</span>
        <span class="n">y_test_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">n_trees</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_test_sum_forest</span><span class="p">]</span>
        
        <span class="c1"># set to 1 if above 0.5 set to 0 if below 0.5, set the case for 0.5 to equal 0 to avoid false positives</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_tr_sum_forest</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">y_tr_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
                <span class="n">y_tr_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_tr_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_val_sum_forest</span><span class="p">)):</span>  <span class="c1"># this is our y_pred over the validation fold</span>
            <span class="k">if</span> <span class="n">y_val_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
                <span class="n">y_val_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_val_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_sum_forest</span><span class="p">)):</span>  <span class="c1"># this is our y_pred over the validation fold</span>
            <span class="k">if</span> <span class="n">y_test_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
                <span class="n">y_test_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_test_sum_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
                
        <span class="c1"># we now have the prediction for this forest, calculate the score for this fold:</span>
        <span class="n">score12</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_tr_sum_forest</span><span class="p">,</span> <span class="n">y_tr1</span><span class="p">)</span>
        <span class="n">score1</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_val_sum_forest</span><span class="p">,</span> <span class="n">y_tr2</span><span class="p">)</span>
        <span class="n">score_test</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_test_sum_forest</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">print_accs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy, training set, fold&#39;</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;is&#39;</span><span class="p">,</span><span class="n">score12</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy, validation set, fold&#39;</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;is&#39;</span><span class="p">,</span><span class="n">score1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy, test set, fold&#39;</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;is&#39;</span><span class="p">,</span><span class="n">score_test</span><span class="p">)</span>
        
        <span class="c1"># append the scores for each fold</span>
        <span class="n">train_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score12</span><span class="p">)</span>
        <span class="n">val_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score1</span><span class="p">)</span>
        <span class="n">test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_test</span><span class="p">)</span>

        
        <span class="c1"># append the y_pred validation for each fold</span>
        <span class="n">y_preds_val_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_val_sum_forest</span><span class="p">)</span>
        <span class="n">y_preds_test_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_sum_forest</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_accs</span><span class="p">,</span> <span class="n">val_accs</span><span class="p">,</span> <span class="n">test_accs</span><span class="p">,</span> <span class="n">y_preds_val_fold</span><span class="p">,</span> <span class="n">y_preds_test_fold</span><span class="p">,</span> <span class="n">VAL_ACC</span><span class="p">,</span> <span class="n">TEST_ACC</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we have pandas dataframes data_train, data_train with standardised descriptors, turn them into numpy arrays</span>
<span class="n">arr_train1</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">arr_test1</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Run the cross-validation function to check whether we have reasonable accuracies.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">train_accs</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">y_test_pred</span><span class="p">,</span> <span class="n">VAL_ACC</span><span class="p">,</span> <span class="n">TEST_ACC</span>  <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span><span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VAL_ACC</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">TEST_ACC</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test_pred</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>

depth 5
nb of trees 5
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.734375
accuracy, validation set, fold 1 is 0.9
accuracy, test set, fold 1 is 0.695

fold 2
accuracy, training set, fold 2 is 0.75
accuracy, validation set, fold 2 is 0.84375
accuracy, test set, fold 2 is 0.67

fold 3
accuracy, training set, fold 3 is 0.7375
accuracy, validation set, fold 3 is 0.85625
accuracy, test set, fold 3 is 0.675

fold 4
accuracy, training set, fold 4 is 0.740625
accuracy, validation set, fold 4 is 0.91875
accuracy, test set, fold 4 is 0.685

fold 5
accuracy, training set, fold 5 is 0.7421875
accuracy, validation set, fold 5 is 0.925
accuracy, test set, fold 5 is 0.65
[0.8275, 0.8, 0.8074999999999999, 0.8550000000000001, 0.8262499999999999]
[0.61, 0.576, 0.595, 0.6119999999999999, 0.604]
[[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Having a lowest testing accuracy on unseen data seems reasonable, and printing out the predictions for y_test shows that we do not get predictions of the same class at all times.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Note that in what follows we take the metric as the validation and testing accuracy of the final y_pred averaged over the five folds. We will then compare this metric in determining the optimal hyperparameters based on the average of the accuracies over the individual trees.</p>
<p>The acccuracies on the training set are larger than on the test set, this is expected, so we continue by scanning through the optimal parameters separately.</p>
<p>i) Investigate the accuracies over different depths with other hyperparameters set to constant values.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[206]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># candidate depths</span>
<span class="n">depths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Candidate depths:&#39;</span><span class="p">,</span><span class="n">depths</span><span class="p">)</span>

<span class="c1"># other hyperparameters constant (adjusted after scanning for them)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">max_val_acc</span><span class="o">=</span><span class="p">[]</span>
<span class="n">max_test_acc</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
    <span class="n">train_accs</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span><span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
    <span class="n">max_val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">))</span>
    <span class="n">max_test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">average validation accuracy:&#39;</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;average testing accuracy:&#39;</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Candidate depths: [1 3 5 7 9]


depth 5
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.93125
accuracy, test set, fold 1 is 0.725

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.74

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.74

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.71

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.90625
accuracy, test set, fold 5 is 0.73


depth 5
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.91875
accuracy, test set, fold 1 is 0.735

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.73

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.88125
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.73

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.9
accuracy, test set, fold 5 is 0.74


depth 5
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.925
accuracy, test set, fold 1 is 0.735

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.73

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.735

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.90625
accuracy, test set, fold 5 is 0.725


depth 5
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.925
accuracy, test set, fold 1 is 0.735

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.8625
accuracy, test set, fold 2 is 0.74

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.9
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.73

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.9125
accuracy, test set, fold 5 is 0.73


depth 5
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.925
accuracy, test set, fold 1 is 0.725

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.8625
accuracy, test set, fold 2 is 0.735

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.925
accuracy, test set, fold 4 is 0.73

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.9
accuracy, test set, fold 5 is 0.735

average validation accuracy: [0.90625, 0.9012500000000001, 0.905, 0.9075, 0.9]

average testing accuracy: [0.729, 0.734, 0.732, 0.734, 0.732]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[210]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">depths</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">depths</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;testing&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>From this plot, we see that the model is not very sensitive to the depth we choose, this may be due to the tree branching out significantly in the second feature that has many unique values.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>ii) Scanning through the number of trees to get an intuition, choose depth = 3, based on the maximum accuracy achieved on the training set previously.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[227]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_trees</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nbs_trees</span><span class="p">)</span>
<span class="n">depth_opt</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">max_val_acc</span><span class="o">=</span><span class="p">[]</span>
<span class="n">max_test_acc</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">nb</span> <span class="ow">in</span> <span class="n">nbs_trees</span><span class="p">:</span>
    <span class="n">train_accs</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span><span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">nb</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth_opt</span><span class="p">)</span>
    <span class="n">max_val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">))</span>
    <span class="n">max_test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">average validation accuracy:&#39;</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">average testing accuracy:&#39;</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[2, 5, 9, 12, 16, 20, 30, 40]


depth 3
nb of trees 2
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.8125
accuracy, validation set, fold 1 is 0.83125
accuracy, test set, fold 1 is 0.455

fold 2
accuracy, training set, fold 2 is 0.828125
accuracy, validation set, fold 2 is 0.78125
accuracy, test set, fold 2 is 0.545

fold 3
accuracy, training set, fold 3 is 0.8109375
accuracy, validation set, fold 3 is 0.81875
accuracy, test set, fold 3 is 0.57

fold 4
accuracy, training set, fold 4 is 0.7859375
accuracy, validation set, fold 4 is 0.81875
accuracy, test set, fold 4 is 0.5

fold 5
accuracy, training set, fold 5 is 0.778125
accuracy, validation set, fold 5 is 0.8
accuracy, test set, fold 5 is 0.55


depth 3
nb of trees 5
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.734375
accuracy, validation set, fold 1 is 0.89375
accuracy, test set, fold 1 is 0.69

fold 2
accuracy, training set, fold 2 is 0.75
accuracy, validation set, fold 2 is 0.85
accuracy, test set, fold 2 is 0.69

fold 3
accuracy, training set, fold 3 is 0.7375
accuracy, validation set, fold 3 is 0.875
accuracy, test set, fold 3 is 0.67

fold 4
accuracy, training set, fold 4 is 0.740625
accuracy, validation set, fold 4 is 0.90625
accuracy, test set, fold 4 is 0.69

fold 5
accuracy, training set, fold 5 is 0.7421875
accuracy, validation set, fold 5 is 0.8875
accuracy, test set, fold 5 is 0.665


depth 3
nb of trees 9
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.7484375
accuracy, validation set, fold 1 is 0.89375
accuracy, test set, fold 1 is 0.715

fold 2
accuracy, training set, fold 2 is 0.7359375
accuracy, validation set, fold 2 is 0.8625
accuracy, test set, fold 2 is 0.72

fold 3
accuracy, training set, fold 3 is 0.74375
accuracy, validation set, fold 3 is 0.86875
accuracy, test set, fold 3 is 0.715

fold 4
accuracy, training set, fold 4 is 0.7234375
accuracy, validation set, fold 4 is 0.93125
accuracy, test set, fold 4 is 0.705

fold 5
accuracy, training set, fold 5 is 0.734375
accuracy, validation set, fold 5 is 0.86875
accuracy, test set, fold 5 is 0.695


depth 3
nb of trees 12
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.7125
accuracy, validation set, fold 1 is 0.90625
accuracy, test set, fold 1 is 0.695

fold 2
accuracy, training set, fold 2 is 0.7265625
accuracy, validation set, fold 2 is 0.8375
accuracy, test set, fold 2 is 0.73

fold 3
accuracy, training set, fold 3 is 0.7125
accuracy, validation set, fold 3 is 0.825
accuracy, test set, fold 3 is 0.65

fold 4
accuracy, training set, fold 4 is 0.7125
accuracy, validation set, fold 4 is 0.91875
accuracy, test set, fold 4 is 0.72

fold 5
accuracy, training set, fold 5 is 0.709375
accuracy, validation set, fold 5 is 0.86875
accuracy, test set, fold 5 is 0.66


depth 3
nb of trees 16
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.725
accuracy, validation set, fold 1 is 0.9125
accuracy, test set, fold 1 is 0.715

fold 2
accuracy, training set, fold 2 is 0.7171875
accuracy, validation set, fold 2 is 0.875
accuracy, test set, fold 2 is 0.725

fold 3
accuracy, training set, fold 3 is 0.7015625
accuracy, validation set, fold 3 is 0.875
accuracy, test set, fold 3 is 0.715

fold 4
accuracy, training set, fold 4 is 0.71875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.695

fold 5
accuracy, training set, fold 5 is 0.69375
accuracy, validation set, fold 5 is 0.90625
accuracy, test set, fold 5 is 0.66


depth 3
nb of trees 20
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.7328125
accuracy, validation set, fold 1 is 0.91875
accuracy, test set, fold 1 is 0.715

fold 2
accuracy, training set, fold 2 is 0.7140625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.735

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.86875
accuracy, test set, fold 3 is 0.73

fold 4
accuracy, training set, fold 4 is 0.69375
accuracy, validation set, fold 4 is 0.925
accuracy, test set, fold 4 is 0.725

fold 5
accuracy, training set, fold 5 is 0.69375
accuracy, validation set, fold 5 is 0.9125
accuracy, test set, fold 5 is 0.725


depth 3
nb of trees 30
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.703125
accuracy, validation set, fold 1 is 0.91875
accuracy, test set, fold 1 is 0.73

fold 2
accuracy, training set, fold 2 is 0.7046875
accuracy, validation set, fold 2 is 0.88125
accuracy, test set, fold 2 is 0.735

fold 3
accuracy, training set, fold 3 is 0.6859375
accuracy, validation set, fold 3 is 0.89375
accuracy, test set, fold 3 is 0.715

fold 4
accuracy, training set, fold 4 is 0.68125
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.745

fold 5
accuracy, training set, fold 5 is 0.6984375
accuracy, validation set, fold 5 is 0.9125
accuracy, test set, fold 5 is 0.73


depth 3
nb of trees 40
nb of features 4

fold 1
accuracy, training set, fold 1 is 0.7078125
accuracy, validation set, fold 1 is 0.93125
accuracy, test set, fold 1 is 0.735

fold 2
accuracy, training set, fold 2 is 0.7046875
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.735

fold 3
accuracy, training set, fold 3 is 0.70625
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.68125
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.735

fold 5
accuracy, training set, fold 5 is 0.671875
accuracy, validation set, fold 5 is 0.9125
accuracy, test set, fold 5 is 0.73

average validation accuracy: [0.8099999999999999, 0.8825, 0.885, 0.8712500000000001, 0.9012499999999999, 0.8987499999999999, 0.9087499999999998, 0.9075]

average testing accuracy: [0.524, 0.6809999999999999, 0.71, 0.6910000000000001, 0.702, 0.726, 0.731, 0.734]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[228]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nbs_trees</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nbs_trees</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;testing&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of trees&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We see that the accuracy plateau is at around 25, so we take this as the optimal value; ideally it would be larger for marginally better accuracies but we have serious computational power constraints. A larger number of trees is more optimal as there is more averaging out of outtlier accuracies.</p>
<p>The maximum depth is one of the stopping criteria for the algorithm - it sets a maximum number of splits in the decision tree.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>iii) Now investigate the optimal number of features randomly chosen at each split, note that we cannot go above 9 because there are 10 training features overall. Choose optimal n_trees = 25 and depth = 3.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[230]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nbs_feat</span><span class="p">)</span>
<span class="n">n_trees_opt</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">depth_opt</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">max_val_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_test_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">nb</span> <span class="ow">in</span> <span class="n">nbs_feat</span><span class="p">:</span>
    <span class="n">train_accs</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span> <span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">nb</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">n_trees_opt</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth_opt</span><span class="p">)</span>
    <span class="n">max_val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">))</span>
    <span class="n">max_test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">average validation accuracy:&#39;</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">average testing accuracy:&#39;</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[3 5 7 9]


depth 3
nb of trees 25
nb of features 3

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.91875
accuracy, test set, fold 1 is 0.73

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.725

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.89375
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.72

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.9125
accuracy, test set, fold 5 is 0.73


depth 3
nb of trees 25
nb of features 5

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.9375
accuracy, test set, fold 1 is 0.73

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.875
accuracy, test set, fold 2 is 0.73

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.725

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.715

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.9
accuracy, test set, fold 5 is 0.73


depth 3
nb of trees 25
nb of features 7

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.9375
accuracy, test set, fold 1 is 0.735

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.8625
accuracy, test set, fold 2 is 0.735

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.735

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.74

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.91875
accuracy, test set, fold 5 is 0.74


depth 3
nb of trees 25
nb of features 9

fold 1
accuracy, training set, fold 1 is 0.7203125
accuracy, validation set, fold 1 is 0.93125
accuracy, test set, fold 1 is 0.73

fold 2
accuracy, training set, fold 2 is 0.715625
accuracy, validation set, fold 2 is 0.86875
accuracy, test set, fold 2 is 0.725

fold 3
accuracy, training set, fold 3 is 0.7
accuracy, validation set, fold 3 is 0.8875
accuracy, test set, fold 3 is 0.73

fold 4
accuracy, training set, fold 4 is 0.6875
accuracy, validation set, fold 4 is 0.9375
accuracy, test set, fold 4 is 0.725

fold 5
accuracy, training set, fold 5 is 0.6703125
accuracy, validation set, fold 5 is 0.90625
accuracy, test set, fold 5 is 0.735

average validation accuracy: [0.90625, 0.9075000000000001, 0.9087500000000001, 0.90625]

average testing accuracy: [0.728, 0.726, 0.7370000000000001, 0.729]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[232]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nbs_feat</span><span class="p">,</span><span class="n">max_val_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nbs_feat</span><span class="p">,</span><span class="n">max_test_acc</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;testing&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of features&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqmklEQVR4nO3dfZwV1Z3n8c+3m4aWZxAwCCrEdXxCBNKLRo3ROBpxo8aMEzFxRokJajQTnUlWzM5MdLOz42QSEzPJ6GpiNBOiQ0yMOjGKcU0kk1VpDCKgRqKoDQiNRp5EoLt/+0dVN8Xt27frNn3pbvi+X6963apT59Q91Ur97qlTdY4iAjMzs7yqeroCZmbWtzhwmJlZWRw4zMysLA4cZmZWFgcOMzMrS7+ersCeMGrUqJgwYUJPV8PMrE9ZtGjR+ogYXZi+TwSOCRMmUF9f39PVMDPrUyS9Wizdt6rMzKwsDhxmZlYWBw4zMyuLA4eZmZXFgcPMzMriwGFmZmVx4DAzs7LsE+9xmO0tIoKWgOaWoCWCppagObO0prW0dLyvs/yFaW37on1aSyRlmloCAf37VTGgXxU11VX071dF/9bPfgXb1aXT+lUJST3957YOOHBYj8teDJvTC1RzwQUue9Hq7GLYYf4iF76OLoZNzQX70rTshbLw4tm6NLXsevHNfn+xtGJ1L5W2L5BIAkmRwFOTSRuQCTg1BcFoQL+C9IJyNR0cv8OAV11FVZWDGThwVExPXwybm1toDnbrYpi9yOW5GLbt24suhlWCflVVVFVBtUR1VetSRXVV6X3VVVVUi7b0mqqqdmlt+UWmXJqunceqqhL9CtLa9indV/jdbfuKp1Wl9d9ZV5VMa9snUV2tXfcJImB7cwvbm1vY0ZR8bm9Klm1NLexo3c6kby+W1rpdLC09zrY0bfO2prb92eNvy5Tpzrnq+lWpXRAbUCTw7BLcMuuFQWyX4FYQrAZUV1FTpHU2oOD4PdE6c+Ao4V9/tYIHn12zV18MW//R574Y7pLW+cWw7YKXuRi2pmUvhoVpVen3FEtrXVrT+lUX7MuktZ1LNn8mrS1/9u+ROU/fLslPgtqqamprqnu6Km0i/fdYGMS2N2cCTWt6c0EAygSrbR2kdxT8tmxravuebL4dbd/dfdeHUq2z/v2quOGco6mbMLLbvg8cOEoaWlvDuOH7ZS6mKvhlmLnQSruktf5aa5+260W63F+GeX4tZn8ZFqZVCV8MbZ+h9EdEv+oqBvbv6drs1NIazIoEq2zAKQxWrS2pToNbZn8lArkDRwkXHX8IFx1/SE9Xw8z2MlVV6nWts3L4cVwzMyuLA4eZmZWlooFD0pmSXpS0QtKcIvtHSLpP0hJJT0ua1FlZSSMlPSrppfRzRCXPwczMdlWxwCGpGvgOMAM4CrhQ0lEF2b4ELI6IycBfAjfnKDsHeCwiDgMeS7fNzGwPqWSLYzqwIiJejojtwD3AuQV5jiK5+BMRLwATJB3QSdlzgbvS9buAj1bwHMzMrEAlA8c44PXMdkOalvUs8DEASdOBQ4DxnZQ9ICLWAKSfY4p9uaTZkuol1Tc2Nu7mqZiZWatKBo5iLwsUvvVyIzBC0mLgc8DvgKacZUuKiNsioi4i6kaPbjfXupmZdVEl3+NoAA7KbI8HVmczRMRGYBaAkrfSXkmXgSXKrpU0NiLWSBoLrKtM9c3MrJhKtjgWAodJmiipPzATeCCbQdLwdB/Ap4En0mBSquwDwMXp+sXA/RU8BzMzK1CxFkdENEm6CngEqAbuiIhlki5P998KHAn8QFIzsBy4tFTZ9NA3AvMkXQq8Bvx5pc7BzMzaU3Tn0JG9VF1dXdTX1/d0NczM+hRJiyKirjDdb46bmVlZHDjMzKwsDhxmZlYWBw4zMyuLA4eZmZXFgcPMzMriwGFmZmVx4DAzs7I4cJiZWVkcOMzMrCwOHGZmVhYHDjMzK4sDh5mZlcWBw8zMyuLAYWZmZXHgMDOzsjhwmJlZWRw4zMysLBUNHJLOlPSipBWS5hTZP0zSg5KelbRM0qw0/XBJizPLRklXp/uul7Qqs++sSp6DmZntql+lDiypGvgOcDrQACyU9EBELM9kuxJYHhFnSxoNvChpbkS8CEzJHGcVcF+m3Dci4muVqruZmXWski2O6cCKiHg5IrYD9wDnFuQJYIgkAYOBt4CmgjynAX+IiFcrWFczM8upkoFjHPB6ZrshTcv6NnAksBp4Dvh8RLQU5JkJ3F2QdpWkJZLukDSi2JdLmi2pXlJ9Y2Njl0/CzMx2VcnAoSJpUbD9YWAxcCDJralvSxradgCpP3AO8ONMmVuAQ9P8a4CvF/vyiLgtIuoiom706NFdOwMzM2unkoGjATgosz2epGWRNQv4aSRWAK8AR2T2zwCeiYi1rQkRsTYimtOWye0kt8TMzGwPqWTgWAgcJmli2nKYCTxQkOc1kj4MJB0AHA68nNl/IQW3qSSNzWyeByzt5nqbmVkJFXuqKiKaJF0FPAJUA3dExDJJl6f7bwW+Atwp6TmSW1vXRsR6AEkDSZ7Iuqzg0F+VNIXkttfKIvvNzKyCFFHY7bD3qauri/r6+p6uhplZnyJpUUTUFab7zXEzMyuLA4eZmZXFgcPMzMriwGFmZmVx4DAzs7I4cJiZWVkcOMzMrCwOHGZmVhYHDjMzK0ungUPSpD1RETMz6xvytDhulfS0pM9KGl7pCpmZWe/WaeCIiJOAT5IMkV4v6UeSTq94zczMrFfK1ccRES8BfwtcC3wQ+JakFyR9rJKVMzOz3idPH8dkSd8Angc+BJwdEUem69+ocP3MzKyXyTMfx7dJZtr7UkRsbU2MiNWS/rZiNTMzs14pT+A4C9gaEc0AkqqA2oh4JyL+raK1MzOzXidPH8cvgf0y2wPTNDMz2wflCRy1EbG5dSNdH1i5KpmZWW+WJ3BskTStdUPS+4CtJfK3kXSmpBclrZA0p8j+YZIelPSspGWSZmX2rZT0nKTFkuoz6SMlPSrppfRzRJ66mJlZ98gTOK4GfixpgaQFwL8DV3VWSFI18B1gBnAUcKGkowqyXQksj4hjgVOAr0vqn9l/akRMKZjzdg7wWEQcBjyWbpuZ2R7Saed4RCyUdARwOCDghYjYkePY04EVEfEygKR7gHOB5dnDA0MkCRgMvAU0dXLcc0mCDMBdwK9I3i8xM7M9IO8gh4eTtBqmkrQc/jJHmXHA65nthjQt69vAkcBq4Dng8xHRku4LYL6kRZJmZ8ocEBFrANLPMcW+XNJsSfWS6hsbG3NU18zM8ui0xSHpyyS/8I8CHiK59fQb4AedFS2SFgXbHwYWk7xMeCjwqKQFEbERODF9V2RMmv5CRDzRWX3bvijiNuA2gLq6usLvNTOzLsrT4jgfOA14IyJmAccCA3KUayAZ36rVeJKWRdYs4KeRWAG8AhwByQuG6ec64D6SW18AayWNBUg/1+Woi5mZdZM8gWNrevuoSdJQkgv1e3OUWwgcJmli2uE9E3igIM9rJEEJSQeQ3BJ7WdIgSUPS9EHAGcDStMwDwMXp+sXA/TnqYmZm3STPm+P16XDqtwOLgM3A050ViogmSVcBjwDVwB0RsUzS5en+W4GvAHdKeo7k1ta1EbFe0nuB+5I+c/oBP4qIh9ND3wjMk3QpSeD589xna2Zmu00RHd/+T592Gh8Rr6fbE4ChEbFkz1Sve9TV1UV9fX3nGc3MrI2kRQWvQwCd3KqKJKr8LLO9sq8FDTMz6155+jielPRfK14TMzPrE/L0cZwKXCbpVWALSV9ERMTkitbMzMx6pTyBY0bFa2FmZn1GnsDhl+fMzKxNnsDxc5LgIaAWmAi8CBxdwXqZmVkvlWeQw2Oy2+kQ65dVrEZmZtar5R3ksE1EPAP4KSszs31UnkEO/zqzWQVMAzzcrJnZPipPH8eQzHoTSZ/HTypTHTMz6+3y9HHcsCcqYmZmfUOnfRzpvN7DM9sjJD1S0VqZmVmvladzfHREvN26ERF/pINZ98zMbO+Xp4+jWdLBEfEagKRD8EuBZtZDduzYQUNDA++++25PV2WvUVtby/jx46mpqcmVP0/g+B/AbyT9Ot0+GZhdIr+ZWcU0NDQwZMgQJkyYQDpnj+2GiODNN9+koaGBiRMn5iqTp3P84fSlv+NJ3h6/JiLW715Vzcy65t1333XQ6EaS2H///WlszP+WRZ7O8fOAHRHxHxHxIMkUsh/tejXNzHaPg0b3Kvfvmadz/MsRsaF1I+0o/3J51TIz23cNHjwYgNWrV3P++ecXzXPKKafQ2Uyl3/zmN3nnnXfats866yzefvvtbqtnXnkCR7E8efpGkHSmpBclrZA0p8j+YZIelPSspGWSZqXpB0l6XNLzafrnM2Wul7RK0uJ0OStPXczMetqBBx7Ivffe2+XyhYHjoYceYvjw4d1Qs/LkCRz1km6SdKik90r6BrCos0KSqoHvkMzncRRwoaSjCrJdCSyPiGOBU4CvS+pP8ob630TEkSR9K1cWlP1GRExJl4dynIOZWbe59tpr+dd//de27euvv54bbriB0047jWnTpnHMMcdw//33tyu3cuVKJk2aBMDWrVuZOXMmkydP5oILLmDr1q1t+a644grq6uo4+uij+fKXkxs83/rWt1i9ejWnnnoqp556KgATJkxg/fqky/mmm25i0qRJTJo0iW9+85tt33fkkUfymc98hqOPPpozzjhjl+/pqjwth88Bfwf8O0nn+HySC35npgMrIuJlAEn3AOcCyzN5Ahii5AbbYOAtoCki1gBrACJik6TngXEFZc1sH3fDg8tYvnpjtx7zqAOH8uWzS88aMXPmTK6++mo++9nPAjBv3jwefvhhrrnmGoYOHcr69es5/vjjOeecczrsP7jlllsYOHAgS5YsYcmSJUybNq1t3z/8wz8wcuRImpubOe2001iyZAl/9Vd/xU033cTjjz/OqFGjdjnWokWL+P73v89TTz1FRHDcccfxwQ9+kBEjRvDSSy9x9913c/vtt/Pxj3+cn/zkJ1x00UW79TfqtMUREVsiYk5E1EXE+yLiuojYkuPY44DXM9sNaVrWt4EjgdXAc8DnI6Ilm0HSBGAq8FQm+SpJSyTdIWlEsS+XNFtSvaT6cp4WMDPrzNSpU1m3bh2rV6/m2WefZcSIEYwdO5YvfelLTJ48mT/90z9l1apVrF27tsNjPPHEE20X8MmTJzN58s7ZuOfNm8e0adOYOnUqy5YtY/ny0r+Zf/Ob33DeeecxaNAgBg8ezMc+9jEWLFgAwMSJE5kyZQoA73vf+1i5cuXunTz5RscdDfx3kombalvTI+JDnRUtklb44uCHgcXAh4BDgUclLYiIjel3DyYZUPHq1jTgFuAr6bG+Anwd+FS7L4q4DbgNoK6uzi8smu2FOmsZVNL555/PvffeyxtvvMHMmTOZO3cujY2NLFq0iJqaGiZMmNDpS4rFWiOvvPIKX/va11i4cCEjRozgkksu6fQ4ER1f4gYMGNC2Xl1d3S23qvL0ccwFXiCZ+e8GYCWwMEe5BuCgzPZ4kpZF1izgp5FYAbwCHAEgqYYkaMyNiJ+2FoiItRHRnLZMbie5JWZmtkfNnDmTe+65h3vvvZfzzz+fDRs2MGbMGGpqanj88cd59dVXS5Y/+eSTmTt3LgBLly5lyZIlAGzcuJFBgwYxbNgw1q5dyy9+8Yu2MkOGDGHTpk1Fj/Wzn/2Md955hy1btnDffffxgQ98oBvPdld5Asf+EfE9knc5fh0RnyLpsO7MQuAwSRPTDu+ZwAMFeV4DTgOQdABwOPBy2ufxPeD5iLgpW0DS2MzmecDSHHUxM+tWRx99NJs2bWLcuHGMHTuWT37yk9TX11NXV8fcuXM54ogjSpa/4oor2Lx5M5MnT+arX/0q06cnv4GPPfZYpk6dytFHH82nPvUpTjzxxLYys2fPZsaMGW2d462mTZvGJZdcwvTp0znuuOP49Kc/zdSpU7v/pFMq1cQBkPRkRByfjoj7LZJWw70RcWinB08elf0mUA3cERH/IOlygIi4VdKBwJ3AWJJbWzdGxA8lnQQsIOn3aO3z+FJEPCTp34ApJLeqVgKXpZ3pHaqrq4vOno82s77h+eef58gjj+zpaux1iv1dJS2KiLrCvHmeqvpfkoYBfwP8CzAUuCZPRdJHZR8qSLs1s74aOKNIud9QvI+EiPiLPN9tZmaVkWesqv9IVzcAp5bKa2Zme788fRxmZmZtHDjMzKwsDhxmZlaWPC8ADgD+DJiQzR8R/7Ny1TIzs94qT4vjfpIxppqALZnFzGyf9Pbbb+8yyGE5esvQ6LsjT+AYHxEXRMRXI+LrrUvFa2Zm1kt1Z+DoqaHRd0ee9zh+K+mYiHiu4rUxM+sD5syZwx/+8AemTJnC6aefzpgxY5g3bx7btm3jvPPO44YbbmDLli18/OMfp6GhgebmZv7u7/6OtWvXtg2NPmrUKB5//HEmTJhAfX09mzdvZsaMGZx00kn89re/Zdy4cdx///3st99+LFy4kEsvvZRBgwZx0kkn8Ytf/IKlS3tu0Iw8geMk4BJJrwDbSF7Mi4iYXLqYmVmF/WIOvNHNv2nfcwzMuLFklhtvvJGlS5eyePFi5s+fz7333svTTz9NRHDOOefwxBNP0NjYyIEHHsjPf/5zADZs2MCwYcM6HBod6HAI9FmzZnHbbbdxwgknMGdOuznx9rg8t6pmAIeRvOF9NvCR9NPMbJ83f/585s+fz9SpU5k2bRovvPACL730Escccwy//OUvufbaa1mwYAHDhg3r9FjFhkB/++232bRpEyeccAIAn/jEJyp5OrnkeXP8VUnHAq1DLS6IiGcrWy0zsxw6aRnsCRHBddddx2WXXdZu36JFi3jooYe47rrrOOOMM/j7v//7kscqNgR6Z+MJ9oROWxzpfN9zgTHp8kNJn6t0xczMeqvs8OYf/vCHueOOO9i8eTMAq1atapvkaeDAgVx00UV84Qtf4JlnnmlXNo8RI0YwZMgQnnzySQDuueeebj6b8uXp47gUOK511j9J/wT8P5IBD83M9jn7778/J554IpMmTWLGjBl84hOf4P3vfz8AgwcP5oc//CErVqzgi1/8IlVVVdTU1HDLLbcAO4dGHzt2LI8//niu7/ve977HZz7zGQYNGsQpp5yS67ZXJeUZVv054L9GxLvpdi2wMCKO2QP16xYeVt1s77EvDqu+efNmBg8eDCQd82vWrOHmm2/u1u/o7mHVvw88Jem+dPujJJMsmZnZHvDzn/+cf/zHf6SpqYlDDjmEO++8s0frk6dz/CZJvyJ5LFfArIj4XaUrZmZmiQsuuIALLrigp6vRpsPAIWloRGyUNJJkpr2VmX0jI+KtylfPzMx6m1Itjh+RvLOxiGSa1lZKt99bwXqZmXUoIpCKThJqXVDuI78dPo4bER9JPydGxHszy8SIyBU0JJ0p6UVJKyS1e91R0jBJD0p6VtIySbM6KytppKRHJb2Ufo4o64zNrE+rra3lzTff7JXvN/RFEcGbb75JbW1t7jJ5hlV/LCJO6yytSLlq4DvA6UADsFDSAxGxPJPtSmB5RJwtaTTwoqS5QHOJsnOAxyLixjSgzAGuzXvCZta3jR8/noaGBhobG3u6KnuN2tpaxo8fnzt/qT6OWmAgMCr9Vd/aLhwKHJjj2NOBFRHxcnq8e0iGZ88GjgCGKGlzDgbeIhm+/bgSZc8FTknL3wX8CgcOs31GTU0NEydO7Olq7NNKtTguA64mCRKL2Bk4NpK0BjozDng9s91AEhCyvg08AKwGhgAXRESLpFJlD4iINQARsUbSmGJfLmk2MBvg4IMPzlFdMzPLo1Qfx80RMRH4QqZvY2JEHBsR385x7GI9V4U3JT8MLCYJTlOAb0samrNsSRFxW0TURUTd6NGjyylqZmYl5HmP418kTQKOAmoz6T/opGgDcFBmezxJyyJrFnBjJL1cK9Kh24/opOxaSWPT1sZYYF1n52BmZt0nzyCHXyYZl+pfgFOBrwLn5Dj2QuAwSRMl9QdmktyWynoNOC39ngOAw4GXOyn7AHBxun4xydS2Zma2h+SZj+N8kov7GxExCzgWGFC6CEREE3AV8AjwPDAvIpZJulzS5Wm2rwAnpONhPQZcGxHrOyqblrkROF3SSyRPXfX8uMpmZvuQPGNVbU07rJvS/od15Hz5LyIeAh4qSLs1s76aZIKoXGXT9DdJWylmZrbn5Qkc9ZKGA7eTPF21GXi6kpUyM7PeK0/n+GfT1VslPQwMjYglla2WmZn1VqVeAJxWal9EPFOZKpmZWW9WqsXx9fSzFqgDniV5v2Iy8BTJMOtmZraPKfUC4KkRcSrwKjAtfZnufcBUYMWeqqCZmfUueR7HPSIinmvdiIilJG95m5nZPijPU1XPS/ou8EOSYT8uInm3wszM9kF5Ascs4Arg8+n2E8AtFauRmZn1ankex30X+Ea6mJnZPq7U47jzIuLj6XAg7UamjYjJFa2ZmZn1SqVaHK23pj6yJypiZmZ9Q4eBIzNZ0qt7rjpmZtbblbpVtYnikycJiIgYWrFamZlZr1WqxTFkT1bEzMz6hjyP4wKQzu2dnQHwtYrUyMzMerU8MwCek06a9Arwa2Al8IsK18vMzHqpPEOOfAU4Hvh9REwkmUTpPytaKzMz67XyBI4d6ax7VZKqIuJxPFaVmdk+K0/geFvSYJKhRuZKuhloynNwSWdKelHSCklziuz/oqTF6bJUUrOkkZIOz6QvlrRR0tVpmeslrcrsO6uM8zUzs92kiGJP3GYySIOArSRB5pPAMGBu2gopVa4a+D1wOtAALAQujIjlHeQ/G7gmIj5U5DirgOMi4lVJ1wObI+JrnZ9eoq6uLurr6/NmNzMzQNKiiKgrTM/zVNVs4McR0QDcVcZ3TgdWRMTLaQXuAc4FigYO4ELg7iLppwF/8IuIZma9Q55bVUOBRyQtkHSlpANyHnsc8HpmuyFNa0fSQOBM4CdFds+kfUC5StISSXdIGtHBMWdLqpdU39jYmLPKZmbWmU4DR0TcEBFHA1cCBwK/lvTLHMdWscN1kPds4D8j4q1dDiD1B84BfpxJvgU4lKSDfg07p7gtrPdt6ayFdaNHj85RXTMzyyNPi6PVOuAN4E1gTI78DcBBme3xwOoO8hZrVQDMAJ6JiLWtCRGxNiKaI6IFuJ3klpiZme0heV4AvELSr4DHgFHAZ3IOqb4QOEzSxLTlMBN4oMjxhwEfBO4vcox2/R6SxmY2zwOW5qiLmZl1kzyd44cAV0fE4nIOHBFNkq4CHgGqgTsiYpmky9P9t6ZZzwPmR8SWbPm03+N04LKCQ39V0hSS214ri+w3M7MK6vRx3L2BH8c1MytfR4/jltPHYWZm5sBhZmblceAwM7OyOHCYmVlZHDjMzKwsDhxmZlYWBw4zMyuLA4eZmZXFgcPMzMriwGFmZmVx4DAzs7I4cJiZWVkcOMzMrCwOHGZmVhYHDjMzK4sDh5mZlcWBw8zMyuLAYWZmZalo4JB0pqQXJa2QNKfI/i9KWpwuSyU1SxqZ7lsp6bl0X32mzEhJj0p6Kf0cUclzMDOzXVUscEiqBr4DzACOAi6UdFQ2T0T8c0RMiYgpwHXAryPirUyWU9P92Tlv5wCPRcRhwGPptpmZ7SGVbHFMB1ZExMsRsR24Bzi3RP4LgbtzHPdc4K50/S7go7tTSTMzK08lA8c44PXMdkOa1o6kgcCZwE8yyQHMl7RI0uxM+gERsQYg/RzTwTFnS6qXVN/Y2Lgbp2FmZlmVDBwqkhYd5D0b+M+C21QnRsQ0kltdV0o6uZwvj4jbIqIuIupGjx5dTlEzMyuhkoGjATgosz0eWN1B3pkU3KaKiNXp5zrgPpJbXwBrJY0FSD/XdWOdzcysE5UMHAuBwyRNlNSfJDg8UJhJ0jDgg8D9mbRBkoa0rgNnAEvT3Q8AF6frF2fLmZlZ5fWr1IEjoknSVcAjQDVwR0Qsk3R5uv/WNOt5wPyI2JIpfgBwn6TWOv4oIh5O990IzJN0KfAa8OeVOgczM2tPER11O+w96urqor6+vvOMZmbWRtKigtchAL85bmZmZXLgMDOzsjhwmJlZWRw4zMysLA4cZmZWFgcOMzMriwOHmZmVpWIvAJrZXigCtqyHDa/DhobM8jo0bYNBo2HQqPRzNAzaf+f6wFHQr39Pn4F1AwcOM9tpx1bYsKp4YNjQABtXQdO7u5bptx8MPwj6DYA3noMtjdCyo/jxa4dlAkkmqOwScNLP/UZAVXXlz9nK5sBhtq9oaYF31sPbrxcEhsz6O+sLCgmGvAeGjYexk+GIs2DYQcn2sPHJ+n4jQJnBsCPg3Q1Jy2RLY7K8s37X7S3r4c0V8NqT8M6bFB04W1WZ4DIqabG0CzKt66NgwNBd62EV48BhtrfY/k7SIuiotbBhFTRv27VMzaCktTBsPBw4ZWcwaA0MQw4s//aSBPsNT5ZR/6Xz/C3N8M5bpYPMlkZY82yyvm1D8eNU928fVEq1amr2K++8rI0Dh1lf0NICW9a1byFkt995s6CQYMjYtLUwBY74SBIUhmcCQ+3wnv+VXlUNg0cnSx5N2zKBZX0aaAqCzJb10Pj75G9WeGutVf/B7VsuHbVqBu4P1b5ctvJfwqw32La5g9ZCa2BY1b7foP/gna2DA6e1by0MPRCqa3rmfCqp3wAYNi5ZOhMB27d0EmQak9t3q55J1qO5+LH2G9E+qAwcVRB80n21w6Fq731o1YHDrNJammHz2tKtha1/3LWMqpLbRMPGw7g6OOqj7QND7bCeby30dhIMGJwsIyd2nr+lBd59e2dQeWd9+yCzZT2sewG2LICtbxU/TlW/XftnOmvV9B/Up/5bOnCY7a5tm4p3NLdub1wNLU27lhkwbGcAGD+9SN/CWN8a6QlVVTBwZLKM/pPO8zc3JbcIi/bNtAac9fDH+uRz+6bix+m3385O/qKtmoL+mX4Duve8y+T/M81KaW6CzW+UDgzvFnTWqhqGjksCwEHH7/oE0rDxyS2W2mE9cz7Wvar7wZADkiWPHVszrZk3iwSZRti8DtYuT9YLH2ZoNWDYru/IlHogYODIbn+s2YGjlIg+1Xy0Lnh3Y4mgkL63UHjPu3Z4GgQOgoPf3z4wDHmP3z+w4mrSd16GH9R53oikNVsqyGxZD2+9Aq8/nbR4oqX9cS78dzj8zG49DQeOUh76Aiz8XvKYX3VNct+ydb26Bqpq0u00vaqmYL116d9B2cLj7O5xW7db1/fxi1dzE2xaUzowFD7aWdUvbS0cBIecULy1MGBIz5yP7VskqB2aLPsf2nn+lpakr6ywb+Y9k7q9ahUNHJLOBG4mmXP8uxFxY8H+LwKfzNTlSGA0MAj4AfAeoAW4LSJuTstcD3wGaEzLfSkiHqrICfyX05MnKZp3JEvLDmjenlyQmren29l9O6Bpe/KETHZfYdnW9cL73t1O3ROQcgXMHPtKHrdwXydBr/Uls1JBYdPq9r/A9huRBIARh8CEk9oHhsFjHHCtb6qqSm9f7V/xr6rYnOOSqoHfA6cDDcBC4MKIWN5B/rOBayLiQ5LGAmMj4hlJQ4BFwEcjYnkaODZHxNfy1qXXzjkekT8gNe9ov681+DRvL56/1HELyxY9Tok6VTroqarjgKTq5D5wYUdjVU36mGb2zeZMYBg6Lnm6xsxy6WjO8Uq2OKYDKyLi5bQC9wDnAkUDB3AhcDdARKwB1qTrmyQ9D4wrUbZvktK3cvuTNLL6kJaWncGmS8GsjFZc4XFbmpOWQWFrYdCYvfrZebPeopKBYxzwema7ATiuWEZJA4EzgauK7JsATAWeyiRfJekvgXrgbyLij0XKzQZmAxx88MFdOwPrWFUVVPX3aKdm+6BK/jwr9jhSR/fFzgb+MyJ2eZtG0mDgJ8DVEbExTb4FOBSYQtIq+XqxA0bEbRFRFxF1o0fnHMrAzMw6VcnA0QBknzkbD6zuIO9M0ttUrSTVkASNuRHx09b0iFgbEc0R0QLcTnJLzMzM9pBKBo6FwGGSJkrqTxIcHijMJGkY8EHg/kyagO8Bz0fETQX5x2Y2zwOWVqDuZmbWgYr1cUREk6SrgEdIHse9IyKWSbo83X9rmvU8YH5EbMkUPxH4C+A5SYvTtNbHbr8qaQrJba+VwGWVOgczM2uvYo/j9ia99nFcM7NerKPHcf3sopmZlcWBw8zMyuLAYWZmZdkn+jgkNQKvdrH4KGB9N1anJ/lcep+95TzA59Jb7c65HBIR7V6E2ycCx+6QVF+sc6gv8rn0PnvLeYDPpbeqxLn4VpWZmZXFgcPMzMriwNG523q6At3I59L77C3nAT6X3qrbz8V9HGZmVha3OMzMrCwOHGZmVhYHjg5IqpX0tKRnJS2TdENP12l3SKqW9DtJ/9HTddkdklZKek7SYkl9egAyScMl3SvpBUnPS3p/T9epKyQdnv73aF02Srq6p+vVFZKuSf+9L5V0t6Tanq5TV0n6fHoey7r7v4f7ODqQDu0+KCI2p3OD/Ab4fEQ82cNV6xJJfw3UAUMj4iM9XZ+ukrQSqIuIPv9ylqS7gAUR8d106oGBEfF2D1drt0iqBlYBx0VEV1+67RGSxpH8Oz8qIrZKmgc8FBF39mzNyidpEnAPyXxF24GHgSsi4qXuOL5bHB2IxOZ0syZd+mSUlTQe+G/Ad3u6LpaQNBQ4mWTeGSJie18PGqnTgD/0taCR0Q/YT1I/YCAdTz7X2x0JPBkR70REE/BrkiksuoUDRwnp7Z3FwDrg0Yh4qpMivdU3gf8OtPRwPbpDAPMlLUrnle+r3gs0At9PbyF+V9Kgnq5UN2g3m2dfERGrgK8Br5FMS70hIub3bK26bClwsqT9JQ0EzmLXGVl3iwNHCekUtVNIpr2dnjb/+hRJHwHWRcSinq5LNzkxIqYBM4ArJZ3c0xXqon7ANOCWiJgKbAHm9GyVdk96u+0c4Mc9XZeukDQCOBeYCBwIDJJ0Uc/Wqmsi4nngn4BHSW5TPQs0ddfxHThySG8h/Ao4s2dr0iUnAuekfQP3AB+S9MOerVLXRcTq9HMdcB99d875BqAh04q9lySQ9GUzgGciYm1PV6SL/hR4JSIaI2IH8FPghB6uU5dFxPciYlpEnAy8BXRL/wY4cHRI0mhJw9P1/Uj+p3qhRyvVBRFxXUSMj4gJJLcR/m9E9MlfUZIGSRrSug6cQR+dcz4i3gBel3R4mnQasLwHq9QdLqSP3qZKvQYcL2lg+nDMacDzPVynLpM0Jv08GPgY3fjfpmJzju8FxgJ3pU+JVAHzIqJPP8q6FzgAuC/5N00/4EcR8XDPVmm3fA6Ym97ieRmY1cP16bL0PvrpwGU9XZeuioinJN0LPENyW+d39O2hR34iaX9gB3BlRPyxuw7sx3HNzKwsvlVlZmZlceAwM7OyOHCYmVlZHDjMzKwsDhxmZlYWBw6zDkj6laS6PfA9f5WOjju3yL67JS2RdE0XjnuKpD77Apv1Xn6Pw6wCJPVLB5fL47PAjIh4peAY7wFOiIhDuliNU4DNwG/zFpBUHRHNXfw+20e4xWF9mqQJ6a/129N5B+anb/rv0mKQNCoddgVJl0j6maQHJb0i6SpJf50ONvikpJGZr7hI0m/TeQ2mp+UHSbpD0sK0zLmZ4/5Y0oNAu8Hx0u9Ymi5Xp2m3kgx4+ECRVsV8YEw6x8UHJB0q6eF0gMcFko5Ij3G2pKfSuvxS0gGSJgCXA9dkyt8p6fxMfTann6dIelzSj4Dn0sE9/zk9vyWSLkvzjZX0RHq8pZI+sDv/7awPiwgvXvrsAkwgect3Sro9D7goXf8VydwdAKOAlen6JcAKYAgwGtgAXJ7u+wZwdab87en6ycDSdP1/Z75jOPB7YFB63AZgZJF6vg94Ls03GFgGTE33rQRGdXBuSzPbjwGHpevHkQwfAzCCnS/zfhr4erp+PfCFTPk7gfMz25vTz1NIBlmcmG7PBv42XR8A1JMM/Pc3wP9I06uBIT39399Lzyy+VWV7g1ciYnG6vojkgtuZxyNiE7BJ0gbgwTT9OWByJt/dABHxhKSh6fhlZ5AMHPmFNE8tcHC6/mhEvFXk+04C7ouILQCSfgp8gGRYi05JGkwy4N6P0yFXILmoQzJ6879LGgv0B15pf4ROPR07b5WdAUzOtE6GAYcBC4E7lExs9rPM39z2MQ4ctjfYlllvBvZL15vYeTu2cArQbJmWzHYLu/67KByTJwABfxYRL2Z3SDqO5Jd7MeogPa8q4O1Ihvkv9C/ATRHxgKRTSFoaxbT9PdJB/Ppn9mXrLeBzEfFI4QHSYez/G/Bvkv45In5Q3mnY3sB9HLY3W0lyiwjg/BL5SrkAQNJJJBP7bAAeAT6XXnyRNDXHcZ4APpqOvDqIZDa2BXkrEREbgVck/Xn6nZJ0bLp7GMl0rQAXZ4ptIrkd12olO/8e55LMalnMI8AVacsCSX+S9uscQjK3y+0kMxf29WHgrYscOGxv9jWSC+BvSfo4uuKPaflbgUvTtK+QXHSXSFqabpcUEc+Q9DE8DTwFfDcict2myvgkcKmkZ0n6SM5N068nuYW1AMjOxf4gcF5r5zhwO/BBSU+T9JF01Dr6LskQ78+k5/d/SFphpwCLJf0O+DPg5jLrb3sJj45rZmZlcYvDzMzK4sBhZmZlceAwM7OyOHCYmVlZHDjMzKwsDhxmZlYWBw4zMyvL/wd/vCd0PHZsGAAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>There is no significant variation in the accuracies, only from the testing accuracy we clearly see that we can choose the optimal number of features as 7.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now that we have an intuition for the optimal ranges, we loop through some candidate values (grid search) to get the best combination of hyperparameters. This time we do not save all the values, just update the optimal parameters on the fly.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[264]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_trees</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">30</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate numbers of features&#39;</span><span class="p">,</span><span class="n">nbs_trees</span><span class="p">)</span>
<span class="n">nbs_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate numbers of features&#39;</span><span class="p">,</span><span class="n">nbs_feat</span><span class="p">)</span>
<span class="n">depths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate depths&#39;</span><span class="p">,</span><span class="n">depths</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>candidate numbers of features [3, 13, 20, 25, 30]
candidate numbers of features [5 7 9]
candidate depths [2 4 6]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[260]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_acc_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_acc_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [tree, n_features, depths]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">tr</span> <span class="ow">in</span> <span class="n">nbs_trees</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Loading for&#39;</span><span class="p">,</span><span class="n">tr</span><span class="p">,</span><span class="s1">&#39;trees...&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">nbs_feat</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading for&#39;</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="s1">&#39;features...&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span> <span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">tr</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">print_accs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">acc_new_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_val</span><span class="o">&gt;</span><span class="n">max_acc_val</span><span class="p">:</span>
                <span class="n">max_acc_val</span> <span class="o">=</span> <span class="n">acc_new_val</span>
                <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
            <span class="n">acc_new_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="s1">&#39;average testing accuracy&#39;</span><span class="p">,</span><span class="n">acc_new_test</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_test</span><span class="o">&gt;</span><span class="n">max_acc_test</span><span class="p">:</span>
                <span class="n">max_acc_test</span> <span class="o">=</span> <span class="n">acc_new_test</span>
                <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max_acc_val&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">list_params_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max_acc_test&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">list_params_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Loading for 3 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.647
depth 4 average testing accuracy 0.6319999999999999
depth 6 average testing accuracy 0.646
Loading for 7 features...
depth 2 average testing accuracy 0.6599999999999999
depth 4 average testing accuracy 0.67
depth 6 average testing accuracy 0.662
Loading for 9 features...
depth 2 average testing accuracy 0.6449999999999999
depth 4 average testing accuracy 0.6359999999999999
depth 6 average testing accuracy 0.6540000000000001

Loading for 13 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.714
depth 4 average testing accuracy 0.72
depth 6 average testing accuracy 0.7190000000000001
Loading for 7 features...
depth 2 average testing accuracy 0.7219999999999999
depth 4 average testing accuracy 0.7129999999999999
depth 6 average testing accuracy 0.72
Loading for 9 features...
depth 2 average testing accuracy 0.7220000000000001
depth 4 average testing accuracy 0.717
depth 6 average testing accuracy 0.716

Loading for 20 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.718
depth 4 average testing accuracy 0.728
depth 6 average testing accuracy 0.7209999999999999
Loading for 7 features...
depth 2 average testing accuracy 0.708
depth 4 average testing accuracy 0.718
depth 6 average testing accuracy 0.7289999999999999
Loading for 9 features...
depth 2 average testing accuracy 0.7140000000000001
depth 4 average testing accuracy 0.72
depth 6 average testing accuracy 0.708

Loading for 25 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.729
depth 4 average testing accuracy 0.727
depth 6 average testing accuracy 0.728
Loading for 7 features...
depth 2 average testing accuracy 0.7290000000000001
depth 4 average testing accuracy 0.723
depth 6 average testing accuracy 0.728
Loading for 9 features...
depth 2 average testing accuracy 0.728
depth 4 average testing accuracy 0.7330000000000001
depth 6 average testing accuracy 0.727

Loading for 30 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.736
depth 4 average testing accuracy 0.7310000000000001
depth 6 average testing accuracy 0.73
Loading for 7 features...
depth 2 average testing accuracy 0.727
depth 4 average testing accuracy 0.735
depth 6 average testing accuracy 0.7270000000000001
Loading for 9 features...
depth 2 average testing accuracy 0.731
depth 4 average testing accuracy 0.733
depth 6 average testing accuracy 0.728
max_acc_val 0.9099999999999999
[30, 7, 6]
max_acc_test 0.736
[30, 5, 2]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[262]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal hyperparameters for the validation sets are:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of trees&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Depth&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on validation sets over the five folds (average in-sample):&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>The optimal hyperparameters for the validation sets are:
Number of trees 30
Number of features 7
Depth 6
Accuracy on validation sets over the five folds (average in-sample): 0.9099999999999999
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[263]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal hyperparameters for the testing are:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of trees&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Depth&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on test set over the five folds (average out-of-sample):&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>The optimal hyperparameters for the testing are:
Number of trees 30
Number of features 5
Depth 2
Accuracy on validation sets over the five folds (average in-sample): 0.736
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="alternative-accuracy-aggregation">alternative accuracy aggregation<a class="anchor-link" href="#alternative-accuracy-aggregation">&#182;</a></h5><p>We now take the metric of determining the hyperparameters based on the accuracies calculated for the prediction of each individual tree, averaged out in the number of trees in the forest, which is then averaged out over the five folds. We do this both for the validation and test sets.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_trees</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">25</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate numbers of features&#39;</span><span class="p">,</span><span class="n">nbs_trees</span><span class="p">)</span>
<span class="n">nbs_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate numbers of features&#39;</span><span class="p">,</span><span class="n">nbs_feat</span><span class="p">)</span>
<span class="n">depths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate depths&#39;</span><span class="p">,</span><span class="n">depths</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>candidate numbers of features [3, 13, 25]
candidate numbers of features [5 7 9]
candidate depths [2 4 6]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_acc_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_acc_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [tree, n_features, depths]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">tr</span> <span class="ow">in</span> <span class="n">nbs_trees</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Loading for&#39;</span><span class="p">,</span><span class="n">tr</span><span class="p">,</span><span class="s1">&#39;trees...&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">nbs_feat</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading for&#39;</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="s1">&#39;features...&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">,</span> <span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">tr</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">print_accs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">acc_new_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_val</span><span class="o">&gt;</span><span class="n">max_acc_val</span><span class="p">:</span>
                <span class="n">max_acc_val</span> <span class="o">=</span> <span class="n">acc_new_val</span>
                <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
            <span class="n">acc_new_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="s1">&#39;average testing accuracy&#39;</span><span class="p">,</span><span class="n">acc_new_test</span><span class="p">)</span>  <span class="c1"># print out the most important metric</span>
            <span class="k">if</span> <span class="n">acc_new_test</span><span class="o">&gt;</span><span class="n">max_acc_test</span><span class="p">:</span>
                <span class="n">max_acc_test</span> <span class="o">=</span> <span class="n">acc_new_test</span>
                <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Loading for 3 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.5933333333333335
depth 4 average testing accuracy 0.6033333333333333
depth 6 average testing accuracy 0.6026666666666667
Loading for 7 features...
depth 2 average testing accuracy 0.607
depth 4 average testing accuracy 0.6166666666666667
depth 6 average testing accuracy 0.6053333333333334
Loading for 9 features...
depth 2 average testing accuracy 0.6026666666666667
depth 4 average testing accuracy 0.6063333333333333
depth 6 average testing accuracy 0.6106666666666667

Loading for 13 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.605
depth 4 average testing accuracy 0.5963076923076923
depth 6 average testing accuracy 0.6040769230769231
Loading for 7 features...
depth 2 average testing accuracy 0.5951538461538461
depth 4 average testing accuracy 0.599076923076923
depth 6 average testing accuracy 0.6116153846153847
Loading for 9 features...
depth 2 average testing accuracy 0.599923076923077
depth 4 average testing accuracy 0.5983846153846153
depth 6 average testing accuracy 0.6003846153846154

Loading for 25 trees...
Loading for 5 features...
depth 2 average testing accuracy 0.6022000000000001
depth 4 average testing accuracy 0.60256
depth 6 average testing accuracy 0.59772
Loading for 7 features...
depth 2 average testing accuracy 0.6049999999999999
depth 4 average testing accuracy 0.60252
depth 6 average testing accuracy 0.60084
Loading for 9 features...
depth 2 average testing accuracy 0.60104
depth 4 average testing accuracy 0.6052000000000001
depth 6 average testing accuracy 0.60068
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation set:&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal parameters: [trees, n_features, depth]:&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set:&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal parameters: [trees, n_features, depth]:&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Validation set: 0.8375
optimal parameters: [trees, n_features, depth]: [3, 9, 2]
Test set: 0.6166666666666667
optimal parameters: [trees, n_features, depth]: [3, 7, 4]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>This method of calculating the accuracies is not the best as it gives the optimal number of trees as the smallest one, while it is expected that the accuracy goes up as the number of trees increases.</p>
<p>Recall that the most important metric is the testing accuracy, but it is also important to see the accuracies on the training set to have a reasonable qualitative intuition about overfitting the training data, balancing out the generalisation to the testing data.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We therefore take the optimal hyperparameters based on the accuracies calculated using the first method, and those computed on the testing set: 30 trees, 5 features and depth 2.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now remove columns 0 and 2 where we have a lot of unique values which makes the tree always to predict based on that value. The small optimal depth also makes sense as trees never really goes into depth after we have a number of features larger than 3. Then we will perform the grid search for that and compare the accuracy we get in the next subsection.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[107]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># remove the columns</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr_train1</span><span class="p">[</span><span class="mi">1</span><span class="p">,:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">arr_train2</span> <span class="o">=</span> <span class="n">arr_train1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">arr_train2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_train2</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr_train2</span><span class="p">[</span><span class="mi">1</span><span class="p">,:</span><span class="mi">8</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr_train2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[ 1.10051477 -0.46062483  4.24450299 -0.70944248 -2.01528369 -0.91297701
  0.66004637  0.66426959]
[-0.46062483 -0.70944248 -2.01528369 -0.91297701  0.66004637  0.66426959
  1.69196261 -0.85972695]
(800, 9)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We need to be mindful that we cannot have more than 4 features to do the cross-validation</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[329]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_feat</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>

<span class="n">max_acc_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_acc_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [tree, n_features, depths]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">tr</span> <span class="ow">in</span> <span class="n">nbs_trees</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Loading for&#39;</span><span class="p">,</span><span class="n">tr</span><span class="p">,</span><span class="s1">&#39;trees...&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">nbs_feat</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading for&#39;</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="s1">&#39;features...&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train2</span><span class="p">,</span> <span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">tr</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">print_accs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">acc_new_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_val</span><span class="o">&gt;</span><span class="n">max_acc_val</span><span class="p">:</span>
                <span class="n">max_acc_val</span> <span class="o">=</span> <span class="n">acc_new_val</span>
                <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
            <span class="n">acc_new_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="s1">&#39;average testing accuracy&#39;</span><span class="p">,</span><span class="n">acc_new_test</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_test</span><span class="o">&gt;</span><span class="n">max_acc_test</span><span class="p">:</span>
                <span class="n">max_acc_test</span> <span class="o">=</span> <span class="n">acc_new_test</span>
                <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max_acc_val&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">list_params_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max_acc_test&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">list_params_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Loading for 3 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.567
depth 4 average testing accuracy 0.592
depth 6 average testing accuracy 0.6210000000000001
Loading for 2 features...
depth 2 average testing accuracy 0.579
depth 4 average testing accuracy 0.621
depth 6 average testing accuracy 0.587

Loading for 13 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.677
depth 4 average testing accuracy 0.6839999999999999
depth 6 average testing accuracy 0.6890000000000001
Loading for 2 features...
depth 2 average testing accuracy 0.672
depth 4 average testing accuracy 0.666
depth 6 average testing accuracy 0.667

Loading for 20 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.6759999999999999
depth 4 average testing accuracy 0.689
depth 6 average testing accuracy 0.6950000000000001
Loading for 2 features...
depth 2 average testing accuracy 0.683
depth 4 average testing accuracy 0.6719999999999999
depth 6 average testing accuracy 0.6579999999999999

Loading for 25 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.716
depth 4 average testing accuracy 0.7060000000000001
depth 6 average testing accuracy 0.718
Loading for 2 features...
depth 2 average testing accuracy 0.704
depth 4 average testing accuracy 0.712
depth 6 average testing accuracy 0.693

Loading for 30 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.6950000000000001
depth 4 average testing accuracy 0.707
depth 6 average testing accuracy 0.7139999999999999
Loading for 2 features...
depth 2 average testing accuracy 0.707
depth 4 average testing accuracy 0.6910000000000001
depth 6 average testing accuracy 0.6859999999999999
max_acc_val 0.9000000000000001
[30, 2, 2]
max_acc_test 0.718
[25, 1, 6]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Print out the optimal hyperparameters based on the accuracies over the validation and test sets:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[331]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal hyperparameters for the validation sets are:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of trees&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Depth&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on validation sets over the five folds (average in-sample):&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal hyperparameters for the testing are:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of trees&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Depth&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on test set over the five folds (average out-of-sample):&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>The optimal hyperparameters for the validation sets are:
Number of trees 30
Number of features 2
Depth 2
Accuracy on validation sets over the five folds (average in-sample): 0.9000000000000001
The optimal hyperparameters for the testing are:
Number of trees 25
Number of features 1
Depth 6
Accuracy on test set over the five folds (average out-of-sample): 0.718
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="alternative-accuracy-aggregation">alternative accuracy aggregation<a class="anchor-link" href="#alternative-accuracy-aggregation">&#182;</a></h5>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[113]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbs_feat</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>

<span class="n">max_acc_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_acc_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [tree, n_features, depths]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">tr</span> <span class="ow">in</span> <span class="n">nbs_trees</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Loading for&#39;</span><span class="p">,</span><span class="n">tr</span><span class="p">,</span><span class="s1">&#39;trees...&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">nbs_feat</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading for&#39;</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="s1">&#39;features...&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">val_accs</span><span class="p">,</span><span class="n">test_accs</span> <span class="o">=</span> <span class="n">cross_val_evaluate_RF</span><span class="p">(</span><span class="n">arr_train2</span><span class="p">,</span> <span class="n">arr_test1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">n_trees</span><span class="o">=</span><span class="n">tr</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">print_accs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">acc_new_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">val_accs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_val</span><span class="o">&gt;</span><span class="n">max_acc_val</span><span class="p">:</span>
                <span class="n">max_acc_val</span> <span class="o">=</span> <span class="n">acc_new_val</span>
                <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
                
            <span class="n">acc_new_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">test_accs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="s1">&#39;average testing accuracy&#39;</span><span class="p">,</span><span class="n">acc_new_test</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">acc_new_test</span><span class="o">&gt;</span><span class="n">max_acc_test</span><span class="p">:</span>
                <span class="n">max_acc_test</span> <span class="o">=</span> <span class="n">acc_new_test</span>
                <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">tr</span><span class="p">,</span><span class="n">feat</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Loading for 3 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.5883333333333332
depth 4 average testing accuracy 0.5656666666666667
depth 6 average testing accuracy 0.5613333333333334
Loading for 2 features...
depth 2 average testing accuracy 0.5543333333333333
depth 4 average testing accuracy 0.5666666666666667
depth 6 average testing accuracy 0.5743333333333334

Loading for 13 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.5697692307692308
depth 4 average testing accuracy 0.5783846153846154
depth 6 average testing accuracy 0.5806153846153845
Loading for 2 features...
depth 2 average testing accuracy 0.5693076923076923
depth 4 average testing accuracy 0.5664615384615385
depth 6 average testing accuracy 0.5739230769230769

Loading for 25 trees...
Loading for 1 features...
depth 2 average testing accuracy 0.5730000000000001
depth 4 average testing accuracy 0.5763199999999999
depth 6 average testing accuracy 0.58284
Loading for 2 features...
depth 2 average testing accuracy 0.56284
depth 4 average testing accuracy 0.5767599999999999
depth 6 average testing accuracy 0.56896
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[114]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation set:&#39;</span><span class="p">,</span><span class="n">max_acc_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal parameters: [trees, n_features, depth]:&#39;</span><span class="p">,</span><span class="n">list_params_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set:&#39;</span><span class="p">,</span><span class="n">max_acc_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimal parameters: [trees, n_features, depth]:&#39;</span><span class="p">,</span><span class="n">list_params_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Validation set: 0.86
optimal parameters: [trees, n_features, depth]: [3, 2, 2]
Test set: 0.5883333333333332
optimal parameters: [trees, n_features, depth]: [3, 1, 2]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Here again we see that the optimal parameters are not what we would expect them to be, especially the number of trees, and removing the columns with the unique predictors dod not really increase the accuracy. Therefore, we will go with the optimal parameters determined using the former accuracy metric.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="2.2.2.">2.2.2.<a class="anchor-link" href="#2.2.2.">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We have number of trees 30, number of features 5, depth 2, with our grid search for the full training set. On the reduced one, we get number of trees 25, number of features 1, depth 6.</p>
<p>Investigate the errors in both cases. We first define the confusion matrix from scratch (it was suggested on Piazza that we need to show how to implement that).</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_actual</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_actual</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span> <span class="n">tp</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span> <span class="n">fp</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="n">tn</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="n">fn</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">print_info</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TP:&#39;</span><span class="p">,</span><span class="n">tp</span><span class="p">,</span><span class="s1">&#39;FP:&#39;</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span><span class="s1">&#39;TN:&#39;</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span><span class="s1">&#39;FN:&#39;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Investigate just one tree:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">30</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[333]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas dataframe</span>
<span class="n">y_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas series</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X_train_cm</span><span class="p">,</span> <span class="n">y_train_cm</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_train_cm</span><span class="p">,</span> <span class="n">y_train_cm</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>

<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_train_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>

<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>
<span class="n">confusion_matrix_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">confusion_matrix_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted  0.0  1.0
Actual             
0.0        231    1
1.0          1  567
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>For the test set:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[334]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_test_cm</span><span class="p">,</span> <span class="n">y_test_cm</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>  <span class="c1"># use the tree trained on the training set</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_test_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span> <span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>

<span class="n">confusion_matrix_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">confusion_matrix_test</span><span class="p">)</span>

<span class="c1"># import seaborn as sb</span>
<span class="c1"># sb.heatmap(confusion_matrix_test, annot=True) # visualise nicely</span>
<span class="c1"># plt.show()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted  0.0  1.0
Actual             
0.0          9   44
1.0         45  102
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Confusion matrix entries are the number of true positives (predicted is 1, actual is 1), true negatives (predicted is 0, actual is 0), false negatives (predicted is 1, actual is 0), true positives (predicted is 0, actual is 1).</p>
<p>We notice that for one tree, we actually get quite good predictions, although we are overfitting the training set significantly because the in-sample accuracy is much higher than the one on the test set.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define a function to train our data using an optimal random forest:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[165]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># iterate through the trees in the forest:</span>
    
<span class="k">def</span> <span class="nf">eval_forest</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>

    <span class="n">y_trains_forest</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_val_forest</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trees</span><span class="p">):</span>
        <span class="n">sample_tr</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">data_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">X_tr1</span> <span class="o">=</span> <span class="n">sample_tr</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_tr1</span> <span class="o">=</span> <span class="n">sample_tr</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">X_tr2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_tr2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># create the tree with this set of parameters and sampled training set</span>
        <span class="n">tree</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X_tr1</span><span class="p">,</span> <span class="n">y_tr1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>

        <span class="c1"># get the accuracy and prediction for each individual tree</span>
        <span class="n">tr_y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_tr1</span><span class="p">,</span> <span class="n">y_tr1</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>  <span class="c1"># we need to input the training set, the testing set and the hyperparameters </span>
        <span class="n">val_y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_tr2</span><span class="p">,</span> <span class="n">y_tr2</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>

        <span class="c1"># call the predict function, append the y_preds</span>
        <span class="n">y_trains_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tr_y_pred</span><span class="p">)</span>
        <span class="n">y_val_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_y_pred</span><span class="p">)</span>
            
    <span class="c1"># sum the predictions of the trees over the forest</span>
    <span class="n">y_tr_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">y_trains_forest</span><span class="p">)]</span>
    <span class="n">y_val_sum_forest</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">y_val_forest</span><span class="p">)]</span>

    <span class="c1"># divide by the number of trees</span>
    <span class="n">y_tr_forest</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">n_trees</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_tr_sum_forest</span><span class="p">]</span>
    <span class="n">y_val_forest</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">n_trees</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_val_sum_forest</span><span class="p">]</span>

    <span class="c1"># set to 1 if above 0.5 set to 0 if below 0.5, set the case for 0.5 to equal 0 to avoid false positives</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_tr_forest</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">y_tr_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
            <span class="n">y_tr_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_tr_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_val_forest</span><span class="p">)):</span>  <span class="c1"># this is our y_pred over the validation fold</span>
        <span class="k">if</span> <span class="n">y_val_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
            <span class="n">y_val_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_val_forest</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
            
    <span class="k">return</span> <span class="n">y_tr_forest</span><span class="p">,</span> <span class="n">y_val_forest</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Get the predictions from the random forest using optimal hyperparameters:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[139]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">30</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[140]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred_train</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">eval_forest</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[141]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train set</span>
<span class="n">X_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas dataframe</span>
<span class="n">y_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas series</span>

<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_train_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred_train</span><span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>

<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>
<span class="n">confusion_matrix_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix_train</span><span class="p">)</span>

<span class="c1"># get accuracy</span>
<span class="n">score12</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_pred_train</span><span class="p">,</span> <span class="n">y_actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Accuracy on training set is &#39;</span><span class="p">,</span><span class="n">score12</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted  0    1
Actual           
0.0        3  229
1.0        6  562

Accuracy on training set is  0.70625
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[142]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test set</span>

<span class="n">X_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_test_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred_test</span> <span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>

<span class="n">confusion_matrix_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">confusion_matrix_test</span><span class="p">)</span>

<span class="c1"># get accuracy</span>
<span class="n">score12</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">,</span> <span class="n">y_actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Accuracy on testing set is&#39;</span><span class="p">,</span><span class="n">score12</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted  0    1
Actual           
0.0        1   52
1.0        3  144

Accuracy on testing set is 0.725
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>From our random forest predictions both on the train and test set, we see that the random forest results in the predictions being biased towards positives, both true and false. This may be a result of overfitting the training data which itself contains a lot of positives.</p>
<p>From the logistic regression implementation, we got a 76% accuracy for the test set. Therefore, the random forest model is not the best choice for this dataset.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now run the model for the dataset with columns 0 and 2 eliminated and the hyperparameters we found using a grid search: number of trees 25, number of features 1, depth 6.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[179]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[180]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_train_c</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">data_test_c</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[181]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_train_c</span> <span class="o">=</span> <span class="n">data_train_c</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data_test_c</span> <span class="o">=</span> <span class="n">data_test_c</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[182]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get predictions</span>
<span class="n">y_pred_train</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">eval_forest</span><span class="p">(</span><span class="n">data_train_c</span><span class="p">,</span> <span class="n">data_test_c</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[183]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train set</span>
<span class="n">X_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas dataframe</span>
<span class="n">y_train_cm</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pandas series</span>

<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_train_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred_train</span><span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>

<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>
<span class="n">confusion_matrix_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix_train</span><span class="p">)</span>


<span class="c1"># get accuracy</span>
<span class="n">score12</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_pred_train</span><span class="p">,</span> <span class="n">y_actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Accuracy on training set is &#39;</span><span class="p">,</span><span class="n">score12</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted  0    1
Actual           
0.0        3  229
1.0        0  568

Accuracy on training set is  0.71375
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[184]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test set</span>

<span class="n">X_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_cm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_test_cm</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">:</span> <span class="n">y_actual</span><span class="p">,</span>
        <span class="s1">&#39;y_Pred&#39;</span><span class="p">:</span> <span class="n">y_pred_test</span> <span class="p">}</span> <span class="c1"># create a dict to input data in pd.corsstab</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">,</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">])</span>

<span class="n">confusion_matrix_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Actual&#39;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;y_Pred&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">])</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">confusion_matrix_test</span><span class="p">)</span>

<span class="c1"># get accuracy</span>
<span class="n">score12</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">score2</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">,</span> <span class="n">y_actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Accuracy on testing set is&#39;</span><span class="p">,</span><span class="n">score12</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Predicted   0    1
Actual            
0.0         7   46
1.0        17  130

Accuracy on testing set is 0.685
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We can see that removing the zero and second columns with many unique values did not really affect the accuracy of the traning, suggesting that perhaps the training set with the removed columns has too little descriptors and the model ends up overfitting the training data.</p>
<p>An alternative to the current approach would be modifying the building of the tree from the ground to change the branching pattern that arises in this case due to the high number of unique values in some of the columns.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="2.3.-SVMs">2.3. SVMs<a class="anchor-link" href="#2.3.-SVMs">&#182;</a></h3>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We define the hinge loss as 
$$
\mathcal L (\boldsymbol w) = \frac{1}{2} \| \boldsymbol w \|^2 + \frac{\lambda}{n} \sum_{i=1}^n \max \bigg( 0, 1-y_i (\boldsymbol w \cdot x_i + b) \bigg) \, .
$$
where $\boldsymbol w$ is the vector of weights that defines the hyperplane, $\lambda$ is the regularisation parameter, and $b$ the intercept which is included in <code>X_train</code> as the additional last column of $1$'s.</p>
<p>Note about the interpretation of the margin: in the notebooks, we were given an algorithm that can work (roughly) for both types of margins, depending on the regularisation parameter $\lambda$ that is set. If we set it to a very large value, we recover the hard margin as errors are penalised harshly, while a very small $\lambda$ allows for a tight fit that may be too specific to the training data. This parameter essentially allows us to control the tradeoff between the complexity of the model (too complex and specific leads to overfitting) and minimising training errors (accuracy).</p>
<p>The considerations whether the data is linearly separable are crucial here - data that is non-linearly separable will not be fit well using any hard-margin approach using a large value for $\lambda$.</p>
<p>Also, we use the maximum function to account for the fact that we only take into account the values that satisfy the constraint, otherwise they do not contribute to the definition of the hyperplane that separates the data and is essentially the model.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="2.3.1.">2.3.1.<a class="anchor-link" href="#2.3.1.">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Prepare the data</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[269]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get the data ready</span>
<span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_train.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
<span class="c1"># Test data</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;classification_test.csv&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[270]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># training set into matrix</span>
<span class="n">arr_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;full dataset size&#39;</span><span class="p">,</span><span class="n">arr_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">arr_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_train</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># eliminate the sixth column in train set</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span> <span class="c1"># shuffle it with the same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_train</span><span class="p">)</span> <span class="c1"># this is a numpy array</span>

<span class="c1"># split it to standardise</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c1"># standardise</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">arr_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;shape of matrix X containing training predictors&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;length of y_train&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="c1"># test set into matrix</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">arr_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr_test</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># eliminate the sixth column in train set and test set</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1007</span><span class="p">)</span> <span class="c1"># shuffle it with same seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">arr_test</span><span class="p">)</span>

<span class="c1"># split it</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">standardise</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># standardise</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">arr_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">shapes of X_train and X_test:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>full dataset size (800, 12)
shape of matrix X containing training predictors (800, 10)
length of y_train 800

shapes of X_train and X_test:
 (800, 10)
(200, 10)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[271]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># stack the standardised training data together and turn into dataframe</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span><span class="o">+</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>  
<span class="n">data_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>

<span class="c1"># stack the standardised testing data together and turn into dataframe</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">+</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>  
<span class="n">data_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[272]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[272]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.492510</td>
      <td>-1.350721</td>
      <td>1.186774</td>
      <td>-0.074595</td>
      <td>-2.015284</td>
      <td>-1.822543</td>
      <td>-0.307055</td>
      <td>-0.143899</td>
      <td>1.691963</td>
      <td>1.163160</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.100515</td>
      <td>-0.460625</td>
      <td>4.244503</td>
      <td>-0.709442</td>
      <td>-2.015284</td>
      <td>-0.912977</td>
      <td>0.660046</td>
      <td>0.664270</td>
      <td>1.691963</td>
      <td>-0.859727</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.100515</td>
      <td>-0.460625</td>
      <td>4.244503</td>
      <td>-0.709442</td>
      <td>-2.015284</td>
      <td>-0.912977</td>
      <td>0.660046</td>
      <td>0.664270</td>
      <td>1.691963</td>
      <td>-0.859727</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[273]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># convert 1/0 labels to 1/-1 train and set</span>
<span class="n">diag_map</span> <span class="o">=</span> <span class="p">{</span><span class="mf">1.0</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">:</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">}</span>
<span class="n">data_train</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">diag_map</span><span class="p">)</span>
<span class="n">data_test</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">diag_map</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[274]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[274]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.492510</td>
      <td>-1.350721</td>
      <td>1.186774</td>
      <td>-0.074595</td>
      <td>-2.015284</td>
      <td>-1.822543</td>
      <td>-0.307055</td>
      <td>-0.143899</td>
      <td>1.691963</td>
      <td>1.163160</td>
      <td>-1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.100515</td>
      <td>-0.460625</td>
      <td>4.244503</td>
      <td>-0.709442</td>
      <td>-2.015284</td>
      <td>-0.912977</td>
      <td>0.660046</td>
      <td>0.664270</td>
      <td>1.691963</td>
      <td>-0.859727</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.100515</td>
      <td>-0.460625</td>
      <td>4.244503</td>
      <td>-0.709442</td>
      <td>-2.015284</td>
      <td>-0.912977</td>
      <td>0.660046</td>
      <td>0.664270</td>
      <td>1.691963</td>
      <td>-0.859727</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[275]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[275]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.459248</td>
      <td>-0.330891</td>
      <td>-0.723786</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>0.919853</td>
      <td>1.597770</td>
      <td>-0.456945</td>
      <td>1.479354</td>
      <td>1.128152</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.456957</td>
      <td>-2.095645</td>
      <td>0.198840</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>-0.883780</td>
      <td>-1.351960</td>
      <td>-0.456945</td>
      <td>-0.037932</td>
      <td>-0.886405</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.456957</td>
      <td>-2.095645</td>
      <td>0.198840</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>-0.883780</td>
      <td>-1.351960</td>
      <td>-0.456945</td>
      <td>-0.037932</td>
      <td>-0.886405</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.459248</td>
      <td>-0.330891</td>
      <td>-0.723786</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>0.919853</td>
      <td>1.597770</td>
      <td>-0.456945</td>
      <td>1.479354</td>
      <td>1.128152</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.227906</td>
      <td>-2.095645</td>
      <td>0.411661</td>
      <td>-0.783729</td>
      <td>-2.187385</td>
      <td>-0.883780</td>
      <td>-0.368716</td>
      <td>1.096408</td>
      <td>-0.037932</td>
      <td>1.128152</td>
      <td>-1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[276]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split dataframes into X and y</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">X_11</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_11</span> <span class="o">=</span> <span class="n">y_1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># dataframes</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">X_22</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_22</span> <span class="o">=</span> <span class="n">y_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[277]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># insert 1 in every row for intercept b</span>
<span class="n">X_1</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_1</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">column</span><span class="o">=</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_2</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_2</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">column</span><span class="o">=</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="n">X_111</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_111</span> <span class="o">=</span> <span class="n">y_1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_222</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_222</span> <span class="o">=</span> <span class="n">y_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[278]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[278]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>intercept</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.492510</td>
      <td>-1.350721</td>
      <td>1.186774</td>
      <td>-0.074595</td>
      <td>-2.015284</td>
      <td>-1.822543</td>
      <td>-0.307055</td>
      <td>-0.143899</td>
      <td>1.691963</td>
      <td>1.163160</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.100515</td>
      <td>-0.460625</td>
      <td>4.244503</td>
      <td>-0.709442</td>
      <td>-2.015284</td>
      <td>-0.912977</td>
      <td>0.660046</td>
      <td>0.664270</td>
      <td>1.691963</td>
      <td>-0.859727</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[279]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[279]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>intercept</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.459248</td>
      <td>-0.330891</td>
      <td>-0.723786</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>0.919853</td>
      <td>1.59777</td>
      <td>-0.456945</td>
      <td>1.479354</td>
      <td>1.128152</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.456957</td>
      <td>-2.095645</td>
      <td>0.198840</td>
      <td>-0.783729</td>
      <td>-0.194323</td>
      <td>-0.883780</td>
      <td>-1.35196</td>
      <td>-0.456945</td>
      <td>-0.037932</td>
      <td>-0.886405</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now write the functions to implement the standard linear hard-margin SVM.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[280]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define function to calculate hinge loss</span>
<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>  
    <span class="n">distances</span><span class="p">[</span><span class="n">distances</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># equivalent to max(0, distance)</span>
    <span class="n">hinge</span> <span class="o">=</span> <span class="n">regul_strength</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> 

    <span class="c1"># calculate cost</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">hinge</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[281]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate gradient of cost</span>
<span class="k">def</span> <span class="nf">calculate_cost_gradient</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="c1"># if only one example is passed</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">y_batch</span><span class="p">])</span>
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">X_batch</span><span class="p">])</span>  <span class="c1"># gives multidimensional array</span>
  
    <span class="n">distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distance</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="p">(</span><span class="n">regul_strength</span> <span class="o">*</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
        <span class="n">dw</span> <span class="o">+=</span> <span class="n">di</span>

    <span class="n">dw</span> <span class="o">=</span> <span class="n">dw</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>  <span class="c1"># average</span>
    <span class="k">return</span> <span class="n">dw</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[282]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sgd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="c1"># write the initial conditions for the weights</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">nth</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="c1"># initialise starting cost as infinity</span>
  <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
  
  <span class="c1"># stochastic gradient descent</span>
  <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">):</span>
      <span class="c1"># shuffle to prevent repeating update cycles</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
          <span class="n">ascent</span> <span class="o">=</span> <span class="n">calculate_cost_gradient</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">regul_strength</span><span class="p">)</span>
          <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">ascent</span><span class="p">)</span>

      <span class="c1"># convergence check on 2^n&#39;th iteration</span>
      <span class="k">if</span> <span class="n">iteration</span><span class="o">==</span><span class="mi">2</span><span class="o">**</span><span class="n">nth</span> <span class="ow">or</span> <span class="n">iteration</span><span class="o">==</span><span class="n">max_iterations</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
          <span class="c1"># compute cost</span>
          <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">)</span> 
          <span class="k">if</span> <span class="n">print_outcome</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration is: </span><span class="si">{}</span><span class="s2">, Cost is: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>
          <span class="c1"># stop criterion</span>
          <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">prev_cost</span> <span class="o">-</span> <span class="n">cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">stop_criterion</span> <span class="o">*</span> <span class="n">prev_cost</span><span class="p">:</span>
              <span class="k">return</span> <span class="n">weights</span>
          
          <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">cost</span>
          <span class="n">nth</span> <span class="o">+=</span> <span class="mi">1</span>
  
  <span class="k">return</span> <span class="n">weights</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>To implement the hard margin, we only need to find the minimal $\textbf{w}$ such that $\frac{1}{2}||\textbf{w}||^2$. But as mentioned before, this is recovered when we set the regul_param to infinity (analytically). Also, if we initialise the weights to a vector of ones, we get slightly better results, but they are strongly dependent on the initial conditions.</p>
<p>Having defined the functions that accommodate the soft margin, we can recover the hard margin by setting the regularisation strength to a very large value; we set $\lambda=10^5$ and hope this is large enough computationally. Recall that this means that the outliers will be penalised harshly; it also means that the model will not work well for data that is not linearly separable.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[283]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">(</span><span class="n">X_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration is: 1, Cost is: 19579374.096242715
Iteration is: 2, Cost is: 20120759.979512103
Iteration is: 4, Cost is: 19328959.818984073
Iteration is: 8, Cost is: 16547165.48981894
Iteration is: 16, Cost is: 13344763.963539356
Iteration is: 32, Cost is: 19116785.03768057
Iteration is: 64, Cost is: 15293428.71455513
Iteration is: 128, Cost is: 17538286.976381686
Iteration is: 256, Cost is: 19036251.698288932
Iteration is: 512, Cost is: 19614068.940503392
Iteration is: 1024, Cost is: 20239485.54946913
Iteration is: 1999, Cost is: 16385728.534843396
Training finished.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[284]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;weights are</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">W</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept b is</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">W</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>weights are
 [-222.34315743  196.61590873   19.11303331  192.30815372 -290.80021471
  -24.25344027 -112.10816389   84.23021442 -293.92029722  161.40955737
  626.36772877]
intercept b is
 626.3677287733799
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Evaluate the mean accuracies:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[285]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">W</span><span class="p">))</span>
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_preds</span><span class="o">==</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[286]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on train set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy on train set: 0.71625
Accuracy on test set: 0.685
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define a separate function to get the predictio for the linear hard-margin SVM. We are predicting by projecting (with the dot product) the location of each x relative to the hyperplane W defined by the support vectors - if it is 'below' the hyperplane, we get a negative sign, if it is 'above', a positive sign.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[287]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">W</span><span class="p">))</span> 
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_preds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now implement the calculation of the F1 score:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[493]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_actual</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_actual</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span> <span class="n">tp</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span> <span class="n">fp</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==-</span><span class="mi">1</span><span class="p">:</span> <span class="n">tn</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==-</span><span class="mi">1</span><span class="p">:</span> <span class="n">fn</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">print_info</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TP:&#39;</span><span class="p">,</span><span class="n">tp</span><span class="p">,</span><span class="s1">&#39;FP:&#39;</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span><span class="s1">&#39;TN:&#39;</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span><span class="s1">&#39;FN:&#39;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span>

<span class="k">def</span> <span class="nf">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">tp</span><span class="o">+</span><span class="n">fp</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tp</span><span class="o">+</span><span class="n">fn</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span>
        
<span class="k">def</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">print_info</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">precision</span><span class="o">==</span><span class="mi">0</span> <span class="ow">or</span> <span class="n">recall</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">precision</span><span class="o">*</span><span class="n">recall</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">precision</span><span class="o">+</span><span class="n">recall</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">print_info</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;F1 score :&#39;</span><span class="p">,</span><span class="n">f1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f1</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[289]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for training data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now get the F1 scores for the training and testing data</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[290]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training data&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision :&#39;</span><span class="p">,</span><span class="n">precision</span><span class="p">)</span>  <span class="c1"># positive predictive value</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Recall :&#39;</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>  <span class="c1"># sensitivity</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Training data
TP: 516 FP: 175 TN: 57 FN: 52
Precision : 0.7467438494934877
Recall : 0.9084507042253521
F1 score : 0.8196981731532962
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[291]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[292]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Test data
TP: 128 FP: 44 TN: 9 FN: 19
F1 score : 0.8025078369905956
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The scores for the hard-margin linear SVM are not too bad for both training and testing sets, the model seems to generalise well to unseen testing data as the difference between training and testing scores is not very significant.</p>
<p>As an extension, we investgate the optimal regularisation strength to judge whether the hard or soft margin works better with our data and how well it generalises. This will also make it easier to make inferences about how the kernelised SVM works based on the distribution of the data we will observe now. To do that, we do a grid search for the hyperparameter regul_strength in a 5-fold CV.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[293]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span><span class="n">reg_str</span><span class="p">):</span>
  
  <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>  <span class="c1"># we get transposed folds, data is (800, 11) dimensional</span>

  <span class="n">F1_scores</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># for score on validation folds</span>
  <span class="n">F1_train</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># on training fold</span>
  <span class="n">F1_test</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># on test set (most important one)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># define the training set</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># define the validation set</span>
    <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># train the model</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="n">reg_str</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>  <span class="c1"># get y_pred on training fold</span>
    <span class="n">y_pred_val</span> <span class="o">=</span> <span class="n">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span>  <span class="c1"># get y_pred on validation fold</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">predict_linSVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>  <span class="c1"># get y_pred on unseen test set</span>
    
    <span class="c1"># evaluate with F1 score on the train fold</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_pred_train</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1_tr</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">F1_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1_tr</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the validation fold</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_val</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the test set</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1_t</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">F1_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1_t</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_train</span><span class="p">,</span> <span class="n">F1_test</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[294]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we have our training data in dataframes X_1 and y_1, stack them into a numpy</span>
<span class="n">X_1</span><span class="o">=</span><span class="n">X_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_1</span><span class="o">=</span><span class="n">y_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span><span class="o">+</span><span class="n">y_1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">X_2</span><span class="o">=</span><span class="n">X_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_2</span><span class="o">=</span><span class="n">y_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">+</span><span class="n">y_2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="c1"># stack the X and y train together so that permutation does not violate the correspondence of the predictors and outcome</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_1</span><span class="p">,</span><span class="n">y_1</span><span class="p">))</span>  
<span class="n">data_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_2</span><span class="p">,</span><span class="n">y_2</span><span class="p">))</span>  
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now investigate the performance of the linear SVM when we vary the regularisation parameter, which quantifies the importance the errors (misclassifications) in the model. It will also give a glimpse into how linearly separable out data is - recall that for small values of $\lambda$ we have a soft margin, and for large values we recover the hard margin.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reg_strs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mf">1e3</span><span class="p">,</span><span class="mf">1e5</span><span class="p">,</span><span class="mf">1e8</span><span class="p">]</span>
<span class="n">scan_val</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scan_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scan_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">rs</span> <span class="ow">in</span> <span class="n">reg_strs</span><span class="p">:</span>
    <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_tr</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">rs</span><span class="p">)</span>
    <span class="n">scan_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_scores</span><span class="p">))</span>
    <span class="n">scan_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_tr</span><span class="p">))</span>
    <span class="n">scan_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fold 1
Iteration is: 1, Cost is: 3.04451700437138
Iteration is: 2, Cost is: 1.6528903479947485
Iteration is: 4, Cost is: 1.5206789051682774
Iteration is: 8, Cost is: 1.5192433639338672
TP: 446 FP: 154 TN: 29 FN: 11
F1 score : 0.8438978240302744
TP: 110 FP: 42 TN: 7 FN: 1
F1 score : 0.8365019011406843
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 3.0064979328189123
Iteration is: 2, Cost is: 1.6374117899964804
Iteration is: 4, Cost is: 1.5118609371499627
Iteration is: 8, Cost is: 1.511528134023695
TP: 454 FP: 171 TN: 10 FN: 5
F1 score : 0.8376383763837638
TP: 108 FP: 46 TN: 5 FN: 1
F1 score : 0.8212927756653993
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 3.0270865161952423
Iteration is: 2, Cost is: 1.6290486873377907
Iteration is: 4, Cost is: 1.5258355416873473
Iteration is: 8, Cost is: 1.5253424111985612
TP: 450 FP: 157 TN: 26 FN: 7
F1 score : 0.8458646616541353
TP: 106 FP: 41 TN: 8 FN: 5
F1 score : 0.8217054263565892
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 3.052410982024858
Iteration is: 2, Cost is: 1.6385437379990417
Iteration is: 4, Cost is: 1.5218750087114694
Iteration is: 8, Cost is: 1.5218896695419297
TP: 420 FP: 147 TN: 43 FN: 30
F1 score : 0.8259587020648967
TP: 102 FP: 36 TN: 6 FN: 16
F1 score : 0.796875
TP: 138 FP: 45 TN: 8 FN: 9
F1 score : 0.8363636363636363
Fold 5
Iteration is: 1, Cost is: 3.0285230972346753
Iteration is: 2, Cost is: 1.6669575599296107
Iteration is: 4, Cost is: 1.5411298582307984
Iteration is: 8, Cost is: 1.5391592485670629
TP: 426 FP: 154 TN: 37 FN: 23
F1 score : 0.8279883381924199
TP: 118 FP: 33 TN: 8 FN: 1
F1 score : 0.874074074074074
TP: 143 FP: 50 TN: 3 FN: 4
F1 score : 0.8411764705882353
Fold 1
Iteration is: 1, Cost is: 13.09092175409366
Iteration is: 2, Cost is: 13.116266730257463
TP: 456 FP: 183 TN: 0 FN: 1
F1 score : 0.8321167883211678
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 12.64130325618997
Iteration is: 2, Cost is: 12.638024974768129
TP: 453 FP: 175 TN: 6 FN: 6
F1 score : 0.8334866605335788
TP: 108 FP: 50 TN: 1 FN: 1
F1 score : 0.8089887640449439
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
Fold 3
Iteration is: 1, Cost is: 12.791608201583067
Iteration is: 2, Cost is: 12.894653552429329
TP: 457 FP: 183 TN: 0 FN: 0
F1 score : 0.8331814038286236
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 13.078285759129889
Iteration is: 2, Cost is: 13.280052356735688
Iteration is: 4, Cost is: 13.102172658796416
Iteration is: 8, Cost is: 13.103408139044012
TP: 441 FP: 165 TN: 25 FN: 9
F1 score : 0.8352272727272727
TP: 114 FP: 41 TN: 1 FN: 4
F1 score : 0.8351648351648351
TP: 145 FP: 48 TN: 5 FN: 2
F1 score : 0.8529411764705882
Fold 5
Iteration is: 1, Cost is: 13.048059941596824
Iteration is: 2, Cost is: 12.873102927546652
Iteration is: 4, Cost is: 12.904301392205944
TP: 435 FP: 181 TN: 10 FN: 14
F1 score : 0.8169014084507044
TP: 119 FP: 40 TN: 1 FN: 0
F1 score : 0.856115107913669
TP: 141 FP: 49 TN: 4 FN: 6
F1 score : 0.8367952522255193
Fold 1
Iteration is: 1, Cost is: 82.81422798787429
Iteration is: 2, Cost is: 88.67512974797495
Iteration is: 4, Cost is: 83.95301665298172
Iteration is: 8, Cost is: 74.49882931530166
Iteration is: 16, Cost is: 84.12731601221937
Iteration is: 32, Cost is: 87.7387104418643
Iteration is: 64, Cost is: 89.94075084999066
Iteration is: 128, Cost is: 78.406435072607
Iteration is: 256, Cost is: 86.38043700351292
Iteration is: 512, Cost is: 85.58979169195712
TP: 411 FP: 158 TN: 25 FN: 46
F1 score : 0.8011695906432749
TP: 98 FP: 39 TN: 10 FN: 13
F1 score : 0.7903225806451613
TP: 130 FP: 45 TN: 8 FN: 17
F1 score : 0.8074534161490682
Fold 2
Iteration is: 1, Cost is: 80.95967564496482
Iteration is: 2, Cost is: 81.60835554723838
TP: 409 FP: 154 TN: 27 FN: 50
F1 score : 0.8003913894324853
TP: 94 FP: 45 TN: 6 FN: 15
F1 score : 0.7580645161290324
TP: 129 FP: 46 TN: 7 FN: 18
F1 score : 0.8012422360248447
Fold 3
Iteration is: 1, Cost is: 83.92580277291862
Iteration is: 2, Cost is: 85.3378805919252
Iteration is: 4, Cost is: 84.92321543130552
TP: 418 FP: 158 TN: 25 FN: 39
F1 score : 0.8092933204259438
TP: 97 FP: 45 TN: 4 FN: 14
F1 score : 0.766798418972332
TP: 119 FP: 46 TN: 7 FN: 28
F1 score : 0.7628205128205128
Fold 4
Iteration is: 1, Cost is: 86.1386660855964
Iteration is: 2, Cost is: 82.63568769510239
Iteration is: 4, Cost is: 81.88574633983374
TP: 411 FP: 172 TN: 18 FN: 39
F1 score : 0.7957405614714425
TP: 109 FP: 38 TN: 4 FN: 9
F1 score : 0.8226415094339624
TP: 132 FP: 45 TN: 8 FN: 15
F1 score : 0.8148148148148148
Fold 5
Iteration is: 1, Cost is: 77.24605746331557
Iteration is: 2, Cost is: 77.57055906927084
TP: 386 FP: 120 TN: 71 FN: 63
F1 score : 0.8083769633507855
TP: 101 FP: 35 TN: 6 FN: 18
F1 score : 0.792156862745098
TP: 121 FP: 42 TN: 11 FN: 26
F1 score : 0.7806451612903227
Fold 1
Iteration is: 1, Cost is: 269.9978228055811
Iteration is: 2, Cost is: 239.6910303894844
Iteration is: 4, Cost is: 258.7912914455073
Iteration is: 8, Cost is: 281.9595557910658
Iteration is: 16, Cost is: 314.8363981234287
Iteration is: 32, Cost is: 265.530010352757
Iteration is: 64, Cost is: 257.2652017964516
Iteration is: 128, Cost is: 271.05429729053634
Iteration is: 256, Cost is: 258.4102109721217
Iteration is: 512, Cost is: 241.0245402830035
Iteration is: 1024, Cost is: 276.0599033477617
Iteration is: 1499, Cost is: 274.8292930510477
TP: 383 FP: 138 TN: 45 FN: 74
F1 score : 0.7832310838445807
TP: 94 FP: 32 TN: 17 FN: 17
F1 score : 0.7932489451476793
TP: 126 FP: 35 TN: 18 FN: 21
F1 score : 0.8181818181818182
Fold 2
Iteration is: 1, Cost is: 225.9877350161613
Iteration is: 2, Cost is: 242.94557318998145
Iteration is: 4, Cost is: 236.049138010765
Iteration is: 8, Cost is: 229.83965991093834
Iteration is: 16, Cost is: 219.22765469501584
Iteration is: 32, Cost is: 251.28853100416978
Iteration is: 64, Cost is: 256.2335044768262
Iteration is: 128, Cost is: 217.55896382089662
Iteration is: 256, Cost is: 245.47841894854756
Iteration is: 512, Cost is: 287.74695231835136
Iteration is: 1024, Cost is: 234.6687538521668
Iteration is: 1499, Cost is: 281.7529355814992
TP: 375 FP: 142 TN: 39 FN: 84
F1 score : 0.7684426229508196
TP: 91 FP: 44 TN: 7 FN: 18
F1 score : 0.7459016393442622
TP: 112 FP: 43 TN: 10 FN: 35
F1 score : 0.7417218543046356
Fold 3
Iteration is: 1, Cost is: 255.64394525892277
Iteration is: 2, Cost is: 274.78597669963415
Iteration is: 4, Cost is: 281.6018550427273
Iteration is: 8, Cost is: 247.37571930878877
Iteration is: 16, Cost is: 280.93111711019014
Iteration is: 32, Cost is: 249.84997152923071
Iteration is: 64, Cost is: 237.2484607149725
Iteration is: 128, Cost is: 274.01341132195665
Iteration is: 256, Cost is: 237.365785707222
Iteration is: 512, Cost is: 290.3894107585353
Iteration is: 1024, Cost is: 239.84229399029567
Iteration is: 1499, Cost is: 257.88288112884595
TP: 404 FP: 151 TN: 32 FN: 53
F1 score : 0.7984189723320156
TP: 99 FP: 45 TN: 4 FN: 12
F1 score : 0.7764705882352941
TP: 131 FP: 46 TN: 7 FN: 16
F1 score : 0.808641975308642
Fold 4
Iteration is: 1, Cost is: 269.2371712506178
Iteration is: 2, Cost is: 289.8310869981322
Iteration is: 4, Cost is: 243.83052545917053
Iteration is: 8, Cost is: 245.8644158723884
TP: 390 FP: 131 TN: 59 FN: 60
F1 score : 0.8032955715756952
TP: 102 FP: 29 TN: 13 FN: 16
F1 score : 0.8192771084337348
TP: 132 FP: 35 TN: 18 FN: 15
F1 score : 0.8407643312101911
Fold 5
Iteration is: 1, Cost is: 283.17823706914953
Iteration is: 2, Cost is: 308.3954185558625
Iteration is: 4, Cost is: 266.1371316403143
Iteration is: 8, Cost is: 279.27835460519685
Iteration is: 16, Cost is: 281.6384687426099
TP: 331 FP: 97 TN: 94 FN: 118
F1 score : 0.7548460661345495
TP: 82 FP: 26 TN: 15 FN: 37
F1 score : 0.722466960352423
TP: 101 FP: 28 TN: 25 FN: 46
F1 score : 0.7318840579710144
Fold 1
Iteration is: 1, Cost is: 691.2315162950198
Iteration is: 2, Cost is: 877.3230685273242
Iteration is: 4, Cost is: 655.8803384525195
Iteration is: 8, Cost is: 781.9313137985632
Iteration is: 16, Cost is: 726.8138589250983
Iteration is: 32, Cost is: 725.370008966883
TP: 365 FP: 152 TN: 31 FN: 92
F1 score : 0.7494866529774128
TP: 85 FP: 37 TN: 12 FN: 26
F1 score : 0.7296137339055793
TP: 111 FP: 43 TN: 10 FN: 36
F1 score : 0.7375415282392026
Fold 2
Iteration is: 1, Cost is: 633.6808477899251
Iteration is: 2, Cost is: 621.2113203042647
Iteration is: 4, Cost is: 773.8595490240468
Iteration is: 8, Cost is: 656.3240710516151
Iteration is: 16, Cost is: 658.1380052314884
TP: 393 FP: 144 TN: 37 FN: 66
F1 score : 0.789156626506024
TP: 95 FP: 44 TN: 7 FN: 14
F1 score : 0.7661290322580644
TP: 129 FP: 45 TN: 8 FN: 18
F1 score : 0.8037383177570093
Fold 3
Iteration is: 1, Cost is: 751.6047681058336
Iteration is: 2, Cost is: 635.3411783445443
Iteration is: 4, Cost is: 674.4846871196459
Iteration is: 8, Cost is: 724.2614654288755
Iteration is: 16, Cost is: 781.0879011596836
Iteration is: 32, Cost is: 798.7612131993579
Iteration is: 64, Cost is: 644.2452850237859
Iteration is: 128, Cost is: 609.3713776249999
Iteration is: 256, Cost is: 716.2184961636466
Iteration is: 512, Cost is: 723.7494887708119
Iteration is: 1024, Cost is: 726.2699470633382
TP: 408 FP: 141 TN: 42 FN: 49
F1 score : 0.8111332007952287
TP: 99 FP: 35 TN: 14 FN: 12
F1 score : 0.8081632653061224
TP: 119 FP: 44 TN: 9 FN: 28
F1 score : 0.7677419354838709
Fold 4
Iteration is: 1, Cost is: 672.2611520266117
Iteration is: 2, Cost is: 662.6683300501554
Iteration is: 4, Cost is: 772.3098864740322
Iteration is: 8, Cost is: 735.2292731011922
Iteration is: 16, Cost is: 693.027633697711
Iteration is: 32, Cost is: 747.6949460120186
Iteration is: 64, Cost is: 720.9015039991814
Iteration is: 128, Cost is: 779.9990856165226
Iteration is: 256, Cost is: 737.2069457585326
Iteration is: 512, Cost is: 690.1430877503736
Iteration is: 1024, Cost is: 713.1564796513275
Iteration is: 1499, Cost is: 789.0951408563501
TP: 382 FP: 149 TN: 41 FN: 68
F1 score : 0.7787971457696228
TP: 96 FP: 34 TN: 8 FN: 22
F1 score : 0.7741935483870969
TP: 122 FP: 43 TN: 10 FN: 25
F1 score : 0.7820512820512822
Fold 5
Iteration is: 1, Cost is: 656.5257031819741
Iteration is: 2, Cost is: 878.6135110875099
Iteration is: 4, Cost is: 776.1349228106349
Iteration is: 8, Cost is: 863.2769557650888
Iteration is: 16, Cost is: 745.1775106214596
Iteration is: 32, Cost is: 724.5354007096789
Iteration is: 64, Cost is: 805.4326808356099
Iteration is: 128, Cost is: 711.5185373909161
Iteration is: 256, Cost is: 874.1322261572349
Iteration is: 512, Cost is: 768.0000372018322
Iteration is: 1024, Cost is: 713.5626792053154
Iteration is: 1499, Cost is: 599.6906725107956
TP: 344 FP: 87 TN: 104 FN: 105
F1 score : 0.7818181818181819
TP: 87 FP: 27 TN: 14 FN: 32
F1 score : 0.7467811158798283
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 1
Iteration is: 1, Cost is: 2553.009727559107
Iteration is: 2, Cost is: 2280.024127972321
Iteration is: 4, Cost is: 1934.7659351125255
Iteration is: 8, Cost is: 2068.77098491789
Iteration is: 16, Cost is: 2233.554779614683
Iteration is: 32, Cost is: 2215.0517546747847
TP: 417 FP: 152 TN: 31 FN: 40
F1 score : 0.8128654970760234
TP: 97 FP: 42 TN: 7 FN: 14
F1 score : 0.7759999999999999
TP: 124 FP: 48 TN: 5 FN: 23
F1 score : 0.7774294670846394
Fold 2
Iteration is: 1, Cost is: 2498.5054849959283
Iteration is: 2, Cost is: 2215.763544990383
Iteration is: 4, Cost is: 2017.1573571553097
Iteration is: 8, Cost is: 1871.9761022759815
Iteration is: 16, Cost is: 1767.4875358029333
Iteration is: 32, Cost is: 2039.0131828644126
Iteration is: 64, Cost is: 2272.5467833319813
Iteration is: 128, Cost is: 2212.003338916518
Iteration is: 256, Cost is: 1769.2726035619946
Iteration is: 512, Cost is: 2242.3146062569313
Iteration is: 1024, Cost is: 2063.1232972284156
Iteration is: 1499, Cost is: 2067.024148833206
TP: 385 FP: 136 TN: 45 FN: 74
F1 score : 0.7857142857142857
TP: 93 FP: 45 TN: 6 FN: 16
F1 score : 0.7530364372469636
TP: 125 FP: 45 TN: 8 FN: 22
F1 score : 0.7886435331230285
Fold 3
Iteration is: 1, Cost is: 2017.908529299256
Iteration is: 2, Cost is: 2421.0025628382086
Iteration is: 4, Cost is: 2346.1113619587054
Iteration is: 8, Cost is: 2257.829448455474
Iteration is: 16, Cost is: 2524.4777494440227
Iteration is: 32, Cost is: 2563.484570475414
Iteration is: 64, Cost is: 2691.02853844241
Iteration is: 128, Cost is: 2242.3703367661647
Iteration is: 256, Cost is: 2666.4980581361647
Iteration is: 512, Cost is: 2400.309861185328
Iteration is: 1024, Cost is: 2588.358431825329
Iteration is: 1499, Cost is: 2211.6320192236735
TP: 411 FP: 153 TN: 30 FN: 46
F1 score : 0.8050930460333006
TP: 99 FP: 44 TN: 5 FN: 12
F1 score : 0.7795275590551181
TP: 126 FP: 44 TN: 9 FN: 21
F1 score : 0.7949526813880126
Fold 4
Iteration is: 1, Cost is: 2686.6927796007376
Iteration is: 2, Cost is: 2115.7807539015917
Iteration is: 4, Cost is: 2252.8143726269514
Iteration is: 8, Cost is: 2632.867278877759
Iteration is: 16, Cost is: 2300.1255489242008
Iteration is: 32, Cost is: 2542.818155606818
Iteration is: 64, Cost is: 2020.0558954114756
Iteration is: 128, Cost is: 2018.340645496087
TP: 404 FP: 133 TN: 57 FN: 46
F1 score : 0.8186423505572442
TP: 102 FP: 30 TN: 12 FN: 16
F1 score : 0.8159999999999998
TP: 132 FP: 36 TN: 17 FN: 15
F1 score : 0.838095238095238
Fold 5
Iteration is: 1, Cost is: 1983.9809906442765
Iteration is: 2, Cost is: 2367.6313881666033
Iteration is: 4, Cost is: 2096.8520826770214
Iteration is: 8, Cost is: 2137.687828417837
Iteration is: 16, Cost is: 2000.7267913029268
Iteration is: 32, Cost is: 2784.1667996694287
Iteration is: 64, Cost is: 1827.908323476432
Iteration is: 128, Cost is: 2501.511409294135
Iteration is: 256, Cost is: 2116.9169206944284
Iteration is: 512, Cost is: 2658.394783248831
Iteration is: 1024, Cost is: 2233.8421304086614
Iteration is: 1499, Cost is: 2058.825253210038
TP: 358 FP: 97 TN: 94 FN: 91
F1 score : 0.7920353982300885
TP: 95 FP: 28 TN: 13 FN: 24
F1 score : 0.7851239669421488
TP: 117 FP: 32 TN: 21 FN: 30
F1 score : 0.7905405405405406
Fold 1
Iteration is: 1, Cost is: 15422169.128647383
Iteration is: 2, Cost is: 16800634.919206195
Iteration is: 4, Cost is: 12954024.326022599
Iteration is: 8, Cost is: 16810832.573686317
Iteration is: 16, Cost is: 16051159.439241419
Iteration is: 32, Cost is: 20127786.874345712
Iteration is: 64, Cost is: 17574481.86175468
Iteration is: 128, Cost is: 15725238.019061832
Iteration is: 256, Cost is: 13322710.879871977
Iteration is: 512, Cost is: 13903267.424580252
Iteration is: 1024, Cost is: 17720984.697507992
Iteration is: 1499, Cost is: 18771953.462655347
TP: 442 FP: 167 TN: 16 FN: 15
F1 score : 0.8292682926829268
TP: 104 FP: 46 TN: 3 FN: 7
F1 score : 0.7969348659003831
TP: 144 FP: 53 TN: 0 FN: 3
F1 score : 0.8372093023255813
Fold 2
Iteration is: 1, Cost is: 18288195.437337935
Iteration is: 2, Cost is: 18082090.33241174
Iteration is: 4, Cost is: 18490398.464533903
Iteration is: 8, Cost is: 16974006.079256535
Iteration is: 16, Cost is: 18724549.12158524
Iteration is: 32, Cost is: 14811728.810391815
Iteration is: 64, Cost is: 14576633.548855636
Iteration is: 128, Cost is: 14695073.05969642
TP: 404 FP: 131 TN: 50 FN: 55
F1 score : 0.8128772635814888
TP: 99 FP: 39 TN: 12 FN: 10
F1 score : 0.8016194331983806
TP: 128 FP: 43 TN: 10 FN: 19
F1 score : 0.8050314465408803
Fold 3
Iteration is: 1, Cost is: 17735195.33532429
Iteration is: 2, Cost is: 14138578.109576283
Iteration is: 4, Cost is: 16013635.36933447
Iteration is: 8, Cost is: 12211479.751201717
Iteration is: 16, Cost is: 11690645.87958629
Iteration is: 32, Cost is: 18754391.734289672
Iteration is: 64, Cost is: 18193583.30437314
Iteration is: 128, Cost is: 21488308.695974365
Iteration is: 256, Cost is: 14639098.851253577
Iteration is: 512, Cost is: 19674363.626478948
Iteration is: 1024, Cost is: 16158480.733584853
Iteration is: 1499, Cost is: 13595840.71177755
TP: 426 FP: 148 TN: 35 FN: 31
F1 score : 0.8263821532492726
TP: 105 FP: 42 TN: 7 FN: 6
F1 score : 0.813953488372093
TP: 139 FP: 44 TN: 9 FN: 8
F1 score : 0.8424242424242423
Fold 4
Iteration is: 1, Cost is: 21600511.14303569
Iteration is: 2, Cost is: 22080615.268562313
Iteration is: 4, Cost is: 18573857.415088315
Iteration is: 8, Cost is: 15947077.939419078
Iteration is: 16, Cost is: 16266639.016763596
Iteration is: 32, Cost is: 21346007.27827771
Iteration is: 64, Cost is: 19869582.53929716
Iteration is: 128, Cost is: 18048946.175443064
Iteration is: 256, Cost is: 16814579.01677265
Iteration is: 512, Cost is: 19738630.60797108
Iteration is: 1024, Cost is: 17419880.952770855
Iteration is: 1499, Cost is: 19458455.502625555
TP: 399 FP: 146 TN: 44 FN: 51
F1 score : 0.8020100502512562
TP: 96 FP: 33 TN: 9 FN: 22
F1 score : 0.7773279352226722
TP: 119 FP: 43 TN: 10 FN: 28
F1 score : 0.7702265372168285
Fold 5
Iteration is: 1, Cost is: 16882582.646760557
Iteration is: 2, Cost is: 14303055.535035662
Iteration is: 4, Cost is: 14980978.818313291
Iteration is: 8, Cost is: 16434028.703526746
Iteration is: 16, Cost is: 16022507.971803796
Iteration is: 32, Cost is: 16819700.346204508
Iteration is: 64, Cost is: 20664310.985168032
Iteration is: 128, Cost is: 20013002.278625432
Iteration is: 256, Cost is: 25524369.1321967
Iteration is: 512, Cost is: 17793553.409635942
Iteration is: 1024, Cost is: 14298039.638413249
Iteration is: 1499, Cost is: 13976254.767539771
TP: 346 FP: 104 TN: 87 FN: 103
F1 score : 0.7697441601779755
TP: 87 FP: 29 TN: 12 FN: 32
F1 score : 0.7404255319148935
TP: 109 FP: 32 TN: 21 FN: 38
F1 score : 0.7569444444444445
Fold 1
Iteration is: 1, Cost is: 18120568052942.27
Iteration is: 2, Cost is: 20606778170046.33
Iteration is: 4, Cost is: 12910049078029.73
Iteration is: 8, Cost is: 17065191489965.701
Iteration is: 16, Cost is: 22138515605949.91
Iteration is: 32, Cost is: 15180247835802.594
Iteration is: 64, Cost is: 15551956657704.799
Iteration is: 128, Cost is: 20990853694597.652
Iteration is: 256, Cost is: 14121507027841.6
Iteration is: 512, Cost is: 23372942610257.95
Iteration is: 1024, Cost is: 16852402658443.756
Iteration is: 1499, Cost is: 11976617163597.22
TP: 393 FP: 123 TN: 60 FN: 64
F1 score : 0.8078108941418294
TP: 98 FP: 31 TN: 18 FN: 13
F1 score : 0.8166666666666668
TP: 123 FP: 33 TN: 20 FN: 24
F1 score : 0.8118811881188118
Fold 2
Iteration is: 1, Cost is: 18247510336829.0
Iteration is: 2, Cost is: 18045406644480.305
Iteration is: 4, Cost is: 18459186389943.844
Iteration is: 8, Cost is: 17794461407788.51
Iteration is: 16, Cost is: 14023932898995.291
Iteration is: 32, Cost is: 16615206150662.447
Iteration is: 64, Cost is: 14720509431863.352
Iteration is: 128, Cost is: 14555932547444.545
Iteration is: 256, Cost is: 15154099318358.246
Iteration is: 512, Cost is: 17082488437268.59
Iteration is: 1024, Cost is: 15307874888429.117
Iteration is: 1499, Cost is: 12464703834966.057
TP: 424 FP: 159 TN: 22 FN: 35
F1 score : 0.8138195777351247
TP: 101 FP: 46 TN: 5 FN: 8
F1 score : 0.7890625
TP: 141 FP: 48 TN: 5 FN: 6
F1 score : 0.8392857142857143
Fold 3
Iteration is: 1, Cost is: 17682702502424.5
Iteration is: 2, Cost is: 18894598577022.895
Iteration is: 4, Cost is: 18504002832750.996
Iteration is: 8, Cost is: 20300655856228.188
Iteration is: 16, Cost is: 16323301751368.879
Iteration is: 32, Cost is: 16942245669526.262
Iteration is: 64, Cost is: 16538831845846.162
Iteration is: 128, Cost is: 15165582011997.414
Iteration is: 256, Cost is: 18385970914811.027
Iteration is: 512, Cost is: 20370158933817.11
Iteration is: 1024, Cost is: 17043896645434.113
Iteration is: 1499, Cost is: 16832587039388.424
TP: 384 FP: 130 TN: 53 FN: 73
F1 score : 0.7909371781668383
TP: 92 FP: 35 TN: 14 FN: 19
F1 score : 0.773109243697479
TP: 116 FP: 43 TN: 10 FN: 31
F1 score : 0.7581699346405228
Fold 4
Iteration is: 1, Cost is: 21521628115794.285
Iteration is: 2, Cost is: 17160042344470.74
Iteration is: 4, Cost is: 18104502674760.926
Iteration is: 8, Cost is: 16445606309484.633
Iteration is: 16, Cost is: 17114378794737.51
Iteration is: 32, Cost is: 20772991171557.684
Iteration is: 64, Cost is: 16365797288567.963
Iteration is: 128, Cost is: 20804926545243.5
Iteration is: 256, Cost is: 18002915471536.81
Iteration is: 512, Cost is: 15057239950526.352
Iteration is: 1024, Cost is: 20102128378523.137
Iteration is: 1499, Cost is: 16711824510217.59
TP: 390 FP: 138 TN: 52 FN: 60
F1 score : 0.7975460122699386
TP: 96 FP: 32 TN: 10 FN: 22
F1 score : 0.7804878048780488
TP: 123 FP: 38 TN: 15 FN: 24
F1 score : 0.7987012987012988
Fold 5
Iteration is: 1, Cost is: 16889133081122.36
Iteration is: 2, Cost is: 15309578691485.5
Iteration is: 4, Cost is: 15095560030437.145
Iteration is: 8, Cost is: 21835955817658.977
Iteration is: 16, Cost is: 16846948463064.168
Iteration is: 32, Cost is: 20331780473243.18
Iteration is: 64, Cost is: 13765176480601.008
Iteration is: 128, Cost is: 19910708184701.285
Iteration is: 256, Cost is: 18984733427485.207
Iteration is: 512, Cost is: 15706819007512.531
Iteration is: 1024, Cost is: 19769674062146.68
Iteration is: 1499, Cost is: 17774706702471.402
TP: 339 FP: 98 TN: 93 FN: 110
F1 score : 0.7652370203160271
TP: 86 FP: 26 TN: 15 FN: 33
F1 score : 0.7445887445887446
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reg_strs</span><span class="p">,</span><span class="n">scan_val</span><span class="p">,</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Validation set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;regularisation strength $\lambda$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reg_strs</span><span class="p">,</span><span class="n">scan_test</span><span class="p">,</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Unseen test dataset&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;regularisation strength $\lambda$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We clearly see from the quality of the predictions based on the F1 score that the model performs best with a small regularisation strength, 2 and 20 being the best on both training (validation folds) and unseen test datasets. This suggests that a linear hard margin SVM (with high regularisation strength) may not be the best way to build a model for this kind of high-dimensional dataset.</p>
<p>Before trying the soft-margin SVM, another method to tackle  is to find a suitable kernel that will project our data points into an extra dimension and attempt to define a hyperplane that separates them in that space. Importantly, this extra dimension is defined solely using the values of the original dimensions, so we must be careful about defining it so that it suits well our dataset and, importantly, future datasets. This is done by taking advantage of the data values in the lower conditions and 'express' some properties that differentiate the +1 and -1 predictions which in turn allows to define a good hyperplane that separates the data well.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="ii)-Radial-Basis-Function-kernel-SVM">ii) Radial Basis Function kernel SVM<a class="anchor-link" href="#ii)-Radial-Basis-Function-kernel-SVM">&#182;</a></h4>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now implement the hard margin non-linear kernel SVM with radial basis function (RBF) kernel and do a grid search to find the optimal hyperparameter. To keep the margin hard, we penalise the misclassifications (unreasonably)  harshly and keep the regularisation parameter very high, $\lambda = 10^5$. The kernel allows to compute an extra dimension of the data, thus adding an extra dimension to the hyperplane that will separate it. The choice of the kernel is crucial here, especially with high-dimensional datta as it needs to take advantage of the existing coordinates to make their properties more 'expressed'. If the Gaussian kernel is suitable, we should expect a better performance than the linear SVM, but this is not necessarily the case if the data is not clustered nicely even with the extra dimension.</p>
<p>There are some crucial changes in the computation of the predictions. We first replace the dot product operations with the kernel function. Also, we do not have the weights as in the linear case because we are defining the hyper-plane in higher dimensions by using the kernel. This means that the weights in the kernelised SVM are not as directly related to the input space.</p>
<p>We will use the coefficients $\alpha$ to compute the predictions. We will also need compute the hyperplane bias $b$ explicitly and not 'on the fly' as the last entry of W, as we did it for the linear case. This is becausee it is not involved in the kernel multiplication.</p>
<p>Moreover, using the kernel trick makes thee optimisation problem dual - therefore we need more advanced optimisation such as quadratic programming or linear programming with inequalities to solve this problem. This is because when we switch to the kernelised SVM, we optimise over the space of the number of data points (rows), while in the linear SVM we only need to optimise over the (much smaller) space of the number of features (columns).</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now compute the radial basis kernel with the hyperparameter $\sigma$ (default is 0.5) that we will need to optimise using the five-fold cross-validation. Note that we need to optimise to avoid overfitting which happens for small values of $\sigma$. (Source: "Kernels", MIT 15.097 Course Notes by Cynthia Rudin, URL: <a href="https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec13.pdf">https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec13.pdf</a>)</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[224]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">rbf_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Compare the dot product and the kernel function - notice that the kernel never goes above 1. This suggests that in the prediction, we need to explicitly add the intercept b and not include it in the kernel calculations which we sum up over the number of the support vectors that define the hyperplane. Naively substituting the dot product by the kernel in the prediction function would give us all predictions as 1, beecause the sign of any value of the exponent function (which is how we define the kernel) is positive.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[225]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rbf_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>-58
0.02815585368030008
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[247]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define function to calculate hinge loss</span>
<span class="k">def</span> <span class="nf">compute_cost_kernel</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">sigma</span><span class="p">))</span>  
<span class="c1">#     distances = 1 - y * (rbf_kernel(X[:,:-1], W[:-1], sigma))  # if we do the intercept b separation</span>
    <span class="n">distances</span><span class="p">[</span><span class="n">distances</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># equivalent to max(0, distance)</span>
    <span class="n">hinge</span> <span class="o">=</span> <span class="n">regul_strength</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="c1"># calculate the hinge loss function</span>
    <span class="c1"># calculate cost</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">hinge</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Below is an attempt to implement the algorithm with the derivative of the kernel because we need to separate the intercept b which is not in the higher dimensional space - the goal is to optimise the weights that define the hyperplane and the intercept b separately. However it takes up a lot of computational power, so it could not be used for scanning over the parameters sigma. For the parameters of sigma that were tried out, it gives out all predictions of 1's.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[248]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate gradient of cost</span>
<span class="k">def</span> <span class="nf">derivative_kernel</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">x_i</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span><span class="o">*</span> <span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">W</span><span class="o">-</span><span class="n">x_i</span><span class="p">))</span>
    

<span class="k">def</span> <span class="nf">calculate_cost_gradient_kernel_costly</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="c1"># if only one example is passed</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">y_batch</span><span class="p">])</span>
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">X_batch</span><span class="p">])</span>  <span class="c1"># gives multidimensional array</span>
    <span class="n">distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">*</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X_batch</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sigma</span><span class="p">))</span> 
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">db</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distance</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">dw</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">db</span> <span class="o">-=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dw</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">regul_strength</span> <span class="o">*</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">*</span> <span class="n">derivative_kernel</span><span class="p">(</span><span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sigma</span><span class="p">))</span>
            <span class="n">db</span> <span class="o">-=</span> <span class="n">regul_strength</span> <span class="o">*</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>  <span class="c1"># update the gradient of b to optimise b implicitly</span>

    <span class="n">dw</span> <span class="o">=</span> <span class="n">dw</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>  <span class="c1"># average it</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">db</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Instead, we perform the optimisation using this gradient descent function.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[249]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate gradient of cost</span>
<span class="k">def</span> <span class="nf">calculate_cost_gradient_kernel</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="c1"># if only one example is passed</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">y_batch</span><span class="p">])</span>
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">X_batch</span><span class="p">])</span>  <span class="c1"># gives multidimensional array</span>
  
    <span class="n">distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">*</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">sigma</span><span class="p">))</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distance</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="p">(</span><span class="n">regul_strength</span> <span class="o">*</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
        <span class="n">dw</span> <span class="o">+=</span> <span class="n">di</span>

    <span class="n">dw</span> <span class="o">=</span> <span class="n">dw</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>  <span class="c1"># average</span>
    <span class="k">return</span> <span class="n">dw</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[299]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sgd_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="c1"># write the initial conditions for the weights</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">nth</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="c1"># initialise starting cost as infinity</span>
  <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
  
  <span class="c1"># stochastic gradient descent</span>
  <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">):</span>
      <span class="c1"># shuffle to prevent repeating update cycles</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
          <span class="n">ascent</span> <span class="o">=</span> <span class="n">calculate_cost_gradient_kernel</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">)</span>
          <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">ascent</span><span class="p">)</span> <span class="c1"># use the gradients of w in ascent for hyperplane optimisation  </span>
               
            
<span class="c1">#           if using the separation of weights and intercept b to optimise it implicitly, using the gradient of b for intercept optimisation</span>
<span class="c1">#           ascent_w, db = calculate_cost_gradient_kernel_costly(weights, x, y[ind], sigma, regul_strength)</span>
<span class="c1">#           weights[:-1] = weights[:-1] - (learning_rate * ascent_w)  # use the gradients of w for hyperplane optimisation</span>
<span class="c1">#           weights[-1] = weights[-1] - (learning_rate * db)  # use the gradient of b for intercept optimisation</span>


      <span class="c1"># convergence check on 2^n&#39;th iteration</span>
      <span class="k">if</span> <span class="n">iteration</span><span class="o">==</span><span class="mi">2</span><span class="o">**</span><span class="n">nth</span> <span class="ow">or</span> <span class="n">iteration</span><span class="o">==</span><span class="n">max_iterations</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
          <span class="c1"># compute cost</span>
          <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost_kernel</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">)</span> 
          <span class="k">if</span> <span class="n">print_outcome</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration is: </span><span class="si">{}</span><span class="s2">, Cost is: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>
          <span class="c1"># stop criterion</span>
          <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">prev_cost</span> <span class="o">-</span> <span class="n">cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">stop_criterion</span> <span class="o">*</span> <span class="n">prev_cost</span><span class="p">:</span>
              <span class="k">return</span> <span class="n">weights</span>
          
          <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">cost</span>
          <span class="n">nth</span> <span class="o">+=</span> <span class="mi">1</span>
  
  <span class="k">return</span> <span class="n">weights</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Define a function to get the prediction for the kernelised SVM.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[251]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span>  <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sigma</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="p">)</span>  <span class="c1"># W[-1] is the intercept b of the hyperplane</span>

<span class="c1">#         y_pred = np.sign(  rbf_kernel(X[i,:-1], W[:-1], sigma) + W[-1])</span>
<span class="c1">#         y_pred = np.sign(np.dot(X[i], W))</span>
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_preds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Run the model</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[252]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">sgd_kernel</span><span class="p">(</span><span class="n">X_111</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_111</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration is: 1, Cost is: 5654802.454523642
Iteration is: 2, Cost is: 22589208.020002853
Iteration is: 4, Cost is: 90326810.81820793
Iteration is: 8, Cost is: 361277200.9436157
Iteration is: 16, Cost is: 1445078800.8800552
Iteration is: 32, Cost is: 5780285202.248498
Iteration is: 64, Cost is: 23121110807.08226
Iteration is: 128, Cost is: 92484413201.097
Iteration is: 256, Cost is: 369937622806.99274
Iteration is: 512, Cost is: 1479750461202.565
Iteration is: 1024, Cost is: 5919001814804.162
Iteration is: 1499, Cost is: 12683871254804.97
Training finished.
[-2.07316477e-01  9.44366218e-02  7.72702409e-01 -2.52178157e-01
 -2.16750598e+00 -1.93875257e+00 -3.25547638e-01 -7.45141061e-01
 -3.83153742e-02 -3.35377594e-01  5.03664000e+06]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now get the prediction for the training data. What happens here is that out prediction is determined by the sign of the intercept b, while the kernel is equal to zero. This gives us all predictions of 1's. I suspect the optimisation in the gradient descent is faulty in the functions I defined.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[254]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for training data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_111</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_111</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_111</span>
<span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training data&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision :&#39;</span><span class="p">,</span><span class="n">precision</span><span class="p">)</span>  <span class="c1"># positive predictive value</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Recall :&#39;</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>  <span class="c1"># sensitivity</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.]
Training data
TP: 568 FP: 232 TN: 0 FN: 0
Precision : 0.71
Recall : 1.0
F1 score : 0.8304093567251462
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[260]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_222</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_222</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_222</span>
<span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Test data
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[261]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_222</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_222</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y_actual</span> <span class="o">=</span> <span class="n">y_2</span>
<span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Test data
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>From trying it with sigma=0.5, we see that the performance based on the F1 score is not better than the linear SVM.</p>
<p>Now perform the grid search and 5-fold CV.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[305]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
  <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>
  <span class="n">F1_scores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">F1_test</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">TPR_test</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">FPR_test</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
    <span class="c1">#print(&#39;Fold&#39;, i+1)</span>
    <span class="c1"># define the training set</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># define the validation set</span>
    <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># train the model</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">sgd_kernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e7</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># get y_pred</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
    <span class="c1"># get y_pred</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">predict_rgd_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
    
    
    <span class="c1"># evaluate with F1 score on the validation fold</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the test set</span>
    <span class="n">tp_test</span><span class="p">,</span> <span class="n">fp_test</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    
    <span class="n">F1_t</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">F1_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1_t</span><span class="p">)</span>
    
    <span class="n">TPR_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>
    <span class="n">fpr</span> <span class="o">=</span> <span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">fp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">fp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span><span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">FPR_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fpr</span><span class="p">)</span>
    

  <span class="k">return</span> <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span><span class="p">,</span> <span class="n">TPR_test</span><span class="p">,</span> <span class="n">FPR_test</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[302]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sigmas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sigmas</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[1.00000000e-04 7.89568421e-01 1.57903684e+00 2.36850526e+00
 3.15797368e+00 3.94744211e+00 4.73691053e+00 5.52637895e+00
 6.31584737e+00 7.10531579e+00 7.89478421e+00 8.68425263e+00
 9.47372105e+00 1.02631895e+01 1.10526579e+01 1.18421263e+01
 1.26315947e+01 1.34210632e+01 1.42105316e+01 1.50000000e+01]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[309]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">scan</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scan_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">TPR_test_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">FPR_test_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sigmas</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span><span class="p">,</span> <span class="n">TPR_test</span><span class="p">,</span> <span class="n">FPR_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">TPR_test_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TPR_test</span><span class="p">)</span>
    <span class="n">FPR_test_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">FPR_test</span><span class="p">)</span>
    <span class="n">scan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_scores</span><span class="p">))</span>
    <span class="n">scan_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">))</span>
    
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>sigma 0.0001 ...
sigma 0.7895684210526316 ...
sigma 1.5790368421052632 ...
sigma 2.368505263157895 ...
sigma 3.1579736842105266 ...
sigma 3.9474421052631583 ...
sigma 4.736910526315789 ...
sigma 5.526378947368421 ...
sigma 6.3158473684210525 ...
sigma 7.105315789473684 ...
sigma 7.894784210526316 ...
sigma 8.684252631578948 ...
sigma 9.473721052631578 ...
sigma 10.26318947368421 ...
sigma 11.052657894736843 ...
sigma 11.842126315789473 ...
sigma 12.631594736842105 ...
sigma 13.421063157894737 ...
sigma 14.210531578947368 ...
sigma 15.0 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[310]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sigmas</span><span class="p">,</span><span class="n">scan</span><span class="p">,</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sigmas</span><span class="p">,</span><span class="n">scan_test</span><span class="p">,</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Errors on training and test sets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\sigma$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We see that in each of the five folds, the predictions are always 1, thus even modifying the parameter of the kernel does not change it. In addition to the kernel being set to 0 and the intercept b being positive thus making the prediction 1, it is useful to think why we get the positive value of b in this case. It may be due to the predictions in training data being generally 1's, while the folds are smaller subsets of the training data, and the hard-margin SVMs does not separate well data that is non-linearly separable.</p>
<p>Since the scores do not change, there is not much use to compute the ROC curve as there is no rates of false positives against the true positives as they remain constant. It would be much more meaningful if we drew it having varying rates of false positives and true negatives, because in that case we could see how well out model is distinguishing between the classes, verying the hyperparameters. It would be most reasonable to choose the hyperparameters for which the true positive rate is largest and falsee positive rate is smallest - that is the point where the line of FP rate and TP rate is furthest from the random diagonal line which represents random sampling.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[314]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ident</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ident</span><span class="p">,</span><span class="n">ident</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">FPR_test_list</span><span class="p">,</span><span class="n">TPR_test_list</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False positive rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True positive rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We can see that the point at 1,1 is not better than random sampling, and this is due to the fact that we get all predictions as 1's.</p>
<p>It may also be that the Gaussian kernel is not well suited for this dataset. It is may be non-separable even after implementing the Gaussian kernel trick as we have high-dimensional variables. However, additional checks and alternative implementations of optimisation would be helpful to explore the data and determine whether it is more suitable for the kernelised SVM.</p>
<p>Additionally, the issue may be the implementation of stochastic gradient descent, it would have been useful to implement the same calculations with Quadratic Programming packages for convex optimisation to use the alphas (Lagrange multipliers) directly to determine the support vectors that will contribute to the definition of the hyperplane. The support vectors will correspond to non-zero alpha terms, using the complimentary slackness condition. Below is a sketch of the implementation. (I started doing this before the instructors specified that we are not allowed to use optimisation packages)</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[315]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">():</span>
    <span class="c1"># perform QP (cvxopt package for example) with our constraint, get the alphas</span>
    <span class="c1"># get the support vectors y_sv </span>
    <span class="c1"># get the sub-kernel matrix K, where K[i,j] = rbf_kernel(X[i], X[j])            </span>
    <span class="c1"># get sv are the indices of the suppoort vectors</span>
    <span class="c1"># calculate the intercept b explicitly looping through the support vectors</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sv</span><span class="p">)):</span> <span class="c1"># number of support vectors sv</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="n">y_sv</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">sv</span><span class="p">]</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">y_sv</span><span class="p">)</span> <span class="c1"># calculate the intercept b explicitly </span>
                                                                <span class="c1"># using the non-zero Lagrange multipliers alpha</span>
                                                                <span class="c1"># and the sub-kernels for that support vector</span>
    <span class="k">return</span> <span class="n">sv</span><span class="p">,</span> <span class="n">b</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[316]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define a prediction function for kernel SVMs</span>
<span class="c1"># the prediction is the sign of the output of this function: kernel(x,w) + b</span>
<span class="k">def</span> <span class="nf">predict_kerSVM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">support_vectors</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">support_vectors</span><span class="p">)):</span>  <span class="c1"># no assumption that we have two support vectors here</span>
            <span class="nb">sum</span> <span class="o">=</span> <span class="nb">sum</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">support_vectors</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1">#np.sign(np.dot(X[i], W))</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="nb">sum</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># add the intercept b explicitly</span>
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_preds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Mastery-Component">Mastery Component<a class="anchor-link" href="#Mastery-Component">&#182;</a></h2>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Hard-vs-Soft-margin">Hard vs Soft margin<a class="anchor-link" href="#Hard-vs-Soft-margin">&#182;</a></h4><p>In our implementation, we retrieve the hard margin for high regularisation strengths, while for smaller ones we have a soft margin.</p>
<p>For a $\lambda$ that is too small, the model is not 'punished' for the errors enough, so expect the model to be too general and not fit well, and for a large $\lambda$, the importance of the error is inflated and we get good in-sample accuracy but we overfit the data. We have already seen in the exploration before the implementation of the hard-margin SVM that we do get higher accuracy in both the training and test sets with a small regularisation strength. We will now explore this in more detail, using the sigmoid kernel (multilayer perceptron) in the comparison of the hard and soft margin SVMs.</p>
<p>The sigmoid kernel is most commonly described in the literature as only being positive definite (a must condition for extra-dimensionality in this case) for some parameter values, and in general it is not seen as better than RBF
or linear kernels. (Source: "A Study on Sigmoid Kernels for SVM and the Training of non-PSD Kernels by SMO-type Methods", Hsuan-Tien Lin and Chih-Jen Lin, National Taiwan University, URL: <a href="http://home.caltech.edu/~htlin/publication/doc/tanh.pdf">http://home.caltech.edu/~htlin/publication/doc/tanh.pdf</a>)</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[318]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># parameters - slope (commonly 1/N, N is the dimension of data) and intercept c</span>
<span class="k">def</span> <span class="nf">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">c</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[325]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.6</span><span class="p">))</span>

<span class="n">check_slope</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">check_intercept</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ran</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">0.001</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ran</span><span class="p">:</span>
    <span class="n">check_slope</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="mf">0.6</span><span class="p">))</span>
    <span class="n">check_intercept</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="n">i</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ran</span><span class="p">,</span><span class="n">check_slope</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;slope&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ran</span><span class="p">,</span><span class="n">check_intercept</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;intercept c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;value of slope/c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>-3
0.5153592780074097
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA17klEQVR4nO3deXxU5dXA8d/JRoAEAiSEXaKyIyBEEEEFQQQ3cMetWG2pWqu21Wrr61q1brW+1laKSlFfFcUVFRUXEEVBwiIQ9p0QlhDIAtmT8/5xLzCEBJLMTGYmc76fz3zu9tx7z8BkztznPvd5RFUxxhgTviICHYAxxpjAskRgjDFhzhKBMcaEOUsExhgT5iwRGGNMmIsKdAB1kZiYqJ07dw50GMYYE1IWLVq0R1WTKq8PyUTQuXNn0tLSAh2GMcaEFBHZUtV6qxoyxpgwZ4nAGGPCnCUCY4wJcyF5j6AqpaWlZGRkUFRUFOhQGqTY2Fg6dOhAdHR0oEMxxvhYg0kEGRkZxMfH07lzZ0Qk0OE0KKpKdnY2GRkZpKSkBDocY4yP+aRqSESmiMhuEVlRzXYRkedFZL2ILBOR/h7bRovIGnfbvXWNoaioiFatWlkS8AMRoVWrVna1ZUwD5at7BFOB0cfYPgbo4r4mAi8CiEgk8C93e0/gahHpWdcgLAn4j/3bGtNw+aRqSFXnikjnYxQZC7ymTp/X80UkQUTaAp2B9aq6EUBEprllV/oiLmPMkVSVwtJyDhSXU1R68FVBUdnh+bLyCspVKa+o9FKlokIpc5crVFEFPXRsd+quqdzD/cEu7w+XO/Z+SqUC4UyVCC0jUku5sH8KKckJPj18fd0jaA9s81jOcNdVtX5QVQcQkYk4VxN06tTJP1H6wbBhw3jmmWdITU0NdCimgSsuK2fD7gNsyT7A9pxCtucUkplTyN4DJeQUlJJTWEpuQSkl5RWBDrXWgu+CVGlMMfEUEi8FxFNAPIU0lmIaU0xjSoiVYmIpPWK5MSU0pphYSoiVEmIoI5qyQ9NoqbR8cLuUHzrzz42nQPJlPn039ZUIqvpv1GOsP3ql6mRgMkBqaqr9RDBhTVXZureA+RuzWbBxL+mZeWzI2k9ZxeE/jSYxkbRLaExSXCNObh1HQpNomjeOIaFJNE0bRREbFUFsdKT7cuejIomKFCIj3Jd4zHusi3DnI9y/YHH/lCt/YUs12+XQdqm0fOT6elFWAgd2w4E9UJDtvA7sgYI9h9cV7oOiPCjOdaf5oOXHPzYAAtFNILrxka+oeIiKgciDr+hq5o9c17dH/+OfspbqKxFkAB09ljsAmUBMNetD0oEDB7jyyivJyMigvLyc+++//4jtb731Fo8//jiqygUXXMCTTz4JQFxcHL/5zW+YPXs2LVq0YNq0aSQlJbFhwwZ++9vfkpWVRZMmTXjppZfo3r17IN6aCRKrd+bx8c+ZfLpsB5uzCwBIjGtE3w7NGdmzNd3bNCMlsSkdWjSmeeNou7ejCvk7Ye9GyM2AvO2Ql+m+Mpzpgayq95VIaNIKmiZC45aQ0BEa9YRGzSC2WaVpc2gUDzFNj/zSj2oMUY2C8ZLmCPWVCGYAt7n3AAYBuaq6Q0SygC4ikgJsB8YD13h7soc/TmdlZp63hzlCz3bNePCiXscs8/nnn9OuXTs+/fRTAHJzc3nxxRcByMzM5J577mHRokW0aNGCUaNG8eGHHzJu3DgOHDhA//79+fvf/84jjzzCww8/zAsvvMDEiROZNGkSXbp0YcGCBdx666188803Pn1fJvhVVCizVu7ile83snDzPiIjhDNOasVNQ1MYfFIiJyU1tS/84nzYvQp2r3S+9PduhOyNsG8TlBYcWTY2AZq1h2btoG0/ZxqX7HzhN0l0p62cchHh8cytTxKBiLwFDAMSRSQDeBCIBlDVScBM4HxgPVAA/NLdViYitwFfAJHAFFVN90VMgXDKKadw1113cc8993DhhRdy5plnHtq2cOFChg0bRlKS0/Hftddey9y5cxk3bhwRERFcddVVAFx33XVceuml7N+/nx9++IErrrji0DGKi4vr9w2ZgPtxQzaPzVzJiu15dGjRmP+5oAeXnNqeVnGNAh1a4ORuh+1psHM57FoJu1ZAjkdfapEx0KIztDwRThwGLVOc+YQToFlb51e7OYKvWg1dfZztCvy2mm0zcRKFzxzvl7u/dO3alUWLFjFz5kz+/Oc/M2rUqEPbtBYtH0SEiooKEhISWLp0qR8iNcEur6iUh2es5L3FGbRPaMxzV/Xjwj5tiYoMj1+oh5QVw/bFkPETZCyEjDTI3+FskwhodTK07w/9r4fWvaB1D0joBBGRgY07xDSYJ4uDQWZmJi1btuS6664jLi6OqVOnHto2aNAg7rjjDvbs2UOLFi146623+N3vfgdARUUF7777LuPHj+fNN99k6NChNGvWjJSUFKZPn84VV1yBqrJs2TL69u0boHdn6suK7bn85vVF7Mgt5LbhJ3PbOScTGx0mX2wVFbBzGWz6FjbOgS0/Qlmhs61FCnQeCh1Og/apkNzTqYc3XrNE4EPLly/n7rvvJiIigujoaF588UXuuusuANq2bcvf/vY3hg8fjqpy/vnnM3bsWACaNm1Keno6AwYMoHnz5rz99tsAvPHGG9xyyy08+uijlJaWMn78eEsEDdys9J3cMW0pLZvG8O4tZ9C/U4tAh+R/JQWw4RtYMxPWfu600gFI6g4DJkDKWdBxkFN3b/xCalNlESxSU1O18sA0q1atokePHgGKyDtxcXHs378/0GEcVyj/G4eCj3/O5I5pSzilQwIv/WIAreNjAx2S/5QcgFWfwMoPYcNs51d/bHPoch6cPBJOPBvi2wQ6ygZHRBap6lEPNdkVgTFB4Iv0ndz59lJSO7dk6i9Po0lMA/zTrCiHTXPh52mw6mMoPQDNOkD/X0D38+GEIU5beVPvGuCnLfSEwtWA8Z/lGbnc/tYS+nRozpQbGmASOLAHFr8KC6c4bfcbNYdTLoO+V0PH08OmiWYwa2CfOGNCy579xfzm9TQS4xrx0i9SiWvUgP4kM5fAgv/AivegvARSzoZRf4VuY+wmb5BpQJ86Y0KLqvKnd5eRfaCE9245g8SG8mzA5nnw3TPODeCYOOg/AU77FbS2p+KDlSUCYwJkeloG36zezYMX9aR3++aBDsd7G7+FOU/A1h+gaRKMfAhSb3K6YTBBzRKBMQGwM7eIRz5ZyeATWzFhcOdAh+OdnSvgqwdh/VdO1w1jnoJTr4eYJoGOzNSQ3aXxoTPOOOO4ZZ577jkKCgqOW84fcnJy+Pe//x2Qc5sjPfX5akrKK3jysj5ERIRoP0H5O+HD38Kkoc5Tv6MehduXwKDfWBIIMZYIfOiHH344bpm6JILy8pp2d3tslgiCw+Kt+3h/yXZ+fWYKnVqF4BdmRTksmAwvnAbL34HBv4Xbl8IZv3N62jQhxxKBD8XFxQEwZ84chg0bxuWXX0737t259tprUVWef/55MjMzGT58OMOHDwdg1qxZDB48mP79+3PFFVccakrauXNnHnnkEYYOHcr06dP5/PPP6d+/P3379mXEiBGA0+31jTfeyGmnncapp57KRx99BMDUqVMZO3Yso0ePplu3bjz88MMA3HvvvWzYsIF+/fpx9913HxX/a6+9Rp8+fejbty/XX3+93/+9wpGq8tinq2gd34hbh50c6HBqL3MpvDwCPrvb6ePn1vlw3mPQpGWgIzNeaJj3CD671+mZ0JfanAJjnqhx8SVLlpCenk67du0YMmQI8+bN4/bbb+fZZ59l9uzZJCYmsmfPHh599FG++uormjZtypNPPsmzzz7LAw88AEBsbCzff/89WVlZ9O/fn7lz55KSksLevXsBeOyxxzjnnHOYMmUKOTk5DBw4kJEjRwLw008/sWLFCpo0acJpp53GBRdcwBNPPMGKFSuq7MguPT2dxx57jHnz5pGYmHjoHMa3ftiQzaIt+/jruN40DaWmouWlMPdpmPuM00XzZa9A78uCvp99UzMh9EkMLQMHDqRDhw4A9OvXj82bNzN06NAjysyfP5+VK1cyZMgQAEpKShg8ePCh7Qe7pp4/fz5nnXUWKSkpALRs6fz6mjVrFjNmzOCZZ54BoKioiK1btwJw7rnn0qpVKwAuvfRSvv/+e8aNG1dtvN988w2XX345iYmJR5zD+Nb/fr2ONs1iuTK1Q6BDqbmstfDBROe5gD7jYcyT0Dgh0FEZH2qYiaAWv9z9pVGjw3WlkZGRlJWVHVVGVTn33HN56623qjxG06ZND5WrauARVeW9996jW7duR6xfsGDBUeWPN3BJdecwvrNgYzY/bdrLQxf1pFFUCPQmqgqL/guf/9l5AOyKV6HXuEBHZfzA7hHUs/j4ePLz8wE4/fTTmTdvHuvXrwegoKCAtWvXHrXP4MGD+fbbb9m0aRPAoWqb8847j3/+85+HxjpYsmTJoX2+/PJL9u7dS2FhIR9++CFDhgw54tyVjRgxgnfeeYfs7OwjzmF857/zNtOiSTTjB3YKdCjHV1IAH94Cn/weTjjDuRdgSaDB8kkiEJHRIrJGRNaLyL1VbL9bRJa6rxUiUi4iLd1tm0Vkubst7eijNywTJ05kzJgxDB8+nKSkJKZOncrVV19Nnz59OP3001m9evVR+yQlJTF58mQuvfRS+vbte6jK6P7776e0tJQ+ffrQu3fvI8ZIHjp0KNdffz39+vXjsssuIzU1lVatWjFkyBB69+591M3iXr16cd9993H22WfTt29f/vCHP/j3HyLMbM8pZNbKnVx1WqfgH1sgewO8PNLpHG7YX+Da96wn0AbO626oRSQSWAucizNI/ULgalVdWU35i4Dfq+o57vJmIFVV99T0nA2tG2pfmzp1Kmlpabzwwgs+Pa79G9fdU5+vZtK3G5j7p+F0aBHETUY3zIZ3JjgdwV32stMltGkwquuG2hdXBAOB9aq6UVVLgGnA2GOUvxqoulLcmAaouKycaQu3MbJHcnAngUWvwhuXQ/P2MPFbSwJhxBeJoD2wzWM5w113FBFpAowG3vNYrcAsEVkkIhOrO4mITBSRNBFJy8rK8kHYDdcNN9zg86sBU3ezV2ex90AJVw8K0nsDFRXw5YPw8e1OD6E3fgEtTgh0VKYe+aLVUFVNTaqrb7oImKeqnncih6hqpoi0Br4UkdWqOveoA6pOBiaDUzVU1cGt5Yv/hOJIdsHigyUZJMY14syTg3CoxfIy+OhWWPY2pN4IY56GyIbZmNBUzxdXBBlAR4/lDkBmNWXHU6laSFUz3elu4AOcqqZai42NJTs7276w/EBVyc7OJja2AQ+d6Cc5BSV8s3o3Y/u1IyoyyBrplRXD9AlOEjjnfrjgWUsCYcoX/+sLgS4ikgJsx/myv6ZyIRFpDpwNXOexrikQoar57vwo4JG6BNGhQwcyMjKwaiP/iI2NPfSAnKm5j5ftoLRcueTUKmtLA6fkAEy7FjbOdq4CBlVbK2vCgNeJQFXLROQ24AsgEpiiqukicrO7fZJb9BJglqoe8Ng9GfjArc6JAt5U1c/rEkd0dPShJ2+NCRYfL82ka3IcvdoFUZ/8JQfg/y6HbfNh7L/h1GsDHZEJMJ9cB6rqTGBmpXWTKi1PBaZWWrcR6OuLGIwJNln5xSzcspfbz+kSPPeuSgvhrfFOErjsZae/IBP2gqzS0piG4+tVu1CF83oFycNYZSXwzi9g03cw7kVLAuYQuzNkjJ98kb6TDi0a06NtfKBDcVoHvXcjrJsFFz4HfccHOiITROyKwBg/yC8qZd76bM7r1Sbw1UKq8OkfYNXHMPoJSP1lYOMxQccSgTF+MGdNFiXlFcFRLfTdM7D4VTjzj3D6LYGOxgQhSwTG+MHsNbtJaBLNgBNaBDaQpW/BN49Cn6ucZwWMqYIlAmN8TFX5bt0ehp6cSGQgB6bfOAdm3AYpZ8HFL9hoYqZalgiM8bHVO/PJyi/mrK5JgQsie4PTQqhVF7jq/yAqJnCxmKBnicAYH/tunfN0+5ldAtS3UHE+TLsGJAKumQaxzQMThwkZ1nzUGB+bu3YPXZPjaNu8cf2fvKICPrgZ9qyD69+HFp3rPwYTcuyKwBgfKiwp56fNezmzS4CqheY+Bas/gfMegxOHBSYGE3IsERjjQz9t3ktJWUVgqoXWfQlz/gZ9r4FBN9f/+U3IskRgjA8t2JhNVIQwMKVl/Z44dzu8PxGSe8OFz1oLIVMrlgiM8aGfNu2ld/vmNImpx9tv5WXw3k3O+AJXTIXoANybMCHNEoExPlJUWs7PGTkMqu+rgTmPw9Yf4aLnILFL/Z7bNAiWCIzxkSVbcygt1/qtFlr/NXz3LJx6HfS5sv7OaxoUSwTG+MhPm/YiAqmd6ykRHMh2moomdXNGGTOmjnySCERktIisEZH1InJvFduHiUiuiCx1Xw/UdF9jQsVPm7Pp0aYZzRtH+/9kqvDJnVC4zxlgJqaJ/89pGiyv72iJSCTwL+BcnIHsF4rIDFVdWanod6p6YR33NSaolZRVsGjLPsaf1ql+Trh8OqyaASMehDan1M85TYPliyuCgcB6Vd2oqiXANGBsPexrTNBIz8ylqLSifu4P5GbAp3dBx0Ew5A7/n880eL5IBO2BbR7LGe66ygaLyM8i8pmI9KrlvojIRBFJE5G0rKwsH4RtjO8s2ZoD4P9upysq4MNboaIMLpkEEZH+PZ8JC75IBFU9uaKVlhcDJ6hqX+CfwIe12NdZqTpZVVNVNTUpKYC9OhpThaXbcmjbPJbkZrH+PVHaK7DpW6cLiZYn+vdcJmz4IhFkAB09ljsAmZ4FVDVPVfe78zOBaBFJrMm+xoSCpdty6Ncxwb8nydkGXz0EJ42AATf491wmrPgiESwEuohIiojEAOOBGZ4FRKSNuAO3ishA97zZNdnXmGCXvb+YrXsL/JsIDo47rOo8OGZdSBgf8rrVkKqWichtwBdAJDBFVdNF5GZ3+yTgcuAWESkDCoHxqqpAlft6G5Mx9ennjBwA+vozEax4D9bNcgafT6inlkkmbPikQxS3umdmpXWTPOZfAF6o6b7GhJKlW3OIEDilvZ8GgDmQDZ/9CdoPgIET/XMOE9bsyWJjvLRkWw5dk+Np2shPHc198RcoyoWL/2mthIxfWCIwxgsVFcrP23I4tVOCf06w/mtYNg2G/gGSex2/vDF1YInAGC9syj5AXlGZf24UlxXDzLug1clw5h99f3xjXDZmsTFe+HlbDgD9OvrhQbIfnoe9G+G69yHaz88nmLBmVwTGeGHF9jxioyM4uXWcbw+csxXm/h16XAwnj/DtsY2pxBKBMV5Iz8ylR9tmREb4uF3/5392nhU473HfHteYKlgiMKaOKiqUlZl59GrXzLcHXvcVrP4EzrobEjoev7wxXrJEYEwdbdtXQH5xGb3b+fD5gbJi+Oxu5wbx4Nt8d1xjjsFuFhtTR+mZeQD08mUi8LxBHBXju+Macwx2RWBMHa3YnktUhNC1jY9uFOftcMYf7nGR3SA29coSgTF1lJ6ZR5fkeBpF+ehp32/+6owzcO5ffXM8Y2rIEoExdaCqpGfm+u5GceZSWPomDLoZWqb45pjG1JAlAmPqYHd+MXv2l9DbF4lAFb64D5q0hLPu8v54xtSSJQJj6iA9MxeAXr7ocXT1p7Dlexj+F4j1Uw+mxhyDJQJj6iB9ex4i0KOtl1cEZSXw5f2Q1B363+CT2IypLZ8kAhEZLSJrRGS9iNxbxfZrRWSZ+/pBRPp6bNssIstFZKmIpPkiHmP8bUVmLimtmhLnbdfTC19ymouOegwirTW3CQyvP3kiEgn8CzgXZwzihSIyQ1VXehTbBJytqvtEZAwwGRjksX24qu7xNhZj6kt6Zp73PY4W7IVvn4STR0KXkT6Jy5i68MUVwUBgvapuVNUSYBow1rOAqv6gqvvcxfk4g9QbE5Lyi0rJ2FfofbXQ3KehOB9GPeqbwIypI18kgvbANo/lDHdddW4CPvNYVmCWiCwSkWrH4RORiSKSJiJpWVlZXgVsjDfW7soHoHub+LofJGcbLHwZ+l0LrXv4KDJj6sYXlZJVdbuoVRYUGY6TCIZ6rB6iqpki0hr4UkRWq+rcow6oOhmnSonU1NQqj29MfVi900kE3bxJBHOfcqZn3+ODiIzxji+uCDIAzy4SOwCZlQuJSB/gZWCsqmYfXK+qme50N/ABTlWTMUFrzc584hpF0T6hcd0OkL0BlrwBqTda76ImKPgiESwEuohIiojEAOOBGZ4FRKQT8D5wvaqu9VjfVETiD84Do4AVPojJGL9ZvTOfrslxiNRxDILZj0NUIxt+0gQNr6uGVLVMRG4DvgAigSmqmi4iN7vbJwEPAK2Af7t/PGWqmgokAx+466KAN1X1c29jMsZfVJU1O/M5/5S2dTvAzuWw4l0nCcS19m1wxtSRTxouq+pMYGaldZM85n8F/KqK/TYCfSuvNyZY7c4vJrewtO43ir95zHl6+Izf+TYwY7xgTxYbUwte3SjethDWfgZn3A6N/TDYvTF1ZInAmFpYs9MZjKZOVwTfPAJNk5weRo0JIpYIjKmF1TvzSW7WiIQmtRw9bOMc2DQXzrwLGvloIBtjfMQSgTG1sGZnPt3a1PKJYlX4+q/QrAOk/tI/gRnjBUsExtRQWXkF63bvp1tyLX/Rr/kMtqfBsHucZqPGBBlLBMbU0ObsAkrKKmp3RVBR4QxB2fIk6HuN/4IzxgvW760xNbRmZx36GFrxHuxeCZe9Yt1Mm6BlVwTG1NCanXlECJzcuoZVQ+WlMOdxSO4NvS71b3DGeMF+ohhTQ6t35tM5sSmx0ZE122HpG86gM1e/DRH2m8sEL/t0GlNDa3bl17xaqLQIvn0KOpwGXc/zb2DGeMkSgTE1UFBSxta9BXRLruGN4rQpkLcdRjwAde2czph6YonAmBpYu2s/qjXsWqI4H777O5w4DFLO8ntsxnjLEoExNVCrriXmT4KCPXDOA36OyhjfsERgTA2s3plPbHQEHVs2OXbBgr3ww/PQ7QLoMKB+gjPGS5YIjKmBNTvz6ZocT2TEcer7f3jeqRo65776CcwYH7BEYEwNrN2VT7fk41QL5e9yqoVOuQKSe9VPYMb4gE8SgYiMFpE1IrJeRO6tYruIyPPu9mUi0r+m+xoTaHv2F7Nnf8nxbxR/9wyUl8Aw+xib0OJ1IhCRSOBfwBigJ3C1iPSsVGwM0MV9TQRerMW+xgTU4a4ljtF0dN8WSPsv9L8eWp1UT5EZ4xu+uCIYCKxX1Y2qWgJMA8ZWKjMWeE0d84EEEWlbw32NCagajUr27VMgEXDWn+opKmN8xxeJoD2wzWM5w11XkzI12RcAEZkoImkikpaVleV10MbU1Nqd+bRqGkNSfDVdSGethZ/fhNN+Bc2r/PgaE9R8kQiqakahNSxTk32dlaqTVTVVVVOTkpJqGaIxdbd6l9NiqFqzH4PoJnDmH+ovKGN8yBeJIAPo6LHcAcisYZma7GtMwFRUKOt25VdfLbTjZ1j5IZx+KzRNrNfYjPEVXySChUAXEUkRkRhgPDCjUpkZwC/c1kOnA7mquqOG+xoTMBn7CikoKa8+EXzzKMQmwBm31WtcxviS191Qq2qZiNwGfAFEAlNUNV1Ebna3TwJmAucD64EC4JfH2tfbmIzxlTW7nBvFVVYNbfkR1s2CkQ9BbPP6DcwYH/LJeASqOhPny95z3SSPeQV+W9N9jQkWB/sY6lp5nGJVZwjKuGQYODEAkRnjO/ZksTHHsGbXftonNCY+NvrIDRu+gS3z4Ky7IaZpYIIzxkcsERhzDGt25h3d46gqfP0INO8E/ScEJjBjfMgSgTHVKCmrYGPWAbpWTgSrPoYdS52uJKJiAhKbMb5kicCYamzac4CyCj3yiqCi3HluILEr9LkqcMEZ40M2eL0x1Vh96EaxRyJY9g5krYYrpkKk/fmYhsGuCIypxtpd+URFCCcluS2GykpgzuPQti/0sC6xTMNhP2mMqcaanfmkJDYlJsr9vbRoKuRshQv/ARH2G8o0HPZpNqYaazy7lig5AHOfhhOGwkkjAhuYMT5micCYKuwvLmPb3sLDo5LNfxEO7IaRD4IcZ7hKY0KMJQJjqrBul8cYBAV7Yd7z0HUMdBwY4MiM8T1LBMZUYY3nYDTznoPiPBhxf2CDMsZPLBEYU4U1u/JpHB1Jx6hcWPAf6HOlDUhvGixLBMZUYe2ufLomxxHx3dNQUQbD/hzokIzxG0sExlRhzc58BrfIg8WvwYAboGVKoEMyxm/sOQJjKtmzv5g9+0u4PO91iIh2ehg1pgGzKwJjKlm9I5+espmTdn0Op98M8W0CHZIxfuVVIhCRliLypYisc6ctqijTUURmi8gqEUkXkTs8tj0kIttFZKn7Ot+beIzxhZWZOfw56k00NgGG3BnocIzxO2+vCO4FvlbVLsDX7nJlZcAfVbUHcDrwWxHp6bH9H6raz33ZSGUm4CrWfcWZkSuIGHYPNE4IdDjG+J23iWAs8Ko7/yowrnIBVd2hqovd+XxgFdDey/Ma4x8V5ZyX+W92RbWD1JsCHY0x9cLbRJCsqjvA+cIHWh+rsIh0Bk4FFnisvk1ElonIlKqqljz2nSgiaSKSlpWV5WXYxlStdNHrpFRsYcGJt9mgMyZsHDcRiMhXIrKiilet+uEVkTjgPeBOVc1zV78InAT0A3YAf69uf1WdrKqpqpqalJRUm1MbUzMlB2D2YyyuOJnIXpcEOhpj6s1xm4+q6sjqtonILhFpq6o7RKQtsLuactE4SeANVX3f49i7PMq8BHxSm+CN8akf/0V0wW4eK72FZ9o3D3Q0xtQbb6uGZgAHR++eAHxUuYCICPAKsEpVn620ra3H4iXACi/jMaZu8nfB98+xMmEYq6J7ckLLJoGOyJh6420ieAI4V0TWAee6y4hIOxE52AJoCHA9cE4VzUSfEpHlIrIMGA783st4jKmbOX+D8mImRV9P9zbxRERYV9MmfHj1ZLGqZgNHjdKhqpnA+e7890CVf1Wqer035zfGJ3alw+JX0dSbmL0wnov7Ngt0RMbUK3uy2IQ3VfjsHohtTuapvye/qIye7SwRmPBiicCEt1UzYPN3MPw+VuyLBKBnW0sEJrxYIjDhq7QQvvgfaN0LBvySVTvyEOHwOMXGhAnrfdSEr3nPQ+5WmPAJREaxYnseKYlNaRJjfxYmvNgVgQlPOdvg+39Az7GQciYAy7fn0LdDQmDjMiYALBGY8PTlA4DCqEcB2JVXxK68Yk6xB8lMGLJEYMLPpu8g/X0YcgckdAJgeUYuAH06WCIw4ccSgQkvZcXwye8h4YQjxhpYtj2XCMGajpqwZHfFTHiZ9zxkr4NrpkPM4W4klmfk0KV1vN0oNmHJrghM+MjeAHOfdm4Qdx11aLWqsnx7LqdYtZAJU5YITHhQhZl3QWQMjH7iiE07covYs7+EvpYITJiyRGDCQ/r7sOEbOOd/oFm7IzYtc28Un2JNR02YskRgGr7CHPj8z9C2Hwz89VGbl2/PISpC6G5PFJswZXfGTMP3xX1wYA9c8zZERB61eVlGLl2T44mNPnqbMeHArghMw7buK1j6f84zA+1OPWpzeYWyZGsO/U9IqP/YjAkSXiUCEWkpIl+KyDp3WuXg8yKy2R2AZqmIpNV2f2PqpCgPPr4dErvB2fdUWWTtrnz2F5cx4AT76Jnw5e0Vwb3A16raBfjaXa7OcFXtp6qpddzfmNr58n7I3wHj/g3RsVUWWbRlHwADOrWsz8iMCSreJoKxwKvu/KvAuHre35iqbZgNi6bC4NugQ2q1xRZv2UdiXCM6tmxcf7EZE2S8TQTJqroDwJ22rqacArNEZJGITKzD/ojIRBFJE5G0rKwsL8M2DVphDsz4HbTqAsP/csyii7buI/WEFojYGMUmfB231ZCIfAW0qWLTfbU4zxBVzRSR1sCXIrJaVefWYn9UdTIwGSA1NVVrs68JMzPvgrxMuGkWRFf/Sz8rv5gt2QVcN+iEegzOmOBz3ESgqiOr2yYiu0SkraruEJG2wO5qjpHpTneLyAfAQGAuUKP9jamxZe/A8unOg2PHqBICWLzVuT/Q324UmzDnbdXQDGCCOz8B+KhyARFpKiLxB+eBUcCKmu5vTI3t2wyf/hE6DYahfzhu8cVb9hETGUHv9tbjqAlv3iaCJ4BzRWQdcK67jIi0E5GZbplk4HsR+Rn4CfhUVT8/1v7G1Fp5Gbz/G2f+0slVPjhW2fxNe+nToTmNouxBMhPevHqyWFWzgRFVrM8EznfnNwJ9a7O/MbX27ZOwbT5c+vKhwWaOJb+olBXbc7l12En1EJwxwc2eLDahb92XMPcp6Hcd9LmiRrss3LyX8gpl8Imt/BycMcHPEoEJbTlb4f1fQ3JvuOCZGu/244ZsYqIi7EaxMVgiMKGsrBim3wAV5XDla8dsKlrZjxuz6d8pwTqaMwZLBCaUffEX2L4Ixv4LWtW8rj+noIT0zDwGn5jox+CMCR2WCExoSpsCC1+GM34HPS+u1a4LNu1FFQafZPcHjAFLBCYUbZoLM++Gk8+FkQ/Xevfv1mXRJCaSvh1taEpjwBKBCTXZG+CdX0DLk+DyV2r0vIAnVWX26iyGnJxozw8Y47JEYEJHYQ68dbUzf800iK39L/r1u/ezPaeQ4d2q7d/QmLBjQ1Wa0FBaBNOugb0b4foPoOWJdTrM7DVOd1bDuiX5MjpjQpolAhP8Ksrh/V/Blnlw2SuQcmadDzV7dRbd28TTLsHGHzDmIKsaMsFN1elWetXHMPoJOOXyOh8qv6iUhZv3MsyqhYw5giUCE9xmP+40FR1yJ5x+i3eHWpNFWYUyooclAmM8WSIwwWvOE04fQqdeByMf8vpwM5ftoHV8IwZ0sm4ljPFkicAEp2+fhjl/g37XwkX/BC+HkjxQXMbsNbsZ07sNERE2LKUxniwRmOAz9xmY/Sj0GQ8X/xMivP+Yzl6zm+KyCsac0tYHARrTsFirIRM8VOGrB2He/8IpV8K4f9f6gbHqzFy+g8S4RpzWuaVPjmdMQ+LVTy0RaSkiX4rIOnd6VOWriHQTkaUerzwRudPd9pCIbPfYdr438ZgQVl4GM37nJIHUm+CSST5LArkFpXy1ajfnn9KGSKsWMuYo3l5z3wt8rapdgK/d5SOo6hpV7aeq/YABQAHwgUeRfxzcrqozK+9vwkBpEUyfAEteh7PvgQv+7rMkADBjWSYlZRVcMaCjz45pTEPibSIYC7zqzr8KjDtO+RHABlXd4uV5TUORvwumXgCrP4HRT8Lwv3h9Y7iyd9O20b1NvA1Sb0w1vE0Eyaq6A8CdHq+B9njgrUrrbhORZSIypaqqpYNEZKKIpIlIWlZWlndRm+Cw42d46RzYvRKufB1Ov9nnp1i7K5+fM3K5fEAHxMcJxpiG4riJQES+EpEVVbzG1uZEIhIDXAxM91j9InAS0A/YAfy9uv1VdbKqpqpqalKS9RMT8tI/hCmjAYUbP6/1mAI19eaCrURHCuNObe+X4xvTEBy31ZCqjqxum4jsEpG2qrpDRNoCu49xqDHAYlXd5XHsQ/Mi8hLwSc3CNiGrrBi+fAAWTIL2qTD+DYhv45dT5RaW8k7aNi7q247EuEZ+OYcxDYG3VUMzgAnu/ATgo2OUvZpK1UJu8jjoEmCFl/GYYLZvs3MVsGASDLoFfjnTb0kAYHraNgpKyrlxSIrfzmFMQ+DtcwRPAO+IyE3AVuAKABFpB7ysque7y02Ac4HfVNr/KRHpByiwuYrtpiFQhWVvw8w/OctXvu63qqCDysormPrDZgamtKR3exuJzJhj8SoRqGo2TkugyuszgfM9lguAowaIVdXrvTm/CQH7d8PHd8KaT6HjILjkP9DS/7/Q31+ynYx9hTx0US+/n8uYUGdPFhv/UIXl0+Gze6DkAIx6FE6/1afPB1SntLyCf36zjj4dmltPo8bUgCUC43u7V8Gnd8GW76H9ABj3IiR1q7fTT0/LYNveQh65uLc1GTWmBiwRGN8pzIG5T8P8FyG2GVz4HPT/Rb1cBRyUW1jK32etIfWEFjYcpTE1ZInAeK+0EBb8B77/BxTlwoAJMOJBaFL/Hbw999Va9haU8OrFA+1qwJgaskRg6q6sGJa+Ad8+Bfk7oMsoGPEAtDklIOEsz8jltR+3cM3ATtZSyJhasERgaq8oDxb9F378N+zf6bQGuuwV6DwkcCGVlnPn20tIimvE3efV3/0IYxoCSwSm5vZthrT/Oq/iXDhxGFz6H0g52+cdxdXW4zNXsSHrAK/fNJCEJjEBjcWYUGOJwBxbeRms+8IZQH79184Xfo+LYOjvod2pgY4OgHcWbuO1H7fwq6EpnNnFbhAbU1uWCMzRVGHHUlj+Lqx4z6n/j2/rjBXQ/xfQPHg6cPtxQzb3fbicM7skcu+Y7oEOx5iQZInAOFRhVzqs+hhWvAvZ6yEiGk4eCec/DV3HQGRwfVwWbt7LTa8upHOrprxwdX+iIm0IbmPqIrj+sk39Ki2ETd/B2s9h7ReQlwEIdB4KZ9zuVAEFoAloTcxevZvb3lxMm2axvPHrQTRvEh3okIwJWZYIwklpEWxPg83zYPN3kLEQyooguimcNByG3es0AY1PDnSk1aqoUKbM28TjM1fRo20zptxwGq3jYwMdljEhzRJBQ6XqtPLJXAKZi2H7YshIg/JiQJy2/qk3OlU/nYdCVPD3178jt5A/vbuM79btYVTPZP5xVT+aNrKPsDHesr+ihqA4H/ashaw1kLUadi53EkDhPmd7ZAwk94aBv3a+9DudDo2rHRU06BwoLmPy3I1MnrsRgMcu6c01AzvZk8PG+IglglBRnA/7tkDOlsPT7PXOl3/utsPlImMgsZtTv9/uVGjXH1r3hKjQa1ufmVPI6/O38NZPW8kpKOWCU9pyz+judGrVJNChGdOgWCIItPIyKNgD+Tth/67D04PzedudL/7CvUfuF90UWp0InQZD0g2Q1N15tegcdK17akpV2bq3gDlrsvh0+Q4Wbt6LAOf1asOvzzqR/p1C5yrGmFDi1TeGiFwBPAT0AAaqalo15UYD/wtE4oxc9oS7viXwNtAZZ4SyK1V1nzcx1bvyUijZDyUFTr/7Jfvd6QEoynF65Czcd/SryGO9Vhx93MYtIC4ZmrWDtv2gxQmQcII77ey05gnhqhFVJTO3iLU781m7K5/0zDx+2rSXnXlFAHRNjuPOEV25tH97Ora0KwBj/Mnbn44rgEuB/1RXQEQigX/hDFWZASwUkRmquhK4F/haVZ8QkXvd5Xu8jKl62xdB1lrnhmlZiTsthvISZ1pWXP228hKnuWVppS/88pKanTu2ufPl3rgFxCZAQidnvkkrp5VOXDLEtTk8H8Q3b8srlNLyCkrKKygtOzhVSsorKCmrYH9xGflFpeQVlZJfVEZ+URm5haXsyitiR27RoWlJ2eEE2KZZLKmdWzDoxFYMPrEVJ7eOC+A7NCa8eDtU5SrgeDftBgLrVXWjW3YaMBZY6U6HueVeBebgx0Sw7JMX6bNjepXbSoiilGjnJdGUeE6JppQoiiWGQlpSKO0oJJZCiaUwOpaCg/O48zSmgEbkE0eexHGAJlQQCYWgBXronAfn9NCqPJRcYG2l9VWV9Vx7eL3nZtWjz3VE2Wq2U+V5lXJVSsoqqDiicM3EREWQ3KwRbZs1pk+HBM7rFUvHlk3o3iaerq3j7TkAYwKoPiqT2wMedzPJAAa588mqugNAVXeISLXjCorIRGAiQKdOneoUyMaet/JezFjKJIYyiaYsIpoyiaZcog9Vs3gmNc/0dnD1keuqLhst0BxI8FjrmSurPm41ZY/IsXL09tocq5rYqy579DGiIoToyAiiIyOIiYogOlLc6cGX0CgqgqaNomgWG018bBTx7jQ2uv4GpzHG1M5xE4GIfAW0qWLTfar6UQ3OUdXlQq1/U6rqZGAyQGpqah1+k8K4M/sz7sz+ddnVGGMarOMmAlUd6eU5MoCOHssdgEx3fpeItHWvBtoCu708lzHGmFqqj166FgJdRCRFRGKA8cAMd9sMYII7PwGoyRWGMcYYH/IqEYjIJSKSAQwGPhWRL9z17URkJoCqlgG3AV8Aq4B3VDXdPcQTwLkisg6nVdET3sRjjDGm9kS1TtXtAZWamqppaVU+smCMMaYaIrJIVVMrr7cO3I0xJsxZIjDGmDBnicAYY8KcJQJjjAlzIXmzWESygC113D0R2OPDcALJ3kvwaSjvA+y9BCtv3ssJqppUeWVIJgJviEhaVXfNQ5G9l+DTUN4H2HsJVv54L1Y1ZIwxYc4SgTHGhLlwTASTAx2AD9l7CT4N5X2AvZdg5fP3Enb3CIwxxhwpHK8IjDHGeLBEYIwxYS4sE4GI/FVElonIUhGZJSLtAh1TXYnI0yKy2n0/H4hIQqBjqgsRuUJE0kWkQkRCspmfiIwWkTUist4dgzskicgUEdktIisCHYs3RKSjiMwWkVXuZ+uOQMdUVyISKyI/icjP7nt52KfHD8d7BCLSTFXz3PnbgZ6qenOAw6oTERkFfKOqZSLyJICq+m3cZ38RkR5ABfAf4C5VDanuZUUkEmew6XNxBmNaCFytqisDGlgdiMhZwH7gNVXtHeh46sod7Kqtqi4WkXhgETAuRP9PBGiqqvtFJBr4HrhDVef74vhheUVwMAm4mlKHoTODharOcsd8AJiPMwJcyFHVVaq6JtBxeGEgsF5VN6pqCTANGBvgmOpEVecCewMdh7dUdYeqLnbn83HGQ2kf2KjqRh373cVo9+Wz762wTAQAIvKYiGwDrgUeCHQ8PnIj8FmggwhT7YFtHssZhOiXTkMkIp2BU4EFAQ6lzkQkUkSW4gzp+6Wq+uy9NNhEICJficiKKl5jAVT1PlXtCLyBM4Ja0Dree3HL3AeU4byfoFST9xHCpIp1IXul2ZCISBzwHnBnpdqAkKKq5araD+eqf6CI+Kza7riD14cqVR1Zw6JvAp8CD/oxHK8c772IyATgQmCEBvFNn1r8n4SiDKCjx3IHIDNAsRiXW5/+HvCGqr4f6Hh8QVVzRGQOMBrwyQ39BntFcCwi0sVj8WJgdaBi8ZaIjAbuAS5W1YJAxxPGFgJdRCRFRGKA8cCMAMcU1twbrK8Aq1T12UDH4w0RSTrYIlBEGgMj8eH3Vri2GnoP6IbTSmULcLOqbg9sVHUjIuuBRkC2u2p+KLaAEpFLgH8CSUAOsFRVzwtoULUkIucDzwGRwBRVfSywEdWNiLwFDMPp7ngX8KCqvhLQoOpARIYC3wHLcf7WAf6iqjMDF1XdiEgf4FWcz1YE8I6qPuKz44djIjDGGHNYWFYNGWOMOcwSgTHGhDlLBMYYE+YsERhjTJizRGCMMWHOEoEJCyKy//ilvDp+kogsEJElInJmDco/JCJ3+SmWRe6zDMbUSIN9stiYejYCWK2qEwIZhNunzna34ztjasSuCEzIEZEnReRWj+WHROSPIhInIl+LyGIRWV5VH0YiMkxEPvFYfkFEbnDnB4jIt+4v6i/cbowr73+Ce45l7rSTiPQDngLOd8e4aFxpnydEZKW7zzNVHLOfiMyXw2NKtHDXzxGR50TkB7dPpoHu+qbumAEL3SsQz/c5BvjcLTfa/bf4WUS+rs2/sQkzqmove4XUC6cXyW89llcCnXCucJu56xKB9Rx+aHK/Ox0GfOKx7wvADTjd+v4AJLnrr8J5OrjyuT8GJrjzNwIfuvM3AC9UUb4lsMYjjgR3+hDOuAsAy4Cz3flHgOfc+TnAS+78WcAKd/5x4LqDx8MZB6Gpu/wRcCLOE9rbgJSDcQT6/81ewfuyqiETclR1iYi0FmdkuSRgn6pudTsYe9wdWKUCpxvoZGBnDQ7bDegNfOl0UUMksKOKcoOBS93513GuBI4lDygCXhaRT4FPPDeKSHOc5PCtu+pVYLpHkbfAGSNARJq5/c2MAi72uMcQC3QSkQ1AB1XdKCIXAXNVdZO7f8iPL2D8xxKBCVXvApcDbXAGgQFnbIkkYICqlorIZpwvSU9lHFklenC7AOmqOriWcRyzjxZ1Ro4biHMPYTxOl+fneHF8xYn1Mq00kI+IjMAZuQq3jPUfY2rE7hGYUDUN54v1cpykANAc2O0mgeHACVXstwXoKSKN3F/jI9z1a4AkERkMTvfFItKriv1/cM8LTuL5vooyh7h94TdXp6OzO4F+nttVNRfY59HS6HrgW48iV7nHGQrkuuW/AH7n9q6JiJzqlh3N4YGJfgTOFpEUt0zLY8VpwptdEZiQpKrp4oxDu11VD1bhvAF8LCJpwFKq6KZXVbeJyDs49fLrgCXu+hIRuRx43k0QUTg9iaZXOsTtwBQRuRvIAn55nFDjgY9EJBbnV/rvqygzAZgkIk2AjZWOuU9EfgCa4dyTAPirG9syNxlsxhmPYhjuaHuqmiUiE4H3RSQCZ1Src48TqwlT1vuoMUHKHXzkLlVNq0HZDjg3lsf4PTDT4NgVgTENgKpm4DQdNabW7IrAGGPCnN0sNsaYMGeJwBhjwpwlAmOMCXOWCIwxJsxZIjDGmDD3/8p4Fr+G2nPHAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>In this graph, we explore thee behaviour of the kernel function and its sensitivity to the variations of the hyperparameters. These graphs are not ideal because in each scanning, we had set the other hyperparameter as constant. Notice however that there is a more dramatic change from -1 to 1 when we vary the slope. Although of course depending on the input vectors, we can also get a positive value when the slope or c is negative.</p>
<p>Interestingly, it has been shown that when the slope and intercept c are in a certain limited range for some a &gt; 0, r &lt; 0, we essentially have a similar behaviour to the RBF kernel. (Source: <a href="https://www.csie.ntu.edu.tw/~cjlin/papers/tanh.pdf">https://www.csie.ntu.edu.tw/~cjlin/papers/tanh.pdf</a>)</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h5 id="define-the-functions-with-sigmoid-kernel">define the functions with sigmoid kernel<a class="anchor-link" href="#define-the-functions-with-sigmoid-kernel">&#182;</a></h5>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[276]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define function to calculate hinge loss</span>
<span class="k">def</span> <span class="nf">compute_cost_sigmoid</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>  
    <span class="n">distances</span><span class="p">[</span><span class="n">distances</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># equivalent to max(0, distance)</span>
    <span class="n">hinge</span> <span class="o">=</span> <span class="n">regul_strength</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="c1"># calculate the hinge loss function</span>
    <span class="c1"># calculate cost</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">hinge</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[277]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># calculate gradient of cost</span>
<span class="k">def</span> <span class="nf">calculate_cost_gradient_sigmoid</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>      <span class="c1"># if only one example is passed</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">y_batch</span><span class="p">])</span>
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">X_batch</span><span class="p">])</span>  <span class="c1"># gives multidimensional arry</span>
    <span class="n">distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">*</span> <span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distance</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">di</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="p">(</span><span class="n">regul_strength</span> <span class="o">*</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
        <span class="n">dw</span> <span class="o">+=</span> <span class="n">di</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">dw</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>  <span class="c1"># average</span>
    <span class="k">return</span> <span class="n">dw</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[278]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define stochastic gradient descent to get weights that define our hyperplane</span>

<span class="k">def</span> <span class="nf">sgd_sigmoid</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="c1"># write the initial conditions for the weights</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">nth</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>  <span class="c1"># initialise starting cost as infinity</span>
  <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">):</span>  <span class="c1"># stochastic gradient descent</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>  <span class="c1"># shuffle to prevent repeating update cycles</span>
      <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
          <span class="n">ascent</span> <span class="o">=</span> <span class="n">calculate_cost_gradient_sigmoid</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">)</span>
          <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">ascent</span><span class="p">)</span>

      <span class="c1"># convergence check on 2^n&#39;th iteration</span>
      <span class="k">if</span> <span class="n">iteration</span><span class="o">==</span><span class="mi">2</span><span class="o">**</span><span class="n">nth</span> <span class="ow">or</span> <span class="n">iteration</span><span class="o">==</span><span class="n">max_iterations</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
          <span class="c1"># compute cost</span>
          <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost_sigmoid</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">)</span> 
          <span class="k">if</span> <span class="n">print_outcome</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration is: </span><span class="si">{}</span><span class="s2">, Cost is: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>
          <span class="c1"># stop criterion</span>
          <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">prev_cost</span> <span class="o">-</span> <span class="n">cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">stop_criterion</span> <span class="o">*</span> <span class="n">prev_cost</span><span class="p">:</span>
              <span class="k">return</span> <span class="n">weights</span>
          
          <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">cost</span>
          <span class="n">nth</span> <span class="o">+=</span> <span class="mi">1</span>
  
  <span class="k">return</span> <span class="n">weights</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[279]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define prediction function</span>
<span class="k">def</span> <span class="nf">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span> <span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="p">)</span>  <span class="c1"># W[-1] is the intercept b of the hyperplane</span>
        
<span class="c1">#         y_pred = np.sign(  kernel_sigmoid(X[i,:-1], W[:-1], slope, c) + W[-1])</span>
<span class="c1">#         y_pred = np.sign(np.dot(X[i], W))</span>
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_preds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[653]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W_hard</span> <span class="o">=</span> <span class="n">sgd_sigmoid</span><span class="p">(</span><span class="n">X_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_11</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e6</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hard</span><span class="p">)</span>
<span class="n">W_soft</span> <span class="o">=</span> <span class="n">sgd_sigmoid</span><span class="p">(</span><span class="n">X_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_11</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_soft</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration is: 1, Cost is: 72432041707.7819
Iteration is: 2, Cost is: 164412536151.2869
Iteration is: 4, Cost is: 247335289067.93423
Iteration is: 8, Cost is: 270692060393.77765
Iteration is: 16, Cost is: 271715349827.50348
Training finished.
[-353011.61416195  238999.14464289 -318635.08876248   87231.37616646
  138968.74444795   34894.10192111 -392725.15899001  139653.13552984
 -217359.1474215  -105080.24546039]
Iteration is: 1, Cost is: 0.0008971598525049202
Iteration is: 2, Cost is: 0.0008971875597396048
Training finished.
[-1.34050092e-04  1.30539355e-04 -7.60064723e-05  1.07761067e-04
  7.92800031e-05 -3.01811658e-05 -1.44278664e-04  1.17895205e-04
 -9.40856058e-05  3.41809772e-05]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[654]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get prediction for test data</span>
<span class="c1"># X_2=X_2.to_numpy()</span>
<span class="c1"># y_2=y_2.to_numpy()</span>

<span class="n">y_pred_h_test</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W_hard</span><span class="p">,</span><span class="n">X_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_22</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">y_pred_s_test</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W_soft</span><span class="p">,</span><span class="n">X_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_22</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">y_actual_test</span> <span class="o">=</span> <span class="n">y_2</span>
<span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;hard margin&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual_test</span><span class="p">,</span><span class="n">y_pred_h_test</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;soft margin&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual_test</span><span class="p">,</span><span class="n">y_pred_s_test</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Test data
hard margin
TP: 82 FP: 30 TN: 23 FN: 65
F1 score : 0.6332046332046333
soft margin
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[288]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W_hard</span> <span class="o">=</span> <span class="n">sgd_sigmoid</span><span class="p">(</span><span class="n">X_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">slope</span><span class="o">=</span><span class="mi">5</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_11</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">1e7</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hard</span><span class="p">)</span>
<span class="n">W_soft</span> <span class="o">=</span> <span class="n">sgd_sigmoid</span><span class="p">(</span><span class="n">X_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">slope</span><span class="o">=</span><span class="mi">5</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_11</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_soft</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration is: 1, Cost is: 7784333020868.32
Iteration is: 2, Cost is: 16959485649488.645
Iteration is: 4, Cost is: 24885383099194.438
Iteration is: 8, Cost is: 27053103625557.992
Iteration is: 16, Cost is: 27160840630827.484
Training finished.
[-3549298.72097779  2383094.53569615 -3196143.11874511   825764.28679378
  1351319.75282191   328678.87186131 -3928276.98032873  1392426.44338418
 -2162214.35658338 -1080879.71514117]
Iteration is: 1, Cost is: 0.008973910689910729
Iteration is: 2, Cost is: 0.008976681413993551
Training finished.
[-0.0013405   0.00130539 -0.00076006  0.00107761  0.0007928  -0.00030181
 -0.00144279  0.00117895 -0.00094086  0.00034181]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[303]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred_h_test</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W_hard</span><span class="p">,</span><span class="n">X_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_22</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">)</span>
<span class="n">y_pred_s_test</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W_soft</span><span class="p">,</span><span class="n">X_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">y_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span><span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_22</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">)</span>
<span class="n">y_actual_test</span> <span class="o">=</span> <span class="n">y_2</span>
<span class="c1"># get F1 score for training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;hard margin&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual_test</span><span class="p">,</span><span class="n">y_pred_h_test</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;soft margin&#39;</span><span class="p">)</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_actual_test</span><span class="p">,</span><span class="n">y_pred_s_test</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Test data
hard margin
TP: 82 FP: 30 TN: 23 FN: 65
F1 score : 0.6332046332046333
soft margin
TP: 65 FP: 23 TN: 30 FN: 82
F1 score : 0.5531914893617021
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>The results for the hard margin seem to be independent from the parameters, but in the soft margin case, varying the intercept does seem to affect the balance between the posittive and negative predictions: for positive values, we get all positive predictions on the testing set, for very small (of order $10^{-5}$) positive and negative values, we have a combination of both positive and negative predictions, while for negative values we only get negative predictions (-1 corresponding to dependent classification variable 0).</p>
<p>In what follows, we will perform a grid parameter search with 5-fold cross-validation on the soft margin sigmoid kernel SVM model to find the optimal hyperparameters.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[383]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate_sigmoid</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">regul_strength</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">print_info</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
  <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>
  <span class="n">F1_scores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">F1_test</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">print_info</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># define the training set</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># define the validation set</span>
    <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># train the model</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">sgd_sigmoid</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> 
                    <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">regul_strength</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">print_outcome</span><span class="o">=</span><span class="n">print_info</span><span class="p">)</span>
    <span class="c1"># get y_pred</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">,</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
    <span class="c1"># get y_pred</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">predict_sigmoid_SVM</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the validation fold</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the test set</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1_t</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">F1_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1_t</span><span class="p">)</span>
    
    

  <span class="k">return</span> <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[369]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># init candidate hyperparameters, we have default regul_strength as 0.01 for the soft margin</span>

<span class="n">slope</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">800</span>
<span class="c1"># cs = [-0.01,-0.001,-0.0008,-0.0005,-0.0003,0]</span>
<span class="n">cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.004</span><span class="p">,</span><span class="mi">0</span><span class="o">-</span><span class="mf">0.0025</span><span class="p">,</span><span class="mf">0.00001</span><span class="p">)</span>

<span class="n">hyperparams</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>

<span class="n">scan</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scan_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;c =&#39;</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate_sigmoid</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">scan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_scores</span><span class="p">))</span>
    <span class="n">scan_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>c = -0.004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0039900000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003980000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003970000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003960000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003950000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0039400000000000025
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003930000000000003
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003920000000000003
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003910000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003900000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0038900000000000046
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003880000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0038700000000000054
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003860000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003850000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0038400000000000066
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003830000000000007
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0038200000000000074
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003810000000000008
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0038000000000000082
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037900000000000086
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003780000000000009
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037700000000000095
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.00376000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037500000000000103
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037400000000000107
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003730000000000011
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037200000000000115
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003710000000000012
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0037000000000000123
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036900000000000127
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003680000000000013
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036700000000000135
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003660000000000014
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036500000000000143
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036400000000000148
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003630000000000015
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036200000000000156
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003610000000000016
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0036000000000000164
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003590000000000017
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003580000000000017
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0035700000000000176
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003560000000000018
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0035500000000000184
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003540000000000019
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0035300000000000192
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0035200000000000196
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.00351000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0035000000000000205
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003490000000000021
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034800000000000213
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034700000000000217
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003460000000000022
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034500000000000225
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003440000000000023
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034300000000000233
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034200000000000237
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003410000000000024
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0034000000000000245
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003390000000000025
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0033800000000000253
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0033700000000000258
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003360000000000026
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0033500000000000266
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003340000000000027
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0033300000000000274
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003320000000000028
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003310000000000028
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0033000000000000286
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003290000000000029
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032800000000000294
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.00327000000000003
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032600000000000302
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032500000000000306
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003240000000000031
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032300000000000315
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003220000000000032
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032100000000000323
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 0 FP: 0 TN: 51 FN: 109
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0032000000000000327
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 1 FP: 4 TN: 47 FN: 108
F1 score : 0.017543859649122806
TP: 0 FP: 2 TN: 51 FN: 147
F1 score : 0
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003190000000000033
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 67 FP: 42 TN: 9 FN: 42
F1 score : 0.6146788990825688
TP: 89 FP: 44 TN: 9 FN: 58
F1 score : 0.6357142857142858
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031800000000000335
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003170000000000034
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 0 FP: 0 TN: 49 FN: 111
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031600000000000343
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 1 FP: 6 TN: 43 FN: 110
F1 score : 0.01694915254237288
TP: 0 FP: 3 TN: 50 FN: 147
F1 score : 0
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 6 FP: 7 TN: 42 FN: 105
F1 score : 0.0967741935483871
TP: 1 FP: 3 TN: 50 FN: 146
F1 score : 0.01324503311258278
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031500000000000347
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 70 FP: 46 TN: 3 FN: 41
F1 score : 0.6167400881057268
TP: 82 FP: 42 TN: 11 FN: 65
F1 score : 0.6051660516605165
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 71 FP: 46 TN: 3 FN: 40
F1 score : 0.6228070175438597
TP: 97 FP: 47 TN: 6 FN: 50
F1 score : 0.6666666666666666
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003140000000000035
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031300000000000355
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003120000000000036
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031100000000000363
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0031000000000000368
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003090000000000037
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0030800000000000376
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003070000000000038
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0030600000000000384
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003050000000000039
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003040000000000039
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0030300000000000396
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.00302000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0030100000000000404
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.003000000000000041
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0029900000000000412
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 0 FP: 0 TN: 42 FN: 118
F1 score : 0
TP: 0 FP: 2 TN: 51 FN: 147
F1 score : 0
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0029800000000000416
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 20 FP: 14 TN: 28 FN: 98
F1 score : 0.2631578947368421
TP: 33 FP: 18 TN: 35 FN: 114
F1 score : 0.33333333333333337
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.002970000000000042
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 105 FP: 41 TN: 1 FN: 13
F1 score : 0.7954545454545454
TP: 130 FP: 53 TN: 0 FN: 17
F1 score : 0.7878787878787878
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.0029600000000000425
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 0 FP: 0 TN: 41 FN: 119
F1 score : 0
TP: 0 FP: 0 TN: 53 FN: 147
F1 score : 0
c = -0.002950000000000043
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 8 FP: 14 TN: 27 FN: 111
F1 score : 0.11347517730496454
TP: 27 FP: 17 TN: 36 FN: 120
F1 score : 0.28272251308900526
c = -0.0029400000000000433
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 107 FP: 37 TN: 4 FN: 12
F1 score : 0.8136882129277566
TP: 126 FP: 53 TN: 0 FN: 21
F1 score : 0.7730061349693251
c = -0.0029300000000000437
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002920000000000044
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0029100000000000445
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002900000000000045
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028900000000000453
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028800000000000457
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002870000000000046
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028600000000000465
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002850000000000047
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028400000000000473
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028300000000000478
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002820000000000048
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0028100000000000486
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002800000000000049
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0027900000000000494
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.00278000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.00277000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0027600000000000506
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002750000000000051
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0027400000000000514
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002730000000000052
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0027200000000000522
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0027100000000000526
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002700000000000053
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026900000000000535
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002680000000000054
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026700000000000543
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026600000000000547
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002650000000000055
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026400000000000555
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002630000000000056
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026200000000000563
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0026100000000000567
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002600000000000057
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0025900000000000575
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002580000000000058
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0025700000000000583
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0025600000000000588
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002550000000000059
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0025400000000000596
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.00253000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.0025200000000000604
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
c = -0.002510000000000061
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[370]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cs</span><span class="p">,</span><span class="n">scan_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xaxis</span><span class="p">(</span><span class="s1">&#39;intercept c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yaxis</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[370]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&lt;matplotlib.lines.Line2D at 0x1a224c5810&gt;]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We do seem to get different F1 scores when we vary the c intercept parameter in the sigmoid kernel function, but it does not reach better accuracies than the prediction where we get all positive preedictions. This suggests there may be fundamental flaws in the optimisation method or in the tuning of other parameters that were not considered in the optimisation.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[375]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># cs = [-0.01,-0.001,-0.0008,-0.0005,-0.0003,0]</span>
<span class="n">c</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">hyperparams</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>

<span class="n">scan</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scan_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">sl</span> <span class="ow">in</span> <span class="n">slopes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope =&#39;</span><span class="p">,</span><span class="n">sl</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate_sigmoid</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">sl</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">scan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_scores</span><span class="p">))</span>
    <span class="n">scan_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>slope = -10.0
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 83 FP: 26 TN: 25 FN: 26
F1 score : 0.7614678899082569
TP: 102 FP: 19 TN: 34 FN: 45
F1 score : 0.7611940298507464
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 83 FP: 20 TN: 29 FN: 28
F1 score : 0.7757009345794393
TP: 101 FP: 23 TN: 30 FN: 46
F1 score : 0.7453874538745388
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 86 FP: 18 TN: 24 FN: 32
F1 score : 0.7747747747747747
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
slope = -9.9
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 83 FP: 26 TN: 25 FN: 26
F1 score : 0.7614678899082569
TP: 102 FP: 19 TN: 34 FN: 45
F1 score : 0.7611940298507464
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 83 FP: 20 TN: 29 FN: 28
F1 score : 0.7757009345794393
TP: 101 FP: 23 TN: 30 FN: 46
F1 score : 0.7453874538745388
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 86 FP: 18 TN: 24 FN: 32
F1 score : 0.7747747747747747
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.8
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 83 FP: 26 TN: 25 FN: 26
F1 score : 0.7614678899082569
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 83 FP: 20 TN: 29 FN: 28
F1 score : 0.7757009345794393
TP: 101 FP: 23 TN: 30 FN: 46
F1 score : 0.7453874538745388
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 86 FP: 18 TN: 24 FN: 32
F1 score : 0.7747747747747747
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.700000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 83 FP: 26 TN: 25 FN: 26
F1 score : 0.7614678899082569
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 83 FP: 20 TN: 29 FN: 28
F1 score : 0.7757009345794393
TP: 102 FP: 23 TN: 30 FN: 45
F1 score : 0.75
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 86 FP: 18 TN: 24 FN: 32
F1 score : 0.7747747747747747
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.600000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 84 FP: 20 TN: 29 FN: 27
F1 score : 0.7813953488372093
TP: 103 FP: 23 TN: 30 FN: 44
F1 score : 0.7545787545787547
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 86 FP: 18 TN: 24 FN: 32
F1 score : 0.7747747747747747
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.500000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 84 FP: 20 TN: 29 FN: 27
F1 score : 0.7813953488372093
TP: 103 FP: 23 TN: 30 FN: 44
F1 score : 0.7545787545787547
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 86 FP: 19 TN: 22 FN: 33
F1 score : 0.7678571428571429
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.400000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 84 FP: 20 TN: 29 FN: 27
F1 score : 0.7813953488372093
TP: 103 FP: 23 TN: 30 FN: 44
F1 score : 0.7545787545787547
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 87 FP: 19 TN: 22 FN: 32
F1 score : 0.7733333333333333
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.300000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 103 FP: 19 TN: 34 FN: 44
F1 score : 0.7657992565055761
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 84 FP: 20 TN: 29 FN: 27
F1 score : 0.7813953488372093
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 87 FP: 20 TN: 21 FN: 32
F1 score : 0.7699115044247786
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.200000000000003
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 84 FP: 20 TN: 29 FN: 27
F1 score : 0.7813953488372093
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 87 FP: 20 TN: 21 FN: 32
F1 score : 0.7699115044247786
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.100000000000003
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 84 FP: 26 TN: 25 FN: 25
F1 score : 0.767123287671233
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 21 TN: 28 FN: 26
F1 score : 0.783410138248848
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 88 FP: 20 TN: 21 FN: 31
F1 score : 0.7753303964757708
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -9.000000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 22 TN: 31 FN: 44
F1 score : 0.7573529411764706
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 18 TN: 24 FN: 30
F1 score : 0.7857142857142858
TP: 102 FP: 22 TN: 31 FN: 45
F1 score : 0.7527675276752769
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 88 FP: 20 TN: 21 FN: 31
F1 score : 0.7753303964757708
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -8.900000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 20 TN: 22 FN: 30
F1 score : 0.7787610619469028
TP: 102 FP: 23 TN: 30 FN: 45
F1 score : 0.75
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 88 FP: 20 TN: 21 FN: 31
F1 score : 0.7753303964757708
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -8.800000000000004
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 20 TN: 22 FN: 30
F1 score : 0.7787610619469028
TP: 102 FP: 23 TN: 30 FN: 45
F1 score : 0.75
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 22 TN: 19 FN: 30
F1 score : 0.7739130434782608
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
slope = -8.700000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 24 TN: 29 FN: 44
F1 score : 0.7518248175182483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 20 TN: 22 FN: 30
F1 score : 0.7787610619469028
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 22 TN: 19 FN: 30
F1 score : 0.7739130434782608
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
slope = -8.600000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 20 TN: 22 FN: 30
F1 score : 0.7787610619469028
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 22 TN: 19 FN: 30
F1 score : 0.7739130434782608
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
slope = -8.500000000000005
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 88 FP: 20 TN: 22 FN: 30
F1 score : 0.7787610619469028
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 23 TN: 18 FN: 30
F1 score : 0.7705627705627704
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
slope = -8.400000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 22 TN: 27 FN: 27
F1 score : 0.7741935483870969
TP: 103 FP: 25 TN: 28 FN: 44
F1 score : 0.749090909090909
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 89 FP: 20 TN: 22 FN: 29
F1 score : 0.7841409691629957
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 23 TN: 18 FN: 30
F1 score : 0.7705627705627704
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
slope = -8.300000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 23 TN: 26 FN: 27
F1 score : 0.7706422018348625
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 89 FP: 20 TN: 22 FN: 29
F1 score : 0.7841409691629957
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 89 FP: 23 TN: 18 FN: 30
F1 score : 0.7705627705627704
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
slope = -8.200000000000006
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 84 FP: 23 TN: 26 FN: 27
F1 score : 0.7706422018348625
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 85 FP: 26 TN: 25 FN: 24
F1 score : 0.7727272727272727
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 89 FP: 20 TN: 22 FN: 29
F1 score : 0.7841409691629957
TP: 102 FP: 27 TN: 26 FN: 45
F1 score : 0.7391304347826086
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 90 FP: 23 TN: 18 FN: 29
F1 score : 0.7758620689655173
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -8.100000000000007
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 104 FP: 19 TN: 34 FN: 43
F1 score : 0.7703703703703704
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 89 FP: 20 TN: 22 FN: 29
F1 score : 0.7841409691629957
TP: 104 FP: 28 TN: 25 FN: 43
F1 score : 0.7455197132616487
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 90 FP: 23 TN: 18 FN: 29
F1 score : 0.7758620689655173
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -8.000000000000007
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 19 TN: 34 FN: 42
F1 score : 0.7749077490774908
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 89 FP: 20 TN: 22 FN: 29
F1 score : 0.7841409691629957
TP: 104 FP: 28 TN: 25 FN: 43
F1 score : 0.7455197132616487
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 91 FP: 23 TN: 18 FN: 28
F1 score : 0.7811158798283262
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.9000000000000075
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 26 TN: 23 FN: 26
F1 score : 0.7657657657657657
TP: 105 FP: 27 TN: 26 FN: 42
F1 score : 0.7526881720430106
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 19 TN: 34 FN: 42
F1 score : 0.7749077490774908
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 23 TN: 26 FN: 26
F1 score : 0.7762557077625571
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 90 FP: 20 TN: 22 FN: 28
F1 score : 0.7894736842105264
TP: 104 FP: 28 TN: 25 FN: 43
F1 score : 0.7455197132616487
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 93 FP: 23 TN: 18 FN: 26
F1 score : 0.7914893617021276
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.800000000000008
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 26 TN: 23 FN: 26
F1 score : 0.7657657657657657
TP: 105 FP: 27 TN: 26 FN: 42
F1 score : 0.7526881720430106
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 24 TN: 29 FN: 42
F1 score : 0.7608695652173914
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 24 TN: 25 FN: 26
F1 score : 0.7727272727272727
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 92 FP: 20 TN: 22 FN: 26
F1 score : 0.8
TP: 104 FP: 28 TN: 25 FN: 43
F1 score : 0.7455197132616487
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 93 FP: 23 TN: 18 FN: 26
F1 score : 0.7914893617021276
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.700000000000008
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 26 TN: 23 FN: 26
F1 score : 0.7657657657657657
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 24 TN: 29 FN: 42
F1 score : 0.7608695652173914
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 24 TN: 25 FN: 26
F1 score : 0.7727272727272727
TP: 103 FP: 26 TN: 27 FN: 44
F1 score : 0.746376811594203
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 92 FP: 20 TN: 22 FN: 26
F1 score : 0.8
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 94 FP: 23 TN: 18 FN: 25
F1 score : 0.7966101694915253
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.6000000000000085
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 85 FP: 26 TN: 23 FN: 26
F1 score : 0.7657657657657657
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 24 TN: 29 FN: 42
F1 score : 0.7608695652173914
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 24 TN: 25 FN: 26
F1 score : 0.7727272727272727
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 92 FP: 20 TN: 22 FN: 26
F1 score : 0.8
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 94 FP: 23 TN: 18 FN: 25
F1 score : 0.7966101694915253
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.500000000000009
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 87 FP: 26 TN: 23 FN: 24
F1 score : 0.7767857142857142
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 24 TN: 29 FN: 42
F1 score : 0.7608695652173914
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 24 TN: 25 FN: 26
F1 score : 0.7727272727272727
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 92 FP: 20 TN: 22 FN: 26
F1 score : 0.8
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 94 FP: 23 TN: 18 FN: 25
F1 score : 0.7966101694915253
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.400000000000009
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 87 FP: 26 TN: 23 FN: 24
F1 score : 0.7767857142857142
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 86 FP: 26 TN: 25 FN: 23
F1 score : 0.7782805429864253
TP: 105 FP: 24 TN: 29 FN: 42
F1 score : 0.7608695652173914
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 24 TN: 25 FN: 26
F1 score : 0.7727272727272727
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 20 TN: 22 FN: 24
F1 score : 0.8103448275862069
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 95 FP: 23 TN: 18 FN: 24
F1 score : 0.8016877637130803
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.30000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 26 TN: 23 FN: 23
F1 score : 0.7822222222222222
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 87 FP: 27 TN: 24 FN: 22
F1 score : 0.7802690582959642
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 25 TN: 24 FN: 26
F1 score : 0.7692307692307693
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 21 TN: 21 FN: 24
F1 score : 0.8068669527896997
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 95 FP: 24 TN: 17 FN: 24
F1 score : 0.7983193277310925
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.20000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 26 TN: 23 FN: 23
F1 score : 0.7822222222222222
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 87 FP: 27 TN: 24 FN: 22
F1 score : 0.7802690582959642
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 25 TN: 24 FN: 26
F1 score : 0.7692307692307693
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 21 TN: 21 FN: 24
F1 score : 0.8068669527896997
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 95 FP: 24 TN: 17 FN: 24
F1 score : 0.7983193277310925
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.10000000000001
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 26 TN: 23 FN: 23
F1 score : 0.7822222222222222
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 87 FP: 27 TN: 24 FN: 22
F1 score : 0.7802690582959642
TP: 105 FP: 26 TN: 27 FN: 42
F1 score : 0.7553956834532375
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 85 FP: 25 TN: 24 FN: 26
F1 score : 0.7692307692307693
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 21 TN: 21 FN: 24
F1 score : 0.8068669527896997
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -7.000000000000011
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 27 TN: 22 FN: 23
F1 score : 0.7787610619469026
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 87 FP: 27 TN: 24 FN: 22
F1 score : 0.7802690582959642
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 21 TN: 21 FN: 24
F1 score : 0.8068669527896997
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -6.900000000000011
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 27 TN: 22 FN: 23
F1 score : 0.7787610619469026
TP: 106 FP: 28 TN: 25 FN: 41
F1 score : 0.7544483985765125
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 88 FP: 27 TN: 24 FN: 21
F1 score : 0.7857142857142858
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 105 FP: 28 TN: 25 FN: 42
F1 score : 0.7500000000000001
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 22 TN: 20 FN: 24
F1 score : 0.8034188034188032
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 103 FP: 27 TN: 26 FN: 44
F1 score : 0.743682310469314
slope = -6.800000000000011
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 27 TN: 22 FN: 23
F1 score : 0.7787610619469026
TP: 108 FP: 28 TN: 25 FN: 39
F1 score : 0.7632508833922261
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 88 FP: 28 TN: 23 FN: 21
F1 score : 0.7822222222222223
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 22 TN: 20 FN: 24
F1 score : 0.8034188034188032
TP: 110 FP: 28 TN: 25 FN: 37
F1 score : 0.7719298245614036
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 27 TN: 26 FN: 37
F1 score : 0.7746478873239437
slope = -6.700000000000012
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 29 TN: 20 FN: 23
F1 score : 0.7719298245614036
TP: 108 FP: 28 TN: 25 FN: 39
F1 score : 0.7632508833922261
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 88 FP: 28 TN: 23 FN: 21
F1 score : 0.7822222222222223
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 22 TN: 20 FN: 24
F1 score : 0.8034188034188032
TP: 110 FP: 28 TN: 25 FN: 37
F1 score : 0.7719298245614036
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 27 TN: 26 FN: 37
F1 score : 0.7746478873239437
slope = -6.600000000000012
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 29 TN: 20 FN: 23
F1 score : 0.7719298245614036
TP: 108 FP: 30 TN: 23 FN: 39
F1 score : 0.7578947368421053
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 88 FP: 28 TN: 23 FN: 21
F1 score : 0.7822222222222223
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 94 FP: 23 TN: 19 FN: 24
F1 score : 0.8000000000000002
TP: 110 FP: 29 TN: 24 FN: 37
F1 score : 0.7692307692307693
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 27 TN: 26 FN: 37
F1 score : 0.7746478873239437
slope = -6.500000000000012
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 88 FP: 29 TN: 20 FN: 23
F1 score : 0.7719298245614036
TP: 108 FP: 30 TN: 23 FN: 39
F1 score : 0.7578947368421053
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 89 FP: 28 TN: 23 FN: 20
F1 score : 0.7876106194690266
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 29 TN: 24 FN: 40
F1 score : 0.7561837455830389
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 95 FP: 23 TN: 19 FN: 23
F1 score : 0.8050847457627118
TP: 111 FP: 29 TN: 24 FN: 36
F1 score : 0.7735191637630662
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 28 TN: 25 FN: 37
F1 score : 0.7719298245614036
slope = -6.400000000000013
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 89 FP: 29 TN: 20 FN: 22
F1 score : 0.777292576419214
TP: 108 FP: 30 TN: 23 FN: 39
F1 score : 0.7578947368421053
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 29 TN: 24 FN: 40
F1 score : 0.7561837455830389
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 95 FP: 23 TN: 19 FN: 23
F1 score : 0.8050847457627118
TP: 111 FP: 29 TN: 24 FN: 36
F1 score : 0.7735191637630662
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 28 TN: 25 FN: 37
F1 score : 0.7719298245614036
slope = -6.300000000000013
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 89 FP: 30 TN: 19 FN: 22
F1 score : 0.7739130434782608
TP: 108 FP: 31 TN: 22 FN: 39
F1 score : 0.7552447552447553
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 31 TN: 22 FN: 40
F1 score : 0.7508771929824561
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 96 FP: 23 TN: 19 FN: 22
F1 score : 0.8101265822784811
TP: 111 FP: 29 TN: 24 FN: 36
F1 score : 0.7735191637630662
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 28 TN: 25 FN: 37
F1 score : 0.7719298245614036
slope = -6.2000000000000135
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 89 FP: 30 TN: 19 FN: 22
F1 score : 0.7739130434782608
TP: 108 FP: 31 TN: 22 FN: 39
F1 score : 0.7552447552447553
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 31 TN: 22 FN: 40
F1 score : 0.7508771929824561
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 96 FP: 23 TN: 19 FN: 22
F1 score : 0.8101265822784811
TP: 111 FP: 29 TN: 24 FN: 36
F1 score : 0.7735191637630662
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 31 TN: 22 FN: 37
F1 score : 0.763888888888889
slope = -6.100000000000014
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 89 FP: 30 TN: 19 FN: 22
F1 score : 0.7739130434782608
TP: 108 FP: 31 TN: 22 FN: 39
F1 score : 0.7552447552447553
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 27 TN: 26 FN: 40
F1 score : 0.7615658362989324
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 87 FP: 25 TN: 24 FN: 24
F1 score : 0.780269058295964
TP: 107 FP: 31 TN: 22 FN: 40
F1 score : 0.7508771929824561
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 23 TN: 19 FN: 21
F1 score : 0.8151260504201682
TP: 111 FP: 29 TN: 24 FN: 36
F1 score : 0.7735191637630662
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 31 TN: 22 FN: 37
F1 score : 0.763888888888889
slope = -6.000000000000014
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 89 FP: 30 TN: 19 FN: 22
F1 score : 0.7739130434782608
TP: 112 FP: 31 TN: 22 FN: 35
F1 score : 0.7724137931034483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 88 FP: 27 TN: 22 FN: 23
F1 score : 0.7787610619469026
TP: 110 FP: 31 TN: 22 FN: 37
F1 score : 0.763888888888889
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 23 TN: 19 FN: 21
F1 score : 0.8151260504201682
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 32 TN: 21 FN: 37
F1 score : 0.7612456747404844
slope = -5.900000000000015
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 90 FP: 30 TN: 19 FN: 21
F1 score : 0.7792207792207791
TP: 112 FP: 31 TN: 22 FN: 35
F1 score : 0.7724137931034483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 90 FP: 28 TN: 23 FN: 19
F1 score : 0.7929515418502202
TP: 107 FP: 28 TN: 25 FN: 40
F1 score : 0.7588652482269505
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 88 FP: 27 TN: 22 FN: 23
F1 score : 0.7787610619469026
TP: 110 FP: 31 TN: 22 FN: 37
F1 score : 0.763888888888889
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 23 TN: 19 FN: 21
F1 score : 0.8151260504201682
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 100 FP: 24 TN: 17 FN: 19
F1 score : 0.8230452674897119
TP: 110 FP: 32 TN: 21 FN: 37
F1 score : 0.7612456747404844
slope = -5.800000000000015
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 90 FP: 31 TN: 18 FN: 21
F1 score : 0.7758620689655173
TP: 112 FP: 31 TN: 22 FN: 35
F1 score : 0.7724137931034483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 91 FP: 28 TN: 23 FN: 18
F1 score : 0.7982456140350875
TP: 115 FP: 29 TN: 24 FN: 32
F1 score : 0.7903780068728522
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 90 FP: 27 TN: 22 FN: 21
F1 score : 0.7894736842105263
TP: 110 FP: 31 TN: 22 FN: 37
F1 score : 0.763888888888889
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 23 TN: 19 FN: 21
F1 score : 0.8151260504201682
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 101 FP: 24 TN: 17 FN: 18
F1 score : 0.8278688524590164
TP: 110 FP: 33 TN: 20 FN: 37
F1 score : 0.7586206896551724
slope = -5.700000000000015
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 94 FP: 31 TN: 18 FN: 17
F1 score : 0.7966101694915254
TP: 112 FP: 31 TN: 22 FN: 35
F1 score : 0.7724137931034483
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 91 FP: 28 TN: 23 FN: 18
F1 score : 0.7982456140350875
TP: 115 FP: 31 TN: 22 FN: 32
F1 score : 0.7849829351535836
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 90 FP: 27 TN: 22 FN: 21
F1 score : 0.7894736842105263
TP: 110 FP: 32 TN: 21 FN: 37
F1 score : 0.7612456747404844
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 23 TN: 19 FN: 21
F1 score : 0.8151260504201682
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 102 FP: 24 TN: 17 FN: 17
F1 score : 0.8326530612244899
TP: 110 FP: 33 TN: 20 FN: 37
F1 score : 0.7586206896551724
slope = -5.600000000000016
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 94 FP: 31 TN: 18 FN: 17
F1 score : 0.7966101694915254
TP: 118 FP: 31 TN: 22 FN: 29
F1 score : 0.7972972972972974
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 91 FP: 28 TN: 23 FN: 18
F1 score : 0.7982456140350875
TP: 115 FP: 31 TN: 22 FN: 32
F1 score : 0.7849829351535836
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 90 FP: 27 TN: 22 FN: 21
F1 score : 0.7894736842105263
TP: 111 FP: 32 TN: 21 FN: 36
F1 score : 0.7655172413793103
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 24 TN: 18 FN: 21
F1 score : 0.811715481171548
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 102 FP: 25 TN: 16 FN: 17
F1 score : 0.8292682926829269
TP: 110 FP: 33 TN: 20 FN: 37
F1 score : 0.7586206896551724
slope = -5.500000000000016
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 94 FP: 31 TN: 18 FN: 17
F1 score : 0.7966101694915254
TP: 118 FP: 31 TN: 22 FN: 29
F1 score : 0.7972972972972974
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 92 FP: 28 TN: 23 FN: 17
F1 score : 0.8034934497816594
TP: 115 FP: 31 TN: 22 FN: 32
F1 score : 0.7849829351535836
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 91 FP: 27 TN: 22 FN: 20
F1 score : 0.7947598253275109
TP: 111 FP: 32 TN: 21 FN: 36
F1 score : 0.7655172413793103
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 24 TN: 18 FN: 21
F1 score : 0.811715481171548
TP: 113 FP: 29 TN: 24 FN: 34
F1 score : 0.7820069204152249
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 104 FP: 25 TN: 16 FN: 15
F1 score : 0.8387096774193548
TP: 110 FP: 33 TN: 20 FN: 37
F1 score : 0.7586206896551724
slope = -5.400000000000016
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 95 FP: 33 TN: 16 FN: 16
F1 score : 0.7949790794979079
TP: 118 FP: 31 TN: 22 FN: 29
F1 score : 0.7972972972972974
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 92 FP: 28 TN: 23 FN: 17
F1 score : 0.8034934497816594
TP: 115 FP: 31 TN: 22 FN: 32
F1 score : 0.7849829351535836
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 91 FP: 27 TN: 22 FN: 20
F1 score : 0.7947598253275109
TP: 112 FP: 32 TN: 21 FN: 35
F1 score : 0.7697594501718213
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 97 FP: 24 TN: 18 FN: 21
F1 score : 0.811715481171548
TP: 113 FP: 31 TN: 22 FN: 34
F1 score : 0.7766323024054983
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 104 FP: 25 TN: 16 FN: 15
F1 score : 0.8387096774193548
TP: 112 FP: 33 TN: 20 FN: 35
F1 score : 0.767123287671233
slope = -5.300000000000017
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 95 FP: 33 TN: 16 FN: 16
F1 score : 0.7949790794979079
TP: 118 FP: 31 TN: 22 FN: 29
F1 score : 0.7972972972972974
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 93 FP: 29 TN: 22 FN: 16
F1 score : 0.8051948051948052
TP: 116 FP: 31 TN: 22 FN: 31
F1 score : 0.7891156462585034
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 91 FP: 27 TN: 22 FN: 20
F1 score : 0.7947598253275109
TP: 112 FP: 32 TN: 21 FN: 35
F1 score : 0.7697594501718213
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 24 TN: 18 FN: 20
F1 score : 0.8166666666666667
TP: 113 FP: 31 TN: 22 FN: 34
F1 score : 0.7766323024054983
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 104 FP: 25 TN: 16 FN: 15
F1 score : 0.8387096774193548
TP: 112 FP: 33 TN: 20 FN: 35
F1 score : 0.767123287671233
slope = -5.200000000000017
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 95 FP: 33 TN: 16 FN: 16
F1 score : 0.7949790794979079
TP: 118 FP: 31 TN: 22 FN: 29
F1 score : 0.7972972972972974
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 94 FP: 29 TN: 22 FN: 15
F1 score : 0.8103448275862069
TP: 116 FP: 31 TN: 22 FN: 31
F1 score : 0.7891156462585034
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 92 FP: 27 TN: 22 FN: 19
F1 score : 0.8
TP: 112 FP: 32 TN: 21 FN: 35
F1 score : 0.7697594501718213
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 24 TN: 18 FN: 20
F1 score : 0.8166666666666667
TP: 113 FP: 31 TN: 22 FN: 34
F1 score : 0.7766323024054983
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 104 FP: 25 TN: 16 FN: 15
F1 score : 0.8387096774193548
TP: 112 FP: 33 TN: 20 FN: 35
F1 score : 0.767123287671233
slope = -5.100000000000017
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 97 FP: 33 TN: 16 FN: 14
F1 score : 0.8049792531120332
TP: 118 FP: 32 TN: 21 FN: 29
F1 score : 0.7946127946127945
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 94 FP: 31 TN: 20 FN: 15
F1 score : 0.8034188034188036
TP: 116 FP: 31 TN: 22 FN: 31
F1 score : 0.7891156462585034
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 92 FP: 27 TN: 22 FN: 19
F1 score : 0.8
TP: 112 FP: 32 TN: 21 FN: 35
F1 score : 0.7697594501718213
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 25 TN: 17 FN: 20
F1 score : 0.8132780082987551
TP: 113 FP: 31 TN: 22 FN: 34
F1 score : 0.7766323024054983
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 104 FP: 25 TN: 16 FN: 15
F1 score : 0.8387096774193548
TP: 112 FP: 33 TN: 20 FN: 35
F1 score : 0.767123287671233
slope = -5.000000000000018
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 99 FP: 33 TN: 16 FN: 12
F1 score : 0.8148148148148148
TP: 118 FP: 32 TN: 21 FN: 29
F1 score : 0.7946127946127945
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 94 FP: 31 TN: 20 FN: 15
F1 score : 0.8034188034188036
TP: 116 FP: 32 TN: 21 FN: 31
F1 score : 0.7864406779661017
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 93 FP: 27 TN: 22 FN: 18
F1 score : 0.8051948051948051
TP: 118 FP: 33 TN: 20 FN: 29
F1 score : 0.7919463087248323
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 25 TN: 17 FN: 20
F1 score : 0.8132780082987551
TP: 114 FP: 31 TN: 22 FN: 33
F1 score : 0.7808219178082191
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 105 FP: 25 TN: 16 FN: 14
F1 score : 0.8433734939759037
TP: 112 FP: 33 TN: 20 FN: 35
F1 score : 0.767123287671233
slope = -4.900000000000018
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 119 FP: 32 TN: 21 FN: 28
F1 score : 0.7986577181208054
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 94 FP: 31 TN: 20 FN: 15
F1 score : 0.8034188034188036
TP: 116 FP: 32 TN: 21 FN: 31
F1 score : 0.7864406779661017
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 93 FP: 27 TN: 22 FN: 18
F1 score : 0.8051948051948051
TP: 118 FP: 33 TN: 20 FN: 29
F1 score : 0.7919463087248323
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 25 TN: 17 FN: 20
F1 score : 0.8132780082987551
TP: 114 FP: 31 TN: 22 FN: 33
F1 score : 0.7808219178082191
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 105 FP: 26 TN: 15 FN: 14
F1 score : 0.84
TP: 114 FP: 33 TN: 20 FN: 33
F1 score : 0.7755102040816326
slope = -4.8000000000000185
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 121 FP: 32 TN: 21 FN: 26
F1 score : 0.8066666666666666
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 94 FP: 31 TN: 20 FN: 15
F1 score : 0.8034188034188036
TP: 116 FP: 37 TN: 16 FN: 31
F1 score : 0.7733333333333333
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 93 FP: 27 TN: 22 FN: 18
F1 score : 0.8051948051948051
TP: 119 FP: 33 TN: 20 FN: 28
F1 score : 0.7959866220735786
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 25 TN: 17 FN: 20
F1 score : 0.8132780082987551
TP: 114 FP: 32 TN: 21 FN: 33
F1 score : 0.7781569965870306
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 105 FP: 26 TN: 15 FN: 14
F1 score : 0.84
TP: 115 FP: 33 TN: 20 FN: 32
F1 score : 0.7796610169491526
slope = -4.700000000000019
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 121 FP: 32 TN: 21 FN: 26
F1 score : 0.8066666666666666
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 95 FP: 31 TN: 20 FN: 14
F1 score : 0.8085106382978724
TP: 122 FP: 37 TN: 16 FN: 25
F1 score : 0.7973856209150327
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 27 TN: 22 FN: 17
F1 score : 0.810344827586207
TP: 119 FP: 33 TN: 20 FN: 28
F1 score : 0.7959866220735786
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 25 TN: 17 FN: 20
F1 score : 0.8132780082987551
TP: 114 FP: 32 TN: 21 FN: 33
F1 score : 0.7781569965870306
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 106 FP: 26 TN: 15 FN: 13
F1 score : 0.844621513944223
TP: 116 FP: 33 TN: 20 FN: 31
F1 score : 0.7837837837837838
slope = -4.600000000000019
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 121 FP: 32 TN: 21 FN: 26
F1 score : 0.8066666666666666
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 96 FP: 33 TN: 18 FN: 13
F1 score : 0.8067226890756303
TP: 126 FP: 38 TN: 15 FN: 21
F1 score : 0.8102893890675242
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 27 TN: 22 FN: 17
F1 score : 0.810344827586207
TP: 119 FP: 33 TN: 20 FN: 28
F1 score : 0.7959866220735786
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 26 TN: 16 FN: 20
F1 score : 0.8099173553719008
TP: 114 FP: 35 TN: 18 FN: 33
F1 score : 0.7702702702702703
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 106 FP: 26 TN: 15 FN: 13
F1 score : 0.844621513944223
TP: 117 FP: 33 TN: 20 FN: 30
F1 score : 0.7878787878787878
slope = -4.5000000000000195
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 121 FP: 32 TN: 21 FN: 26
F1 score : 0.8066666666666666
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 96 FP: 36 TN: 15 FN: 13
F1 score : 0.7966804979253113
TP: 126 FP: 39 TN: 14 FN: 21
F1 score : 0.8076923076923076
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 27 TN: 22 FN: 17
F1 score : 0.810344827586207
TP: 121 FP: 33 TN: 20 FN: 26
F1 score : 0.8039867109634551
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 26 TN: 16 FN: 20
F1 score : 0.8099173553719008
TP: 114 FP: 35 TN: 18 FN: 33
F1 score : 0.7702702702702703
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 108 FP: 27 TN: 14 FN: 11
F1 score : 0.8503937007874016
TP: 117 FP: 35 TN: 18 FN: 30
F1 score : 0.782608695652174
slope = -4.40000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 100 FP: 33 TN: 16 FN: 11
F1 score : 0.819672131147541
TP: 122 FP: 32 TN: 21 FN: 25
F1 score : 0.8106312292358805
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 98 FP: 36 TN: 15 FN: 11
F1 score : 0.8065843621399177
TP: 126 FP: 42 TN: 11 FN: 21
F1 score : 0.7999999999999999
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 29 TN: 20 FN: 17
F1 score : 0.8034188034188033
TP: 121 FP: 33 TN: 20 FN: 26
F1 score : 0.8039867109634551
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 26 TN: 16 FN: 20
F1 score : 0.8099173553719008
TP: 114 FP: 35 TN: 18 FN: 33
F1 score : 0.7702702702702703
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 109 FP: 27 TN: 14 FN: 10
F1 score : 0.8549019607843137
TP: 117 FP: 35 TN: 18 FN: 30
F1 score : 0.782608695652174
slope = -4.30000000000002
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 101 FP: 33 TN: 16 FN: 10
F1 score : 0.8244897959183672
TP: 122 FP: 36 TN: 17 FN: 25
F1 score : 0.7999999999999999
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 98 FP: 38 TN: 13 FN: 11
F1 score : 0.7999999999999999
TP: 126 FP: 42 TN: 11 FN: 21
F1 score : 0.7999999999999999
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 29 TN: 20 FN: 17
F1 score : 0.8034188034188033
TP: 121 FP: 33 TN: 20 FN: 26
F1 score : 0.8039867109634551
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 28 TN: 14 FN: 20
F1 score : 0.8032786885245902
TP: 114 FP: 35 TN: 18 FN: 33
F1 score : 0.7702702702702703
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 109 FP: 27 TN: 14 FN: 10
F1 score : 0.8549019607843137
TP: 117 FP: 36 TN: 17 FN: 30
F1 score : 0.7799999999999999
slope = -4.200000000000021
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 101 FP: 33 TN: 16 FN: 10
F1 score : 0.8244897959183672
TP: 122 FP: 36 TN: 17 FN: 25
F1 score : 0.7999999999999999
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 99 FP: 38 TN: 13 FN: 10
F1 score : 0.8048780487804877
TP: 131 FP: 42 TN: 11 FN: 16
F1 score : 0.81875
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 29 TN: 20 FN: 17
F1 score : 0.8034188034188033
TP: 121 FP: 33 TN: 20 FN: 26
F1 score : 0.8039867109634551
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 28 TN: 14 FN: 20
F1 score : 0.8032786885245902
TP: 115 FP: 35 TN: 18 FN: 32
F1 score : 0.7744107744107744
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 111 FP: 27 TN: 14 FN: 8
F1 score : 0.8638132295719845
TP: 117 FP: 36 TN: 17 FN: 30
F1 score : 0.7799999999999999
slope = -4.100000000000021
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 101 FP: 33 TN: 16 FN: 10
F1 score : 0.8244897959183672
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 99 FP: 38 TN: 13 FN: 10
F1 score : 0.8048780487804877
TP: 131 FP: 42 TN: 11 FN: 16
F1 score : 0.81875
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 94 FP: 31 TN: 18 FN: 17
F1 score : 0.7966101694915254
TP: 122 FP: 35 TN: 18 FN: 25
F1 score : 0.8026315789473685
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 28 TN: 14 FN: 20
F1 score : 0.8032786885245902
TP: 115 FP: 35 TN: 18 FN: 32
F1 score : 0.7744107744107744
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 111 FP: 27 TN: 14 FN: 8
F1 score : 0.8638132295719845
TP: 120 FP: 37 TN: 16 FN: 27
F1 score : 0.7894736842105263
slope = -4.000000000000021
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 33 TN: 16 FN: 8
F1 score : 0.834008097165992
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 99 FP: 38 TN: 13 FN: 10
F1 score : 0.8048780487804877
TP: 131 FP: 42 TN: 11 FN: 16
F1 score : 0.81875
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 96 FP: 31 TN: 18 FN: 15
F1 score : 0.8067226890756303
TP: 122 FP: 38 TN: 15 FN: 25
F1 score : 0.7947882736156352
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 31 TN: 11 FN: 20
F1 score : 0.7935222672064778
TP: 115 FP: 35 TN: 18 FN: 32
F1 score : 0.7744107744107744
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 111 FP: 27 TN: 14 FN: 8
F1 score : 0.8638132295719845
TP: 120 FP: 37 TN: 16 FN: 27
F1 score : 0.7894736842105263
slope = -3.9000000000000217
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 33 TN: 16 FN: 8
F1 score : 0.834008097165992
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 99 FP: 38 TN: 13 FN: 10
F1 score : 0.8048780487804877
TP: 132 FP: 42 TN: 11 FN: 15
F1 score : 0.822429906542056
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 96 FP: 31 TN: 18 FN: 15
F1 score : 0.8067226890756303
TP: 122 FP: 38 TN: 15 FN: 25
F1 score : 0.7947882736156352
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 98 FP: 31 TN: 11 FN: 20
F1 score : 0.7935222672064778
TP: 121 FP: 35 TN: 18 FN: 26
F1 score : 0.7986798679867986
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 120 FP: 37 TN: 16 FN: 27
F1 score : 0.7894736842105263
slope = -3.800000000000022
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 33 TN: 16 FN: 8
F1 score : 0.834008097165992
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 100 FP: 38 TN: 13 FN: 9
F1 score : 0.8097165991902835
TP: 134 FP: 42 TN: 11 FN: 13
F1 score : 0.8297213622291021
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 97 FP: 31 TN: 18 FN: 14
F1 score : 0.8117154811715481
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 99 FP: 31 TN: 11 FN: 19
F1 score : 0.7983870967741936
TP: 121 FP: 35 TN: 18 FN: 26
F1 score : 0.7986798679867986
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 120 FP: 37 TN: 16 FN: 27
F1 score : 0.7894736842105263
slope = -3.7000000000000224
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 33 TN: 16 FN: 8
F1 score : 0.834008097165992
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 101 FP: 38 TN: 13 FN: 8
F1 score : 0.8145161290322581
TP: 134 FP: 42 TN: 11 FN: 13
F1 score : 0.8297213622291021
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 98 FP: 31 TN: 18 FN: 13
F1 score : 0.8166666666666668
TP: 122 FP: 41 TN: 12 FN: 25
F1 score : 0.7870967741935484
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 99 FP: 31 TN: 11 FN: 19
F1 score : 0.7983870967741936
TP: 121 FP: 35 TN: 18 FN: 26
F1 score : 0.7986798679867986
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 121 FP: 39 TN: 14 FN: 26
F1 score : 0.7882736156351792
slope = -3.6000000000000227
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 33 TN: 16 FN: 8
F1 score : 0.834008097165992
TP: 123 FP: 43 TN: 10 FN: 24
F1 score : 0.7859424920127795
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 102 FP: 38 TN: 13 FN: 7
F1 score : 0.819277108433735
TP: 134 FP: 42 TN: 11 FN: 13
F1 score : 0.8297213622291021
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 98 FP: 31 TN: 18 FN: 13
F1 score : 0.8166666666666668
TP: 123 FP: 41 TN: 12 FN: 24
F1 score : 0.7909967845659165
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 99 FP: 33 TN: 9 FN: 19
F1 score : 0.792
TP: 127 FP: 38 TN: 15 FN: 20
F1 score : 0.814102564102564
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 121 FP: 39 TN: 14 FN: 26
F1 score : 0.7882736156351792
slope = -3.500000000000023
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 34 TN: 15 FN: 8
F1 score : 0.8306451612903225
TP: 123 FP: 44 TN: 9 FN: 24
F1 score : 0.7834394904458599
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 102 FP: 38 TN: 13 FN: 7
F1 score : 0.819277108433735
TP: 134 FP: 42 TN: 11 FN: 13
F1 score : 0.8297213622291021
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 98 FP: 31 TN: 18 FN: 13
F1 score : 0.8166666666666668
TP: 123 FP: 41 TN: 12 FN: 24
F1 score : 0.7909967845659165
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 99 FP: 33 TN: 9 FN: 19
F1 score : 0.792
TP: 127 FP: 38 TN: 15 FN: 20
F1 score : 0.814102564102564
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 121 FP: 42 TN: 11 FN: 26
F1 score : 0.7806451612903227
slope = -3.4000000000000234
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 35 TN: 14 FN: 8
F1 score : 0.8273092369477911
TP: 129 FP: 44 TN: 9 FN: 18
F1 score : 0.80625
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 103 FP: 38 TN: 13 FN: 6
F1 score : 0.824
TP: 134 FP: 42 TN: 11 FN: 13
F1 score : 0.8297213622291021
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 98 FP: 31 TN: 18 FN: 13
F1 score : 0.8166666666666668
TP: 123 FP: 42 TN: 11 FN: 24
F1 score : 0.7884615384615385
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 100 FP: 34 TN: 8 FN: 18
F1 score : 0.7936507936507936
TP: 128 FP: 41 TN: 12 FN: 19
F1 score : 0.810126582278481
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 28 TN: 13 FN: 4
F1 score : 0.8778625954198472
TP: 121 FP: 42 TN: 11 FN: 26
F1 score : 0.7806451612903227
slope = -3.300000000000024
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 35 TN: 14 FN: 8
F1 score : 0.8273092369477911
TP: 129 FP: 44 TN: 9 FN: 18
F1 score : 0.80625
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 103 FP: 38 TN: 13 FN: 6
F1 score : 0.824
TP: 134 FP: 45 TN: 8 FN: 13
F1 score : 0.8220858895705521
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 100 FP: 32 TN: 17 FN: 11
F1 score : 0.823045267489712
TP: 123 FP: 44 TN: 9 FN: 24
F1 score : 0.7834394904458599
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 100 FP: 34 TN: 8 FN: 18
F1 score : 0.7936507936507936
TP: 129 FP: 41 TN: 12 FN: 18
F1 score : 0.8138801261829653
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 29 TN: 12 FN: 4
F1 score : 0.8745247148288973
TP: 122 FP: 42 TN: 11 FN: 25
F1 score : 0.7845659163987139
slope = -3.200000000000024
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 36 TN: 13 FN: 8
F1 score : 0.824
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 104 FP: 38 TN: 13 FN: 5
F1 score : 0.8286852589641435
TP: 135 FP: 45 TN: 8 FN: 12
F1 score : 0.8256880733944955
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 100 FP: 32 TN: 17 FN: 11
F1 score : 0.823045267489712
TP: 129 FP: 44 TN: 9 FN: 18
F1 score : 0.80625
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 101 FP: 35 TN: 7 FN: 17
F1 score : 0.7952755905511811
TP: 129 FP: 41 TN: 12 FN: 18
F1 score : 0.8138801261829653
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 29 TN: 12 FN: 4
F1 score : 0.8745247148288973
TP: 122 FP: 42 TN: 11 FN: 25
F1 score : 0.7845659163987139
slope = -3.1000000000000245
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 103 FP: 37 TN: 12 FN: 8
F1 score : 0.8207171314741037
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 104 FP: 39 TN: 12 FN: 5
F1 score : 0.8253968253968254
TP: 135 FP: 48 TN: 5 FN: 12
F1 score : 0.8181818181818182
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 101 FP: 33 TN: 16 FN: 10
F1 score : 0.8244897959183672
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 101 FP: 35 TN: 7 FN: 17
F1 score : 0.7952755905511811
TP: 129 FP: 41 TN: 12 FN: 18
F1 score : 0.8138801261829653
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 29 TN: 12 FN: 4
F1 score : 0.8745247148288973
TP: 122 FP: 42 TN: 11 FN: 25
F1 score : 0.7845659163987139
slope = -3.000000000000025
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 104 FP: 38 TN: 11 FN: 7
F1 score : 0.8221343873517787
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 104 FP: 39 TN: 12 FN: 5
F1 score : 0.8253968253968254
TP: 135 FP: 48 TN: 5 FN: 12
F1 score : 0.8181818181818182
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 101 FP: 35 TN: 14 FN: 10
F1 score : 0.8178137651821862
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 102 FP: 35 TN: 7 FN: 16
F1 score : 0.7999999999999999
TP: 129 FP: 43 TN: 10 FN: 18
F1 score : 0.8087774294670848
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 30 TN: 11 FN: 4
F1 score : 0.8712121212121211
TP: 123 FP: 44 TN: 9 FN: 24
F1 score : 0.7834394904458599
slope = -2.9000000000000252
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 105 FP: 38 TN: 11 FN: 6
F1 score : 0.8267716535433071
TP: 136 FP: 45 TN: 8 FN: 11
F1 score : 0.8292682926829269
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 105 FP: 39 TN: 12 FN: 4
F1 score : 0.8300395256916996
TP: 141 FP: 48 TN: 5 FN: 6
F1 score : 0.8392857142857143
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 103 FP: 37 TN: 12 FN: 8
F1 score : 0.8207171314741037
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 102 FP: 35 TN: 7 FN: 16
F1 score : 0.7999999999999999
TP: 129 FP: 43 TN: 10 FN: 18
F1 score : 0.8087774294670848
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 115 FP: 33 TN: 8 FN: 4
F1 score : 0.8614232209737828
TP: 130 FP: 44 TN: 9 FN: 17
F1 score : 0.809968847352025
slope = -2.8000000000000256
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 105 FP: 39 TN: 10 FN: 6
F1 score : 0.8235294117647058
TP: 136 FP: 45 TN: 8 FN: 11
F1 score : 0.8292682926829269
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 105 FP: 39 TN: 12 FN: 4
F1 score : 0.8300395256916996
TP: 141 FP: 48 TN: 5 FN: 6
F1 score : 0.8392857142857143
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 103 FP: 37 TN: 12 FN: 8
F1 score : 0.8207171314741037
TP: 136 FP: 44 TN: 9 FN: 11
F1 score : 0.8318042813455656
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 102 FP: 35 TN: 7 FN: 16
F1 score : 0.7999999999999999
TP: 129 FP: 43 TN: 10 FN: 18
F1 score : 0.8087774294670848
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 116 FP: 33 TN: 8 FN: 3
F1 score : 0.8656716417910447
TP: 135 FP: 44 TN: 9 FN: 12
F1 score : 0.8282208588957056
slope = -2.700000000000026
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 106 FP: 41 TN: 8 FN: 5
F1 score : 0.8217054263565892
TP: 136 FP: 48 TN: 5 FN: 11
F1 score : 0.8217522658610272
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 105 FP: 39 TN: 12 FN: 4
F1 score : 0.8300395256916996
TP: 144 FP: 50 TN: 3 FN: 3
F1 score : 0.844574780058651
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 103 FP: 40 TN: 9 FN: 8
F1 score : 0.8110236220472441
TP: 139 FP: 48 TN: 5 FN: 8
F1 score : 0.8323353293413174
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 102 FP: 35 TN: 7 FN: 16
F1 score : 0.7999999999999999
TP: 135 FP: 43 TN: 10 FN: 12
F1 score : 0.8307692307692308
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 116 FP: 34 TN: 7 FN: 3
F1 score : 0.8624535315985129
TP: 135 FP: 45 TN: 8 FN: 12
F1 score : 0.8256880733944955
slope = -2.6000000000000263
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 106 FP: 42 TN: 7 FN: 5
F1 score : 0.8185328185328186
TP: 139 FP: 50 TN: 3 FN: 8
F1 score : 0.8273809523809524
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 105 FP: 39 TN: 12 FN: 4
F1 score : 0.8300395256916996
TP: 145 FP: 50 TN: 3 FN: 2
F1 score : 0.847953216374269
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 103 FP: 42 TN: 7 FN: 8
F1 score : 0.8046874999999999
TP: 139 FP: 50 TN: 3 FN: 8
F1 score : 0.8273809523809524
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 106 FP: 37 TN: 5 FN: 12
F1 score : 0.8122605363984675
TP: 138 FP: 44 TN: 9 FN: 9
F1 score : 0.8389057750759877
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 116 FP: 34 TN: 7 FN: 3
F1 score : 0.8624535315985129
TP: 135 FP: 45 TN: 8 FN: 12
F1 score : 0.8256880733944955
slope = -2.5000000000000266
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 108 FP: 42 TN: 7 FN: 3
F1 score : 0.8275862068965518
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 105 FP: 44 TN: 7 FN: 4
F1 score : 0.813953488372093
TP: 145 FP: 50 TN: 3 FN: 2
F1 score : 0.847953216374269
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 104 FP: 42 TN: 7 FN: 7
F1 score : 0.8093385214007782
TP: 139 FP: 50 TN: 3 FN: 8
F1 score : 0.8273809523809524
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 106 FP: 37 TN: 5 FN: 12
F1 score : 0.8122605363984675
TP: 138 FP: 47 TN: 6 FN: 9
F1 score : 0.8313253012048193
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 116 FP: 34 TN: 7 FN: 3
F1 score : 0.8624535315985129
TP: 141 FP: 48 TN: 5 FN: 6
F1 score : 0.8392857142857143
slope = -2.400000000000027
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 108 FP: 42 TN: 7 FN: 3
F1 score : 0.8275862068965518
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 107 FP: 44 TN: 7 FN: 2
F1 score : 0.823076923076923
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 104 FP: 42 TN: 7 FN: 7
F1 score : 0.8093385214007782
TP: 141 FP: 50 TN: 3 FN: 6
F1 score : 0.8343195266272189
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 108 FP: 37 TN: 5 FN: 10
F1 score : 0.8212927756653994
TP: 138 FP: 47 TN: 6 FN: 9
F1 score : 0.8313253012048193
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 117 FP: 35 TN: 6 FN: 2
F1 score : 0.8634686346863469
TP: 143 FP: 48 TN: 5 FN: 4
F1 score : 0.8461538461538461
slope = -2.3000000000000274
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 109 FP: 42 TN: 7 FN: 2
F1 score : 0.83206106870229
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 107 FP: 44 TN: 7 FN: 2
F1 score : 0.823076923076923
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 105 FP: 42 TN: 7 FN: 6
F1 score : 0.813953488372093
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 109 FP: 37 TN: 5 FN: 9
F1 score : 0.8257575757575757
TP: 141 FP: 47 TN: 6 FN: 6
F1 score : 0.8417910447761194
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 117 FP: 37 TN: 4 FN: 2
F1 score : 0.8571428571428571
TP: 146 FP: 48 TN: 5 FN: 1
F1 score : 0.8563049853372434
slope = -2.2000000000000277
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 109 FP: 42 TN: 7 FN: 2
F1 score : 0.83206106870229
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 107 FP: 44 TN: 7 FN: 2
F1 score : 0.823076923076923
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 105 FP: 42 TN: 7 FN: 6
F1 score : 0.813953488372093
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 109 FP: 37 TN: 5 FN: 9
F1 score : 0.8257575757575757
TP: 141 FP: 50 TN: 3 FN: 6
F1 score : 0.8343195266272189
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 117 FP: 37 TN: 4 FN: 2
F1 score : 0.8571428571428571
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
slope = -2.100000000000028
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 110 FP: 42 TN: 7 FN: 1
F1 score : 0.8365019011406843
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 107 FP: 46 TN: 5 FN: 2
F1 score : 0.816793893129771
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 105 FP: 43 TN: 6 FN: 6
F1 score : 0.8108108108108109
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 110 FP: 37 TN: 5 FN: 8
F1 score : 0.830188679245283
TP: 141 FP: 50 TN: 3 FN: 6
F1 score : 0.8343195266272189
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 118 FP: 37 TN: 4 FN: 1
F1 score : 0.8613138686131386
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
slope = -2.0000000000000284
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 110 FP: 43 TN: 6 FN: 1
F1 score : 0.8333333333333333
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 47 TN: 4 FN: 0
F1 score : 0.8226415094339622
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 106 FP: 43 TN: 6 FN: 5
F1 score : 0.8153846153846154
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 114 FP: 37 TN: 5 FN: 4
F1 score : 0.8475836431226765
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 118 FP: 37 TN: 4 FN: 1
F1 score : 0.8613138686131386
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
slope = -1.9000000000000288
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 110 FP: 43 TN: 6 FN: 1
F1 score : 0.8333333333333333
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 48 TN: 3 FN: 0
F1 score : 0.819548872180451
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 106 FP: 43 TN: 6 FN: 5
F1 score : 0.8153846153846154
TP: 147 FP: 50 TN: 3 FN: 0
F1 score : 0.8546511627906977
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 114 FP: 37 TN: 5 FN: 4
F1 score : 0.8475836431226765
TP: 146 FP: 50 TN: 3 FN: 1
F1 score : 0.8513119533527697
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 118 FP: 37 TN: 4 FN: 1
F1 score : 0.8613138686131386
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.8000000000000291
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 110 FP: 45 TN: 4 FN: 1
F1 score : 0.8270676691729324
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 49 TN: 2 FN: 0
F1 score : 0.8164794007490637
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 106 FP: 43 TN: 6 FN: 5
F1 score : 0.8153846153846154
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 115 FP: 39 TN: 3 FN: 3
F1 score : 0.8455882352941175
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 37 TN: 4 FN: 0
F1 score : 0.8654545454545455
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.7000000000000295
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 45 TN: 4 FN: 0
F1 score : 0.8314606741573033
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 107 FP: 47 TN: 2 FN: 4
F1 score : 0.8075471698113208
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 115 FP: 39 TN: 3 FN: 3
F1 score : 0.8455882352941175
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 39 TN: 2 FN: 0
F1 score : 0.8592057761732852
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.6000000000000298
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 48 TN: 1 FN: 0
F1 score : 0.8222222222222222
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 116 FP: 40 TN: 2 FN: 2
F1 score : 0.8467153284671532
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 39 TN: 2 FN: 0
F1 score : 0.8592057761732852
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.5000000000000302
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 116 FP: 41 TN: 1 FN: 2
F1 score : 0.8436363636363636
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 39 TN: 2 FN: 0
F1 score : 0.8592057761732852
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.4000000000000306
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 116 FP: 41 TN: 1 FN: 2
F1 score : 0.8436363636363636
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.300000000000031
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
slope = -1.2000000000000313
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 51 TN: 2 FN: 0
F1 score : 0.8521739130434782
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -1.1000000000000316
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -1.000000000000032
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.9000000000000323
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.8000000000000327
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.700000000000033
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.6000000000000334
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.5000000000000338
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.4000000000000341
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.30000000000003446
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.20000000000003482
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -0.10000000000003517
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = -3.552713678800501e-14
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.09999999999996412
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.19999999999996376
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.2999999999999634
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.39999999999996305
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.4999999999999627
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.5999999999999623
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.699999999999962
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.7999999999999616
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope = 0.8999999999999613
Fold 1
Iteration is: 1, Cost is: 0.008955372077610933
Iteration is: 2, Cost is: 0.00896048615034294
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
Iteration is: 1, Cost is: 0.008940050832452426
Iteration is: 2, Cost is: 0.00894514708934767
TP: 109 FP: 51 TN: 0 FN: 0
F1 score : 0.8104089219330856
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
Iteration is: 1, Cost is: 0.00895543195326053
Iteration is: 2, Cost is: 0.008960623886081315
TP: 111 FP: 49 TN: 0 FN: 0
F1 score : 0.8191881918819187
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
Iteration is: 1, Cost is: 0.009009107853185915
Iteration is: 2, Cost is: 0.009014429633772615
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 5
Iteration is: 1, Cost is: 0.009016642425011795
Iteration is: 2, Cost is: 0.009021808947850258
TP: 119 FP: 41 TN: 0 FN: 0
F1 score : 0.8530465949820789
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[376]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span><span class="n">scan_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;test set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">scan</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>It looks like for a fixed value of intercept c that was shown to produce a better accuracy, (although only by making all predictions to be 1's, and this accuracy being high due to the data having a large number of 1's in general) we have better accuracy around the value -2.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We now perform a grid search over both hyperparameters:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[399]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.0034</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.4</span><span class="p">)</span>

<span class="n">max_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [slope, c]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Loading for intercept c =&#39;</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sl</span> <span class="ow">in</span> <span class="n">slopes</span><span class="p">:</span>
        <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate_sigmoid</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">sl</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span><span class="n">print_info</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">F1_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_scores</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_scores</span><span class="o">&gt;</span><span class="n">max_val</span><span class="p">:</span>
            <span class="n">max_val</span> <span class="o">=</span> <span class="n">F1_scores</span>
            <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">sl</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                
        <span class="n">F1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span><span class="n">sl</span><span class="p">,</span><span class="s1">&#39;average testing accuracy&#39;</span><span class="p">,</span><span class="n">F1_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_test</span><span class="o">&gt;</span><span class="n">max_test</span><span class="p">:</span>
            <span class="n">max_test</span> <span class="o">=</span> <span class="n">F1_test</span>
            <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">sl</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Loading for intercept c = -0.0034 ...
slope -5.0 average testing accuracy 0.6935630325337923
slope -4.6 average testing accuracy 0.6935630325337923
slope -4.199999999999999 average testing accuracy 0.6935630325337923
slope -3.799999999999999 average testing accuracy 0.6935630325337923
slope -3.3999999999999986 average testing accuracy 0.6941139967211202
slope -2.9999999999999982 average testing accuracy 0.6916901104888294
slope -2.599999999999998 average testing accuracy 0.6916901104888294
slope -2.1999999999999975 average testing accuracy 0.6916901104888294
slope -1.7999999999999972 average testing accuracy 0.6912032883206154
slope -1.3999999999999968 average testing accuracy 0.6879177975376753
slope -0.9999999999999964 average testing accuracy 0.6810317650830665
slope -0.5999999999999961 average testing accuracy 0.6513663171088837
slope -0.19999999999999574 average testing accuracy 0.5694881098239487
slope 0.20000000000000462 average testing accuracy 0.3845936421437508
slope 0.600000000000005 average testing accuracy 0.4491942159820427

Loading for intercept c = 0.0066 ...
slope -5.0 average testing accuracy 0.7660519359606912
slope -4.6 average testing accuracy 0.7626273545701228
slope -4.199999999999999 average testing accuracy 0.7718540026135827
slope -3.799999999999999 average testing accuracy 0.7799855967608706
slope -3.3999999999999986 average testing accuracy 0.7942183471913655
slope -2.9999999999999982 average testing accuracy 0.7929039012860969
slope -2.599999999999998 average testing accuracy 0.799781072526753
slope -2.1999999999999975 average testing accuracy 0.813577577934679
slope -1.7999999999999972 average testing accuracy 0.842178731652244
slope -1.3999999999999968 average testing accuracy 0.8520015211053366
slope -0.9999999999999964 average testing accuracy 0.8492269139205615
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0166 ...
slope -5.0 average testing accuracy 0.80305920537094
slope -4.6 average testing accuracy 0.8136112755622295
slope -4.199999999999999 average testing accuracy 0.8274713153353993
slope -3.799999999999999 average testing accuracy 0.8404590945514684
slope -3.3999999999999986 average testing accuracy 0.8495799162921399
slope -2.9999999999999982 average testing accuracy 0.8534878709536683
slope -2.599999999999998 average testing accuracy 0.8521739130434781
slope -2.1999999999999975 average testing accuracy 0.8511915800025059
slope -1.7999999999999972 average testing accuracy 0.8482445808795891
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0266 ...
slope -5.0 average testing accuracy 0.8485813098952452
slope -4.6 average testing accuracy 0.8534878709536683
slope -4.199999999999999 average testing accuracy 0.8515065722952478
slope -3.799999999999999 average testing accuracy 0.8521739130434781
slope -3.3999999999999986 average testing accuracy 0.8511915800025059
slope -2.9999999999999982 average testing accuracy 0.8492269139205615
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0366 ...
slope -5.0 average testing accuracy 0.8521739130434781
slope -4.6 average testing accuracy 0.8511915800025059
slope -4.199999999999999 average testing accuracy 0.8492269139205615
slope -3.799999999999999 average testing accuracy 0.8482445808795891
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0466 ...
slope -5.0 average testing accuracy 0.8492269139205615
slope -4.6 average testing accuracy 0.8482445808795891
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0566 ...
slope -5.0 average testing accuracy 0.8472622478386167
slope -4.6 average testing accuracy 0.8472622478386167
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0666 ...
slope -5.0 average testing accuracy 0.8472622478386167
slope -4.6 average testing accuracy 0.8472622478386167
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0766 ...
slope -5.0 average testing accuracy 0.8472622478386167
slope -4.6 average testing accuracy 0.8472622478386167
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0866 ...
slope -5.0 average testing accuracy 0.8472622478386167
slope -4.6 average testing accuracy 0.8472622478386167
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167

Loading for intercept c = 0.0966 ...
slope -5.0 average testing accuracy 0.8472622478386167
slope -4.6 average testing accuracy 0.8472622478386167
slope -4.199999999999999 average testing accuracy 0.8472622478386167
slope -3.799999999999999 average testing accuracy 0.8472622478386167
slope -3.3999999999999986 average testing accuracy 0.8472622478386167
slope -2.9999999999999982 average testing accuracy 0.8472622478386167
slope -2.599999999999998 average testing accuracy 0.8472622478386167
slope -2.1999999999999975 average testing accuracy 0.8472622478386167
slope -1.7999999999999972 average testing accuracy 0.8472622478386167
slope -1.3999999999999968 average testing accuracy 0.8472622478386167
slope -0.9999999999999964 average testing accuracy 0.8472622478386167
slope -0.5999999999999961 average testing accuracy 0.8472622478386167
slope -0.19999999999999574 average testing accuracy 0.8472622478386167
slope 0.20000000000000462 average testing accuracy 0.8472622478386167
slope 0.600000000000005 average testing accuracy 0.8472622478386167
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[398]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">list_params_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">list_params_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[0.0, -0.0034]
[0.0, 0.0966]
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>These hyperparameters are not very meaningful since normally they are positive, and moreover the score that determines their choice is the one for the predictions of all 1's. This suggests that the implementation of the optimisation has errors.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="A-state-of-the-art-alternative-to-modifying-the-code-provided">A state-of-the-art alternative to modifying the code provided<a class="anchor-link" href="#A-state-of-the-art-alternative-to-modifying-the-code-provided">&#182;</a></h3><h5 id="(in-other-words,-a-hacky-way-to-implement-the-soft-margin-part-of-the-Mastery-material)">(in other words, a hacky way to implement the soft margin part of the Mastery material)<a class="anchor-link" href="#(in-other-words,-a-hacky-way-to-implement-the-soft-margin-part-of-the-Mastery-material)">&#182;</a></h5>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>A way to go around the failing optimisation in the kernelised soft-margin SVM is to implement a different gradient descent method, namely the Pegasos algorithm, first introduced by Shalev-Shwartz et al. in 2011. (Source: Shalev-Shwartz, S., Singer, Y., Srebro, N. et al. Pegasos: primal estimated sub-gradient solver for SVM. Math. Program. 127, 3–30 (2011). <a href="https://doi.org/10.1007/s10107-010-0420-4">https://doi.org/10.1007/s10107-010-0420-4</a>)</p>
<p>The authors note that it is usually a constrained quadratic programming optimisation problem, but at its core, it originates from an unconstrained minimisation of the hinge loss function. In that paper, it has a slightly different formulation because the penalty term $\lambda$ is written for the norm of the vector $\boldsymbol w$ that is essentially our classification model:
$$
L(\boldsymbol w) = \frac{\lambda}{2} \| \boldsymbol w \|^2 + \frac{1}{n} \sum_{i=1}^n l (\boldsymbol w, (\boldsymbol x, y)) \ 
$$
with $ l = \max \big( 0, 1-y_i \langle \boldsymbol w, \boldsymbol x \rangle ) \big)$ (*), and the inner product of w or x can be either linear or non-linear (kernelised). When kernelised, it is computed as
$$ \langle \boldsymbol w, \boldsymbol x \rangle = \sum_{i\in I_t} \alpha_i \langle \boldsymbol x_i, \boldsymbol x_j \rangle, $$
and computing the norm of the weights that are the parameters of the separation hyperplane we seek to minimise also using the Lagrange multipliers alpha:
$$  \| \boldsymbol w_t \|^2 = \sum_{i\in I_t} \alpha_i \alpha_j \langle \boldsymbol x_i, \boldsymbol x_j \rangle,$$
where the index $t$ represeents the fact that we are only training on a sub-sample of the training examples.</p>
<p>The crucial modification in this stochastic gradient descent method is that they do a projection step at each step of the calculation of the gradient. The projection is that of the weight w onto an L2 ball of radius $1/\sqrt{\lambda}$. Moreover, it does not use the full training examples, but only a sub-sample k of them to compute an approximate sub-gradient. This significantly reduces the computational power and allows for parallel computation. Also note that the learning rate is set to $\eta_t = \frac{1}{\lambda t}$.</p>
<p>The implementation of the for the linear and non-linear kernel case can be readily found on github for various programming languages; I rely on the pseudocode provided by the authors and a simple and straightforward implementation in the repository <a href="https://github.com/h44rd/Pegasos/blob/master/pegasos.py">https://github.com/h44rd/Pegasos/blob/master/pegasos.py</a>.</p>
<p>To better understand the updatee rule in this case, write thee update rules for the stochastic sub-gradient algorithm (it is stochastic because the training data is sampled at random):</p>
<p>if $ y_i f(\boldsymbol x_{i})&lt;1:$ 
$$\boldsymbol w_{t+1} = \boldsymbol w_{t} - \eta(\lambda \boldsymbol w_{t} - y_i \boldsymbol x_{i}),$$
else:
$$\boldsymbol w_{t+1} = \boldsymbol w_{t} - \eta \lambda \boldsymbol w_{t}, $$
where again $\eta$ is the learning rate.</p>
<p>Source: <a href="https://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf">https://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf</a></p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[507]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define the linear SVM algorithm - training and testing</span>

<span class="k">def</span> <span class="nf">train_nonkernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">lam</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># initialise the weights array</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="c1"># permute the order of the indices</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">:</span>  <span class="c1"># iterate through the indices</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># get the predictor and outcome at index i</span>
        <span class="n">nt</span>  <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>  <span class="c1"># nt is the learning rate, t is incremented after each iteration of the index</span>
        <span class="c1"># these conditionals correspond to the max function l defined above (*)</span>
        <span class="k">if</span> <span class="n">yi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span> 
            <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nt</span> <span class="o">*</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">nt</span> <span class="o">*</span> <span class="n">yi</span> <span class="o">*</span> <span class="n">x</span> 
        <span class="k">elif</span> <span class="n">yi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nt</span> <span class="o">*</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span>
        <span class="n">w</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">))</span> <span class="o">*</span> <span class="n">w</span>  <span class="c1"># update the weights depending on the penalty term</span>
        <span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">w</span>  <span class="c1"># return the weights</span>

<span class="k">def</span> <span class="nf">test_nonkernel</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># init list to store predictions</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">yi</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>  <span class="c1"># append prediction</span>
        <span class="k">if</span> <span class="n">yi</span> <span class="o">*</span> <span class="n">pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>  <span class="c1"># output predictions as signs of the y to get -1,1 values</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Prepare the data and parameters. Note that the performance of the algorithm depends on the parameter lambda and, importantly, does not depend on the size of the data.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[508]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># lambda value</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># number of iterations for training</span>

<span class="c1"># the input is numpy arrays without the extra column of 1&#39;s for the intercept b</span>
<span class="n">X_train_peg</span> <span class="o">=</span> <span class="n">X_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_peg</span> <span class="o">=</span> <span class="n">y_11</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">X_test_peg</span> <span class="o">=</span> <span class="n">X_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_test_peg</span> <span class="o">=</span> <span class="n">y_22</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Run the model</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[509]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">train_nonkernel</span><span class="p">(</span><span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">lam</span><span class="p">)</span>
<span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">test_nonkernel</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X_test_peg</span><span class="p">,</span> <span class="n">y_test_peg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LINEAR SVM correct predictions:&#39;</span><span class="p">,</span><span class="n">correct</span><span class="p">,</span><span class="s1">&#39;total:&#39;</span><span class="p">,</span><span class="n">total</span><span class="p">,</span> <span class="s1">&#39;accuracy:&#39;</span><span class="p">,</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predictions:&#39;</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LINEAR SVM correct predictions: 127 total: 200 accuracy: 0.635
predictions: [-1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.
  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.
 -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.
  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.
  1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.
  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.
 -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.
  1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.
  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.
 -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.
  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.
  1.  1.]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[510]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Evaluate F1 score on test data</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_peg</span><span class="p">,</span><span class="n">preds</span><span class="p">)</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1_linear_test</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TP: 91 FP: 17 TN: 36 FN: 56
F1 score : 0.7137254901960784
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We seee that the F1 score of the linear SVM is not great, suggesting that our data is indeed non linearly separable. Implement the non-linear soft margin SVM with both the Gaussian and sigmoid kernels for a qualitative discussion about their performance.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[529]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define the gaussian RBF kernel</span>
<span class="k">def</span> <span class="nf">kernel_rbf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
     <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span>

<span class="c1"># parameters - slope (commonly 1/N, N is the dimension of data) and intercept c</span>
<span class="k">def</span> <span class="nf">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">c</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">train_kernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
    <span class="n">aplhas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="c1"># permute</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">kernel</span><span class="o">==</span><span class="s1">&#39;rbf&#39;</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">aplhas</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">y_train</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">kernel_rbf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">sigma</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">kernel</span><span class="o">==</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">aplhas</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">y_train</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">yi</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span><span class="o">*</span><span class="n">s</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">aplhas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aplhas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;=</span> <span class="n">T</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="c1">#         if t%100==0:</span>
<span class="c1">#             print(&quot;Iteration of Kernel Training: &quot;, t)</span>
    <span class="k">return</span> <span class="n">aplhas</span>  <span class="c1"># return the alphas - the non-zero ones identify which support vectors define our separation hyperplane</span>


<span class="k">def</span> <span class="nf">test_kernel</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">yi</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">kernel</span><span class="o">==</span><span class="s1">&#39;rbf&#39;</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">alphas</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">y_train</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">kernel_rbf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">sigma</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">kernel</span><span class="o">==</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">alphas</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">y_train</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">kernel_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">yi</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span><span class="o">*</span><span class="n">s</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;=</span> <span class="n">T</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="c1">#         if t%50==0:</span>
<span class="c1">#             print(&quot;Testing iteration: &quot;, t)</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">preds</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[474]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">slope</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">X_train_peg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">c</span> <span class="o">=</span> <span class="mf">0.0005</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that the algorithm for the kernelised SVM is much slower.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[483]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># run the kernelised non-linear SVM algorithm using the RBF kernel</span>
<span class="n">alphas_rfb</span> <span class="o">=</span> <span class="n">train_kernel</span><span class="p">(</span><span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>
<span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">test_kernel</span><span class="p">(</span><span class="n">alphas_rfb</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_test_peg</span><span class="p">,</span> <span class="n">y_test_peg</span><span class="p">,</span> <span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NON-LINEAR RBF KERNEL SVM -- correct predictions:&#39;</span><span class="p">,</span><span class="n">correct</span><span class="p">,</span><span class="s1">&#39;total:&#39;</span><span class="p">,</span><span class="n">total</span><span class="p">,</span> <span class="s1">&#39;accuracy:&#39;</span><span class="p">,</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predictions:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration of Kernel Training:  100
Iteration of Kernel Training:  200
Iteration of Kernel Training:  300
Iteration of Kernel Training:  400
Iteration of Kernel Training:  500
Iteration of Kernel Training:  600
Iteration of Kernel Training:  700
Iteration of Kernel Training:  800
Testing iteration:  50
Testing iteration:  100
Testing iteration:  150
Testing iteration:  200
NON-LINEAR RBF KERNEL SVM -- correct predictions: 181 total: 200 accuracy: 0.905
predictions: [ 1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.
  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.
 -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.
 -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.
  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.
 -1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.
  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.
  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.
 -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.
 -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.
  1. -1.]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[484]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Evaluate F1 score on test data</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_peg</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1_linear_test</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TP: 115 FP: 33 TN: 20 FN: 32
F1 score : 0.7796610169491526
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that the score is better than that for the linear SVM, suggesting our data is better separable with the extra dimension. Perhaps the sigmoid kernel is even better suited to our data.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[485]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># run the kernelised non-linear SVM algorithm using the sigmoid kernel</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">train_kernel</span><span class="p">(</span><span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
<span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">test_kernel</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_test_peg</span><span class="p">,</span> <span class="n">y_test_peg</span><span class="p">,</span> <span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NON-LINEAR SIGMOID KERNEL SVM -- correct predictions:&#39;</span><span class="p">,</span><span class="n">correct</span><span class="p">,</span><span class="s1">&#39;total:&#39;</span><span class="p">,</span><span class="n">total</span><span class="p">,</span> <span class="s1">&#39;accuracy:&#39;</span><span class="p">,</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predictions:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iteration of Kernel Training:  100
Iteration of Kernel Training:  200
Iteration of Kernel Training:  300
Iteration of Kernel Training:  400
Iteration of Kernel Training:  500
Iteration of Kernel Training:  600
Iteration of Kernel Training:  700
Iteration of Kernel Training:  800
Testing iteration:  50
Testing iteration:  100
Testing iteration:  150
Testing iteration:  200
NON-LINEAR SIGMOID KERNEL SVM -- correct predictions: 135 total: 200 accuracy: 0.675
predictions: [ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.
 -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1. -1. -1. -1.
  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1.
 -1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.
 -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1.
 -1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.
  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.
  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.
  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.
  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.
  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.
  1.  1.]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[486]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Evaluate F1 score on test data</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_peg</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1_linear_test</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TP: 67 FP: 45 TN: 8 FN: 80
F1 score : 0.5173745173745173
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Using this algorithm, we ge a worse accuracy and F1 score for the sigmoid kernel. This may be due to a poor choice of parameters.</p>
<p>Although having a better score and accuracy for the sigmoid kernel clearly suggests that the data is separable in the extra dimensional space. We now perform a 5-fold CV and grid search for the optimal hyperparameters for the soft-margin sigmoid kernel SVM.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[530]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_val_evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
  
  <span class="n">folds</span> <span class="o">=</span> <span class="n">cross_val_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>  <span class="c1"># we get transposed folds, data is (800, 11) dimensional</span>

  <span class="n">F1_scores</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># for score on validation folds</span>
  <span class="n">F1_test</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># on test set (most important one)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># define the training set</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">folds</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">folds</span><span class="p">),</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">folds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_folds</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="o">*</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_folds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># define the validation set</span>
    <span class="n">val_fold</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">val_fold</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># train the model</span>
    <span class="n">T</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># number of iterations for training</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># will not be used, rbf param</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">train_kernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
    
    <span class="c1"># get predictions</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y_pred_val</span> <span class="o">=</span> <span class="n">test_kernel</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>  <span class="c1"># get y_pred on validation fold</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">test_kernel</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>  <span class="c1"># get y_pred on test set</span>
    
    
    <span class="c1"># evaluate with F1 score on the validation fold</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_pred_val</span><span class="p">))</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">F1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1</span><span class="p">)</span>
    
    <span class="c1"># evaluate with F1 score on the test set</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">))</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">F1_t</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">F1_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1_t</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">F1_scores</span><span class="p">,</span> <span class="n">F1_test</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[544]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get stacked training and testing data to do the folds</span>
<span class="n">y_train_peg</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span><span class="o">+</span><span class="n">y_train_peg</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">y_test_peg</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">+</span><span class="n">y_test_peg</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train_peg</span><span class="p">,</span><span class="n">y_train_peg</span><span class="p">))</span>  
<span class="n">data_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test_peg</span><span class="p">,</span><span class="n">y_test_peg</span><span class="p">))</span>

<span class="c1"># set parameters</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="n">max_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [slope, c]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;c&#39;</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">slope</span> <span class="ow">in</span> <span class="n">slopes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span><span class="n">slope</span><span class="p">)</span>
        <span class="n">F1_val</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">F1_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_scores</span><span class="o">&gt;</span><span class="n">max_val</span><span class="p">:</span>
            <span class="n">max_val</span> <span class="o">=</span> <span class="n">F1_scores</span>
            <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                
        <span class="n">F1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_test</span><span class="o">&gt;</span><span class="n">max_test</span><span class="p">:</span>
            <span class="n">max_test</span> <span class="o">=</span> <span class="n">F1_test</span>
            <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
    
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>c 0.01
slope 0.01
Fold 1
TP: 58 FP: 38 TN: 11 FN: 53
F1 score : 0.5603864734299517
TP: 75 FP: 37 TN: 16 FN: 72
F1 score : 0.5791505791505791
Fold 2
TP: 47 FP: 39 TN: 12 FN: 62
F1 score : 0.4820512820512821
TP: 76 FP: 41 TN: 12 FN: 71
F1 score : 0.5757575757575758
Fold 3
TP: 55 FP: 37 TN: 12 FN: 56
F1 score : 0.541871921182266
TP: 76 FP: 34 TN: 19 FN: 71
F1 score : 0.5914396887159533
Fold 4
TP: 51 FP: 29 TN: 13 FN: 67
F1 score : 0.5151515151515151
TP: 75 FP: 37 TN: 16 FN: 72
F1 score : 0.5791505791505791
Fold 5
TP: 53 FP: 25 TN: 16 FN: 66
F1 score : 0.5380710659898478
TP: 74 FP: 37 TN: 16 FN: 73
F1 score : 0.5736434108527131
slope 0.34
Fold 1
TP: 49 FP: 27 TN: 22 FN: 62
F1 score : 0.5240641711229946
TP: 68 FP: 27 TN: 26 FN: 79
F1 score : 0.5619834710743802
Fold 2
TP: 47 FP: 32 TN: 19 FN: 62
F1 score : 0.5
TP: 65 FP: 50 TN: 3 FN: 82
F1 score : 0.4961832061068703
Fold 3
TP: 50 FP: 35 TN: 14 FN: 61
F1 score : 0.5102040816326531
TP: 56 FP: 40 TN: 13 FN: 91
F1 score : 0.4609053497942387
Fold 4
TP: 48 FP: 22 TN: 20 FN: 70
F1 score : 0.5106382978723405
TP: 71 FP: 30 TN: 23 FN: 76
F1 score : 0.5725806451612903
Fold 5
TP: 50 FP: 23 TN: 18 FN: 69
F1 score : 0.5208333333333334
TP: 68 FP: 25 TN: 28 FN: 79
F1 score : 0.5666666666666667
slope 0.67
Fold 1
TP: 52 FP: 35 TN: 14 FN: 59
F1 score : 0.5252525252525252
TP: 66 FP: 40 TN: 13 FN: 81
F1 score : 0.5217391304347826
Fold 2
TP: 41 FP: 35 TN: 16 FN: 68
F1 score : 0.4432432432432433
TP: 69 FP: 29 TN: 24 FN: 78
F1 score : 0.563265306122449
Fold 3
TP: 53 FP: 33 TN: 16 FN: 58
F1 score : 0.5380710659898477
TP: 76 FP: 45 TN: 8 FN: 71
F1 score : 0.5671641791044777
Fold 4
TP: 47 FP: 23 TN: 19 FN: 71
F1 score : 0.5
TP: 67 FP: 28 TN: 25 FN: 80
F1 score : 0.5537190082644627
Fold 5
TP: 51 FP: 29 TN: 12 FN: 68
F1 score : 0.5125628140703518
TP: 60 FP: 41 TN: 12 FN: 87
F1 score : 0.48387096774193544
slope 1.0
Fold 1
TP: 48 FP: 29 TN: 20 FN: 63
F1 score : 0.5106382978723404
TP: 70 FP: 33 TN: 20 FN: 77
F1 score : 0.5599999999999999
Fold 2
TP: 50 FP: 34 TN: 17 FN: 59
F1 score : 0.5181347150259067
TP: 72 FP: 49 TN: 4 FN: 75
F1 score : 0.5373134328358209
Fold 3
TP: 53 FP: 31 TN: 18 FN: 58
F1 score : 0.5435897435897435
TP: 69 FP: 24 TN: 29 FN: 78
F1 score : 0.5750000000000001
Fold 4
TP: 47 FP: 25 TN: 17 FN: 71
F1 score : 0.49473684210526314
TP: 68 FP: 29 TN: 24 FN: 79
F1 score : 0.5573770491803278
Fold 5
TP: 53 FP: 27 TN: 14 FN: 66
F1 score : 0.5326633165829145
TP: 60 FP: 40 TN: 13 FN: 87
F1 score : 0.48582995951416996
c 0.016666666666666666
slope 0.01
Fold 1
TP: 64 FP: 44 TN: 5 FN: 47
F1 score : 0.5844748858447488
TP: 80 FP: 40 TN: 13 FN: 67
F1 score : 0.599250936329588
Fold 2
TP: 51 FP: 39 TN: 12 FN: 58
F1 score : 0.5125628140703516
TP: 80 FP: 40 TN: 13 FN: 67
F1 score : 0.599250936329588
Fold 3
TP: 58 FP: 43 TN: 6 FN: 53
F1 score : 0.5471698113207547
TP: 84 FP: 40 TN: 13 FN: 63
F1 score : 0.6199261992619925
Fold 4
TP: 63 FP: 32 TN: 10 FN: 55
F1 score : 0.5915492957746479
TP: 77 FP: 41 TN: 12 FN: 70
F1 score : 0.5811320754716982
Fold 5
TP: 66 FP: 28 TN: 13 FN: 53
F1 score : 0.619718309859155
TP: 83 FP: 35 TN: 18 FN: 64
F1 score : 0.6264150943396227
slope 0.34
Fold 1
TP: 54 FP: 37 TN: 12 FN: 57
F1 score : 0.5346534653465347
TP: 65 FP: 46 TN: 7 FN: 82
F1 score : 0.503875968992248
Fold 2
TP: 60 FP: 19 TN: 32 FN: 49
F1 score : 0.6382978723404256
TP: 67 FP: 34 TN: 19 FN: 80
F1 score : 0.5403225806451614
Fold 3
TP: 50 FP: 35 TN: 14 FN: 61
F1 score : 0.5102040816326531
TP: 70 FP: 40 TN: 13 FN: 77
F1 score : 0.5447470817120622
Fold 4
TP: 49 FP: 27 TN: 15 FN: 69
F1 score : 0.5051546391752578
TP: 71 FP: 31 TN: 22 FN: 76
F1 score : 0.570281124497992
Fold 5
TP: 48 FP: 26 TN: 15 FN: 71
F1 score : 0.4974093264248705
TP: 62 FP: 42 TN: 11 FN: 85
F1 score : 0.49402390438247007
slope 0.67
Fold 1
TP: 48 FP: 32 TN: 17 FN: 63
F1 score : 0.5026178010471204
TP: 70 FP: 33 TN: 20 FN: 77
F1 score : 0.5599999999999999
Fold 2
TP: 39 FP: 34 TN: 17 FN: 70
F1 score : 0.42857142857142866
TP: 65 FP: 28 TN: 25 FN: 82
F1 score : 0.5416666666666666
Fold 3
TP: 45 FP: 35 TN: 14 FN: 66
F1 score : 0.47120418848167533
TP: 62 FP: 34 TN: 19 FN: 85
F1 score : 0.5102880658436213
Fold 4
TP: 46 FP: 24 TN: 18 FN: 72
F1 score : 0.4893617021276596
TP: 67 FP: 31 TN: 22 FN: 80
F1 score : 0.546938775510204
Fold 5
TP: 48 FP: 29 TN: 12 FN: 71
F1 score : 0.48979591836734687
TP: 55 FP: 47 TN: 6 FN: 92
F1 score : 0.44176706827309237
slope 1.0
Fold 1
TP: 53 FP: 36 TN: 13 FN: 58
F1 score : 0.53
TP: 57 FP: 46 TN: 7 FN: 90
F1 score : 0.456
Fold 2
TP: 47 FP: 38 TN: 13 FN: 62
F1 score : 0.4845360824742268
TP: 77 FP: 49 TN: 4 FN: 70
F1 score : 0.5641025641025642
Fold 3
TP: 48 FP: 35 TN: 14 FN: 63
F1 score : 0.49484536082474223
TP: 63 FP: 40 TN: 13 FN: 84
F1 score : 0.5039999999999999
Fold 4
TP: 61 FP: 33 TN: 9 FN: 57
F1 score : 0.5754716981132074
TP: 69 FP: 43 TN: 10 FN: 78
F1 score : 0.5328185328185329
Fold 5
TP: 52 FP: 25 TN: 16 FN: 67
F1 score : 0.5306122448979592
TP: 70 FP: 31 TN: 22 FN: 77
F1 score : 0.564516129032258
c 0.02333333333333333
slope 0.01
Fold 1
TP: 66 FP: 44 TN: 5 FN: 45
F1 score : 0.5972850678733032
TP: 81 FP: 40 TN: 13 FN: 66
F1 score : 0.6044776119402985
Fold 2
TP: 65 FP: 42 TN: 9 FN: 44
F1 score : 0.6018518518518519
TP: 87 FP: 42 TN: 11 FN: 60
F1 score : 0.6304347826086958
Fold 3
TP: 60 FP: 38 TN: 11 FN: 51
F1 score : 0.5741626794258374
TP: 80 FP: 43 TN: 10 FN: 67
F1 score : 0.5925925925925926
Fold 4
TP: 65 FP: 34 TN: 8 FN: 53
F1 score : 0.599078341013825
TP: 80 FP: 40 TN: 13 FN: 67
F1 score : 0.599250936329588
Fold 5
TP: 71 FP: 31 TN: 10 FN: 48
F1 score : 0.6425339366515838
TP: 83 FP: 41 TN: 12 FN: 64
F1 score : 0.6125461254612545
slope 0.34
Fold 1
TP: 52 FP: 37 TN: 12 FN: 59
F1 score : 0.52
TP: 55 FP: 47 TN: 6 FN: 92
F1 score : 0.44176706827309237
Fold 2
TP: 38 FP: 38 TN: 13 FN: 71
F1 score : 0.41081081081081083
TP: 65 FP: 34 TN: 19 FN: 82
F1 score : 0.5284552845528455
Fold 3
TP: 55 FP: 33 TN: 16 FN: 56
F1 score : 0.5527638190954773
TP: 72 FP: 25 TN: 28 FN: 75
F1 score : 0.5901639344262295
Fold 4
TP: 50 FP: 25 TN: 17 FN: 68
F1 score : 0.5181347150259066
TP: 71 FP: 31 TN: 22 FN: 76
F1 score : 0.570281124497992
Fold 5
TP: 56 FP: 27 TN: 14 FN: 63
F1 score : 0.5544554455445544
TP: 66 FP: 39 TN: 14 FN: 81
F1 score : 0.5238095238095237
slope 0.67
Fold 1
TP: 46 FP: 32 TN: 17 FN: 65
F1 score : 0.4867724867724868
TP: 69 FP: 36 TN: 17 FN: 78
F1 score : 0.5476190476190477
Fold 2
TP: 47 FP: 37 TN: 14 FN: 62
F1 score : 0.48704663212435234
TP: 59 FP: 47 TN: 6 FN: 88
F1 score : 0.466403162055336
Fold 3
TP: 55 FP: 36 TN: 13 FN: 56
F1 score : 0.5445544554455446
TP: 70 FP: 47 TN: 6 FN: 77
F1 score : 0.5303030303030303
Fold 4
TP: 61 FP: 36 TN: 6 FN: 57
F1 score : 0.5674418604651162
TP: 66 FP: 49 TN: 4 FN: 81
F1 score : 0.5038167938931297
Fold 5
TP: 57 FP: 21 TN: 20 FN: 62
F1 score : 0.5786802030456852
TP: 63 FP: 31 TN: 22 FN: 84
F1 score : 0.5228215767634854
slope 1.0
Fold 1
TP: 49 FP: 28 TN: 21 FN: 62
F1 score : 0.5212765957446808
TP: 67 FP: 31 TN: 22 FN: 80
F1 score : 0.546938775510204
Fold 2
TP: 46 FP: 33 TN: 18 FN: 63
F1 score : 0.48936170212765956
TP: 60 FP: 27 TN: 26 FN: 87
F1 score : 0.5128205128205129
Fold 3
TP: 48 FP: 33 TN: 16 FN: 63
F1 score : 0.5
TP: 66 FP: 27 TN: 26 FN: 81
F1 score : 0.5499999999999999
Fold 4
TP: 45 FP: 22 TN: 20 FN: 73
F1 score : 0.4864864864864865
TP: 67 FP: 30 TN: 23 FN: 80
F1 score : 0.5491803278688524
Fold 5
TP: 55 FP: 22 TN: 19 FN: 64
F1 score : 0.5612244897959183
TP: 62 FP: 29 TN: 24 FN: 85
F1 score : 0.5210084033613446
c 0.03
slope 0.01
Fold 1
TP: 65 FP: 44 TN: 5 FN: 46
F1 score : 0.5909090909090908
TP: 87 FP: 40 TN: 13 FN: 60
F1 score : 0.635036496350365
Fold 2
TP: 62 FP: 41 TN: 10 FN: 47
F1 score : 0.5849056603773586
TP: 85 FP: 40 TN: 13 FN: 62
F1 score : 0.625
Fold 3
TP: 71 FP: 46 TN: 3 FN: 40
F1 score : 0.6228070175438597
TP: 88 FP: 40 TN: 13 FN: 59
F1 score : 0.64
Fold 4
TP: 68 FP: 33 TN: 9 FN: 50
F1 score : 0.6210045662100457
TP: 77 FP: 40 TN: 13 FN: 70
F1 score : 0.5833333333333334
Fold 5
TP: 73 FP: 32 TN: 9 FN: 46
F1 score : 0.6517857142857143
TP: 88 FP: 44 TN: 9 FN: 59
F1 score : 0.6308243727598566
slope 0.34
Fold 1
TP: 49 FP: 28 TN: 21 FN: 62
F1 score : 0.5212765957446808
TP: 67 FP: 29 TN: 24 FN: 80
F1 score : 0.551440329218107
Fold 2
TP: 43 FP: 38 TN: 13 FN: 66
F1 score : 0.45263157894736844
TP: 68 FP: 35 TN: 18 FN: 79
F1 score : 0.544
Fold 3
TP: 50 FP: 32 TN: 17 FN: 61
F1 score : 0.5181347150259068
TP: 71 FP: 29 TN: 24 FN: 76
F1 score : 0.5748987854251013
Fold 4
TP: 46 FP: 26 TN: 16 FN: 72
F1 score : 0.4842105263157894
TP: 70 FP: 28 TN: 25 FN: 77
F1 score : 0.5714285714285714
Fold 5
TP: 47 FP: 24 TN: 17 FN: 72
F1 score : 0.4947368421052632
TP: 67 FP: 33 TN: 20 FN: 80
F1 score : 0.5425101214574899
slope 0.67
Fold 1
TP: 50 FP: 27 TN: 22 FN: 61
F1 score : 0.5319148936170213
TP: 66 FP: 26 TN: 27 FN: 81
F1 score : 0.5523012552301255
Fold 2
TP: 42 FP: 37 TN: 14 FN: 67
F1 score : 0.44680851063829785
TP: 67 FP: 27 TN: 26 FN: 80
F1 score : 0.5560165975103735
Fold 3
TP: 51 FP: 35 TN: 14 FN: 60
F1 score : 0.5177664974619289
TP: 64 FP: 48 TN: 5 FN: 83
F1 score : 0.49420849420849416
Fold 4
TP: 63 FP: 27 TN: 15 FN: 55
F1 score : 0.6057692307692307
TP: 63 FP: 38 TN: 15 FN: 84
F1 score : 0.5080645161290323
Fold 5
TP: 54 FP: 24 TN: 17 FN: 65
F1 score : 0.5482233502538071
TP: 70 FP: 31 TN: 22 FN: 77
F1 score : 0.564516129032258
slope 1.0
Fold 1
TP: 52 FP: 35 TN: 14 FN: 59
F1 score : 0.5252525252525252
TP: 56 FP: 46 TN: 7 FN: 91
F1 score : 0.4497991967871486
Fold 2
TP: 46 FP: 33 TN: 18 FN: 63
F1 score : 0.48936170212765956
TP: 76 FP: 49 TN: 4 FN: 71
F1 score : 0.5588235294117647
Fold 3
TP: 49 FP: 35 TN: 14 FN: 62
F1 score : 0.5025641025641026
TP: 63 FP: 38 TN: 15 FN: 84
F1 score : 0.5080645161290323
Fold 4
TP: 45 FP: 23 TN: 19 FN: 73
F1 score : 0.48387096774193544
TP: 65 FP: 28 TN: 25 FN: 82
F1 score : 0.5416666666666666
Fold 5
TP: 48 FP: 24 TN: 17 FN: 71
F1 score : 0.5026178010471204
TP: 70 FP: 30 TN: 23 FN: 77
F1 score : 0.5668016194331984
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[545]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best parameters [slope,c]&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;on validation sets&#39;</span><span class="p">,</span> <span class="n">list_params_val</span><span class="p">,</span> <span class="s1">&#39;max F1 score&#39;</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;on testing sets&#39;</span><span class="p">,</span> <span class="n">list_params_test</span><span class="p">,</span> <span class="s1">&#39;max F1 score&#39;</span><span class="p">,</span> <span class="n">max_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>best parameters [slope,c]
on validation sets [0.01, 0.03] max F1 score 0.6142824098652138
on testing sets [0.01, 0.03] max F1 score 0.622838840488711
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>We get much better F1 scores than with defaulut parameters, but the optimal values indicate that we need to look at smaller values of the parameters:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[547]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.005</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">1000</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="mi">200</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="n">max_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># [slope, c]</span>
<span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> 
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;c&#39;</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">slope</span> <span class="ow">in</span> <span class="n">slopes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span><span class="n">slope</span><span class="p">)</span>
        <span class="n">F1_val</span><span class="p">,</span> <span class="n">F1_test</span> <span class="o">=</span> <span class="n">cross_val_evaluate</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">F1_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_scores</span><span class="o">&gt;</span><span class="n">max_val</span><span class="p">:</span>
            <span class="n">max_val</span> <span class="o">=</span> <span class="n">F1_scores</span>
            <span class="n">list_params_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                
        <span class="n">F1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">F1_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F1_test</span><span class="o">&gt;</span><span class="n">max_test</span><span class="p">:</span>
            <span class="n">max_test</span> <span class="o">=</span> <span class="n">F1_test</span>
            <span class="n">list_params_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">slope</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>c 0.001
slope 0.001
Fold 1
TP: 83 FP: 46 TN: 3 FN: 28
F1 score : 0.6916666666666667
TP: 107 FP: 52 TN: 1 FN: 40
F1 score : 0.6993464052287581
Fold 2
TP: 80 FP: 46 TN: 5 FN: 29
F1 score : 0.6808510638297872
TP: 114 FP: 52 TN: 1 FN: 33
F1 score : 0.7284345047923322
Fold 3
TP: 85 FP: 47 TN: 2 FN: 26
F1 score : 0.6995884773662552
TP: 105 FP: 52 TN: 1 FN: 42
F1 score : 0.6907894736842105
Fold 4
TP: 82 FP: 41 TN: 1 FN: 36
F1 score : 0.6804979253112033
TP: 103 FP: 47 TN: 6 FN: 44
F1 score : 0.6936026936026937
Fold 5
TP: 92 FP: 35 TN: 6 FN: 27
F1 score : 0.7479674796747969
TP: 105 FP: 52 TN: 1 FN: 42
F1 score : 0.6907894736842105
slope 0.002333333333333333
Fold 1
TP: 66 FP: 44 TN: 5 FN: 45
F1 score : 0.5972850678733032
TP: 79 FP: 39 TN: 14 FN: 68
F1 score : 0.5962264150943397
Fold 2
TP: 58 FP: 41 TN: 10 FN: 51
F1 score : 0.5576923076923076
TP: 82 FP: 40 TN: 13 FN: 65
F1 score : 0.6096654275092938
Fold 3
TP: 55 FP: 41 TN: 8 FN: 56
F1 score : 0.5314009661835748
TP: 75 FP: 40 TN: 13 FN: 72
F1 score : 0.5725190839694656
Fold 4
TP: 66 FP: 36 TN: 6 FN: 52
F1 score : 0.6
TP: 80 FP: 40 TN: 13 FN: 67
F1 score : 0.599250936329588
Fold 5
TP: 69 FP: 30 TN: 11 FN: 50
F1 score : 0.6330275229357799
TP: 81 FP: 40 TN: 13 FN: 66
F1 score : 0.6044776119402985
slope 0.0036666666666666666
Fold 1
TP: 51 FP: 42 TN: 7 FN: 60
F1 score : 0.5
TP: 70 FP: 36 TN: 17 FN: 77
F1 score : 0.5533596837944664
Fold 2
TP: 50 FP: 38 TN: 13 FN: 59
F1 score : 0.5076142131979695
TP: 73 FP: 39 TN: 14 FN: 74
F1 score : 0.5637065637065637
Fold 3
TP: 50 FP: 39 TN: 10 FN: 61
F1 score : 0.5
TP: 72 FP: 36 TN: 17 FN: 75
F1 score : 0.5647058823529412
Fold 4
TP: 61 FP: 30 TN: 12 FN: 57
F1 score : 0.583732057416268
TP: 69 FP: 36 TN: 17 FN: 78
F1 score : 0.5476190476190477
Fold 5
TP: 50 FP: 26 TN: 15 FN: 69
F1 score : 0.5128205128205129
TP: 63 FP: 36 TN: 17 FN: 84
F1 score : 0.5121951219512195
slope 0.005
Fold 1
TP: 49 FP: 37 TN: 12 FN: 62
F1 score : 0.4974619289340101
TP: 67 FP: 37 TN: 16 FN: 80
F1 score : 0.5338645418326693
Fold 2
TP: 43 FP: 37 TN: 14 FN: 66
F1 score : 0.45502645502645506
TP: 68 FP: 39 TN: 14 FN: 79
F1 score : 0.5354330708661418
Fold 3
TP: 47 FP: 36 TN: 13 FN: 64
F1 score : 0.48453608247422686
TP: 70 FP: 36 TN: 17 FN: 77
F1 score : 0.5533596837944664
Fold 4
TP: 54 FP: 29 TN: 13 FN: 64
F1 score : 0.5373134328358209
TP: 66 FP: 36 TN: 17 FN: 81
F1 score : 0.5301204819277109
Fold 5
TP: 48 FP: 24 TN: 17 FN: 71
F1 score : 0.5026178010471204
TP: 72 FP: 36 TN: 17 FN: 75
F1 score : 0.5647058823529412
c 0.002333333333333333
slope 0.001
Fold 1
TP: 105 FP: 49 TN: 0 FN: 6
F1 score : 0.7924528301886792
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
Fold 2
TP: 103 FP: 51 TN: 0 FN: 6
F1 score : 0.7832699619771862
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
Fold 3
TP: 107 FP: 49 TN: 0 FN: 4
F1 score : 0.801498127340824
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
Fold 4
TP: 113 FP: 41 TN: 1 FN: 5
F1 score : 0.8308823529411765
TP: 142 FP: 53 TN: 0 FN: 5
F1 score : 0.8304093567251462
Fold 5
TP: 110 FP: 41 TN: 0 FN: 9
F1 score : 0.8148148148148148
TP: 141 FP: 53 TN: 0 FN: 6
F1 score : 0.8269794721407624
slope 0.002333333333333333
Fold 1
TP: 76 FP: 46 TN: 3 FN: 35
F1 score : 0.6523605150214593
TP: 97 FP: 47 TN: 6 FN: 50
F1 score : 0.6666666666666666
Fold 2
TP: 76 FP: 44 TN: 7 FN: 33
F1 score : 0.6637554585152838
TP: 108 FP: 47 TN: 6 FN: 39
F1 score : 0.7152317880794702
Fold 3
TP: 79 FP: 46 TN: 3 FN: 32
F1 score : 0.6694915254237288
TP: 100 FP: 47 TN: 6 FN: 47
F1 score : 0.6802721088435374
Fold 4
TP: 77 FP: 36 TN: 6 FN: 41
F1 score : 0.6666666666666666
TP: 92 FP: 44 TN: 9 FN: 55
F1 score : 0.6501766784452297
Fold 5
TP: 78 FP: 34 TN: 7 FN: 41
F1 score : 0.6753246753246753
TP: 90 FP: 43 TN: 10 FN: 57
F1 score : 0.6428571428571429
slope 0.0036666666666666666
Fold 1
TP: 62 FP: 44 TN: 5 FN: 49
F1 score : 0.5714285714285714
TP: 79 FP: 40 TN: 13 FN: 68
F1 score : 0.5939849624060151
Fold 2
TP: 54 FP: 43 TN: 8 FN: 55
F1 score : 0.5242718446601943
TP: 82 FP: 42 TN: 11 FN: 65
F1 score : 0.6051660516605165
Fold 3
TP: 55 FP: 39 TN: 10 FN: 56
F1 score : 0.5365853658536586
TP: 76 FP: 37 TN: 16 FN: 71
F1 score : 0.5846153846153846
Fold 4
TP: 62 FP: 32 TN: 10 FN: 56
F1 score : 0.5849056603773585
TP: 75 FP: 40 TN: 13 FN: 72
F1 score : 0.5725190839694656
Fold 5
TP: 65 FP: 31 TN: 10 FN: 54
F1 score : 0.6046511627906976
TP: 81 FP: 39 TN: 14 FN: 66
F1 score : 0.6067415730337078
slope 0.005
Fold 1
TP: 55 FP: 37 TN: 12 FN: 56
F1 score : 0.541871921182266
TP: 74 FP: 37 TN: 16 FN: 73
F1 score : 0.5736434108527131
Fold 2
TP: 48 FP: 42 TN: 9 FN: 61
F1 score : 0.4824120603015076
TP: 71 FP: 40 TN: 13 FN: 76
F1 score : 0.5503875968992249
Fold 3
TP: 52 FP: 39 TN: 10 FN: 59
F1 score : 0.514851485148515
TP: 75 FP: 37 TN: 16 FN: 72
F1 score : 0.5791505791505791
Fold 4
TP: 61 FP: 30 TN: 12 FN: 57
F1 score : 0.583732057416268
TP: 73 FP: 37 TN: 16 FN: 74
F1 score : 0.5680933852140079
Fold 5
TP: 61 FP: 27 TN: 14 FN: 58
F1 score : 0.5893719806763283
TP: 77 FP: 39 TN: 14 FN: 70
F1 score : 0.5855513307984791
c 0.0036666666666666666
slope 0.001
Fold 1
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 146 FP: 53 TN: 0 FN: 1
F1 score : 0.8439306358381502
Fold 2
TP: 107 FP: 51 TN: 0 FN: 2
F1 score : 0.8014981273408239
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 3
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 146 FP: 53 TN: 0 FN: 1
F1 score : 0.8439306358381502
Fold 5
TP: 116 FP: 41 TN: 0 FN: 3
F1 score : 0.8405797101449274
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
slope 0.002333333333333333
Fold 1
TP: 84 FP: 46 TN: 3 FN: 27
F1 score : 0.6970954356846473
TP: 106 FP: 47 TN: 6 FN: 41
F1 score : 0.7066666666666667
Fold 2
TP: 81 FP: 45 TN: 6 FN: 28
F1 score : 0.6893617021276596
TP: 114 FP: 47 TN: 6 FN: 33
F1 score : 0.7402597402597403
Fold 3
TP: 82 FP: 48 TN: 1 FN: 29
F1 score : 0.6804979253112033
TP: 101 FP: 52 TN: 1 FN: 46
F1 score : 0.6733333333333333
Fold 4
TP: 87 FP: 41 TN: 1 FN: 31
F1 score : 0.7073170731707318
TP: 99 FP: 47 TN: 6 FN: 48
F1 score : 0.6757679180887373
Fold 5
TP: 95 FP: 35 TN: 6 FN: 24
F1 score : 0.7630522088353414
TP: 104 FP: 52 TN: 1 FN: 43
F1 score : 0.6864686468646864
slope 0.0036666666666666666
Fold 1
TP: 66 FP: 44 TN: 5 FN: 45
F1 score : 0.5972850678733032
TP: 83 FP: 40 TN: 13 FN: 64
F1 score : 0.6148148148148148
Fold 2
TP: 60 FP: 43 TN: 8 FN: 49
F1 score : 0.5660377358490566
TP: 86 FP: 41 TN: 12 FN: 61
F1 score : 0.6277372262773724
Fold 3
TP: 65 FP: 43 TN: 6 FN: 46
F1 score : 0.5936073059360731
TP: 87 FP: 44 TN: 9 FN: 60
F1 score : 0.6258992805755397
Fold 4
TP: 64 FP: 32 TN: 10 FN: 54
F1 score : 0.5981308411214954
TP: 77 FP: 41 TN: 12 FN: 70
F1 score : 0.5811320754716982
Fold 5
TP: 72 FP: 31 TN: 10 FN: 47
F1 score : 0.6486486486486487
TP: 81 FP: 44 TN: 9 FN: 66
F1 score : 0.5955882352941175
slope 0.005
Fold 1
TP: 61 FP: 44 TN: 5 FN: 50
F1 score : 0.5648148148148149
TP: 76 FP: 40 TN: 13 FN: 71
F1 score : 0.5779467680608366
Fold 2
TP: 61 FP: 42 TN: 9 FN: 48
F1 score : 0.5754716981132075
TP: 77 FP: 44 TN: 9 FN: 70
F1 score : 0.5746268656716419
Fold 3
TP: 59 FP: 41 TN: 8 FN: 52
F1 score : 0.5592417061611374
TP: 79 FP: 41 TN: 12 FN: 68
F1 score : 0.5917602996254682
Fold 4
TP: 62 FP: 31 TN: 11 FN: 56
F1 score : 0.5876777251184834
TP: 75 FP: 40 TN: 13 FN: 72
F1 score : 0.5725190839694656
Fold 5
TP: 66 FP: 29 TN: 12 FN: 53
F1 score : 0.616822429906542
TP: 76 FP: 39 TN: 14 FN: 71
F1 score : 0.5801526717557253
c 0.005
slope 0.001
Fold 1
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 2
TP: 107 FP: 51 TN: 0 FN: 2
F1 score : 0.8014981273408239
TP: 146 FP: 53 TN: 0 FN: 1
F1 score : 0.8439306358381502
Fold 3
TP: 110 FP: 49 TN: 0 FN: 1
F1 score : 0.8148148148148148
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
Fold 4
TP: 118 FP: 42 TN: 0 FN: 0
F1 score : 0.8489208633093526
TP: 146 FP: 53 TN: 0 FN: 1
F1 score : 0.8439306358381502
Fold 5
TP: 118 FP: 41 TN: 0 FN: 1
F1 score : 0.8489208633093526
TP: 147 FP: 53 TN: 0 FN: 0
F1 score : 0.8472622478386168
slope 0.002333333333333333
Fold 1
TP: 87 FP: 48 TN: 1 FN: 24
F1 score : 0.7073170731707318
TP: 114 FP: 52 TN: 1 FN: 33
F1 score : 0.7284345047923322
Fold 2
TP: 83 FP: 47 TN: 4 FN: 26
F1 score : 0.6945606694560669
TP: 116 FP: 47 TN: 6 FN: 31
F1 score : 0.7483870967741936
Fold 3
TP: 89 FP: 49 TN: 0 FN: 22
F1 score : 0.7148594377510041
TP: 114 FP: 52 TN: 1 FN: 33
F1 score : 0.7284345047923322
Fold 4
TP: 91 FP: 41 TN: 1 FN: 27
F1 score : 0.728
TP: 110 FP: 47 TN: 6 FN: 37
F1 score : 0.7236842105263157
Fold 5
TP: 92 FP: 35 TN: 6 FN: 27
F1 score : 0.7479674796747969
TP: 99 FP: 47 TN: 6 FN: 48
F1 score : 0.6757679180887373
slope 0.0036666666666666666
Fold 1
TP: 72 FP: 44 TN: 5 FN: 39
F1 score : 0.6343612334801763
TP: 89 FP: 40 TN: 13 FN: 58
F1 score : 0.6449275362318841
Fold 2
TP: 71 FP: 43 TN: 8 FN: 38
F1 score : 0.6367713004484304
TP: 93 FP: 42 TN: 11 FN: 54
F1 score : 0.6595744680851063
Fold 3
TP: 64 FP: 44 TN: 5 FN: 47
F1 score : 0.5844748858447488
TP: 87 FP: 43 TN: 10 FN: 60
F1 score : 0.6281588447653429
Fold 4
TP: 74 FP: 37 TN: 5 FN: 44
F1 score : 0.6462882096069869
TP: 91 FP: 42 TN: 11 FN: 56
F1 score : 0.6500000000000001
Fold 5
TP: 77 FP: 32 TN: 9 FN: 42
F1 score : 0.6754385964912281
TP: 90 FP: 43 TN: 10 FN: 57
F1 score : 0.6428571428571429
slope 0.005
Fold 1
TP: 64 FP: 44 TN: 5 FN: 47
F1 score : 0.5844748858447488
TP: 76 FP: 40 TN: 13 FN: 71
F1 score : 0.5779467680608366
Fold 2
TP: 60 FP: 43 TN: 8 FN: 49
F1 score : 0.5660377358490566
TP: 80 FP: 40 TN: 13 FN: 67
F1 score : 0.599250936329588
Fold 3
TP: 62 FP: 42 TN: 7 FN: 49
F1 score : 0.5767441860465116
TP: 83 FP: 42 TN: 11 FN: 64
F1 score : 0.6102941176470588
Fold 4
TP: 64 FP: 32 TN: 10 FN: 54
F1 score : 0.5981308411214954
TP: 79 FP: 40 TN: 13 FN: 68
F1 score : 0.5939849624060151
Fold 5
TP: 65 FP: 30 TN: 11 FN: 54
F1 score : 0.6074766355140186
TP: 83 FP: 40 TN: 13 FN: 64
F1 score : 0.6148148148148148
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[548]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best parameters [slope,c]&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;on validation sets&#39;</span><span class="p">,</span> <span class="n">list_params_val</span><span class="p">,</span> <span class="s1">&#39;max F1 score&#39;</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;on testing sets&#39;</span><span class="p">,</span> <span class="n">list_params_test</span><span class="p">,</span> <span class="s1">&#39;max F1 score&#39;</span><span class="p">,</span> <span class="n">max_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>best parameters [slope,c]
on validation sets [0.001, 0.005] max F1 score 0.8257938967178318
on testing sets [0.001, 0.005] max F1 score 0.8459296030384301
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Notice that these values look familiar: check whether these high F1 scores are not a result of merely predicting all 1's:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[549]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">slope_opt</span> <span class="o">=</span> <span class="n">list_params_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">c_opt</span> <span class="o">=</span> <span class="n">list_params_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[552]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="n">train_kernel</span><span class="p">(</span><span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope_opt</span><span class="p">,</span> <span class="n">c_opt</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">test_kernel</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">X_test_peg</span><span class="p">,</span> <span class="n">y_test_peg</span><span class="p">,</span> <span class="n">X_train_peg</span><span class="p">,</span> <span class="n">y_train_peg</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">slope_opt</span><span class="p">,</span> <span class="n">c_opt</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>  <span class="c1"># get y_pred on test set</span>
<span class="nb">print</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="c1"># evaluate with F1 score on the test set</span>
<span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_peg</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">))</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">prec_rec</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
<span class="n">F1_t</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">F1_t</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
   1.  1.]]
TP: 145 FP: 53 TN: 0 FN: 2
F1 score : 0.8405797101449276
0.8405797101449276
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>It looks like the sigmoid kernel does not lead to a good separation of the data and therefore a good hyperplane is not defined to separate the data, even using the sigmoid kernel. It ends up overpredicting positive values. A better option is the RBF kernel.</p>

</div>
</div>
</body>







</html>
